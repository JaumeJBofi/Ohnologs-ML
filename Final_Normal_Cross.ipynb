{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_metrics as km\n",
    "from keras import initializers\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import regularizers\n",
    "from custom_callbacks import LrFinder\n",
    "from custom_callbacks import CycleLearner\n",
    "from custom_callbacks import reset_weights\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from time import time\n",
    "from keras.layers import Input, Dense,Dropout,BatchNormalization,LSTM,GRU,Bidirectional,Conv2D, MaxPool2D, Flatten, GlobalAvgPool2D, GlobalMaxPool2D,merge,CuDNNGRU,CuDNNLSTM\n",
    "from keras.models import Model,Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import math\n",
    "import json\n",
    "import keras.backend as K\n",
    "from keras.layers import Lambda\n",
    "\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "\n",
    "train_filepath = \"train_workspace/\"\n",
    "animalList = [\"Human\",\"Pig\",\"Chicken\",\"Rat\",\"Mouse\",\"Dog\"]\n",
    "levelList = [\"Strict\",\"Relaxed\",\"Intermediate\"]\n",
    "dataList = [\"Ohnologs\",\"No-Ohnologs\",\"Paralogs\"]\n",
    "dataNameList = [\"ohnologs\",\"no-ohnologs\",\"paralog\"]\n",
    "sns.set_style(\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_level = \"Strict\"\n",
    "kmer_chosen = 8\n",
    "type_chosen = \"cdna\"\n",
    "\n",
    "dataset_complete = pd.read_pickle(train_filepath + working_level + \"/datasets/2_paralog_dataset_complete-\" + str(kmer_chosen) + \"-\" + type_chosen + \".pkl\")\n",
    "dataset_complete_soft = pd.read_pickle(train_filepath + working_level + \"/datasets/3_paralog_dataset_complete-\" + str(kmer_chosen) + \"-\" + type_chosen + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specie_Chicken</th>\n",
       "      <th>Specie_Dog</th>\n",
       "      <th>Specie_Human</th>\n",
       "      <th>Specie_Mouse</th>\n",
       "      <th>Specie_Pig</th>\n",
       "      <th>Specie_Rat</th>\n",
       "      <th>Is_Ohnolog</th>\n",
       "      <th>Is_Paralog</th>\n",
       "      <th>Sequence-1 GC</th>\n",
       "      <th>Sequence-1 Length</th>\n",
       "      <th>...</th>\n",
       "      <th>Embedding2_91</th>\n",
       "      <th>Embedding2_92</th>\n",
       "      <th>Embedding2_93</th>\n",
       "      <th>Embedding2_94</th>\n",
       "      <th>Embedding2_95</th>\n",
       "      <th>Embedding2_96</th>\n",
       "      <th>Embedding2_97</th>\n",
       "      <th>Embedding2_98</th>\n",
       "      <th>Embedding2_99</th>\n",
       "      <th>Dup_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429090</td>\n",
       "      <td>0.030467</td>\n",
       "      <td>...</td>\n",
       "      <td>35.407509</td>\n",
       "      <td>23.369914</td>\n",
       "      <td>8.144324</td>\n",
       "      <td>-26.702099</td>\n",
       "      <td>241.207709</td>\n",
       "      <td>-12.695194</td>\n",
       "      <td>-79.573883</td>\n",
       "      <td>121.379307</td>\n",
       "      <td>-69.633950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441268</td>\n",
       "      <td>0.053554</td>\n",
       "      <td>...</td>\n",
       "      <td>12.556002</td>\n",
       "      <td>23.217834</td>\n",
       "      <td>3.162621</td>\n",
       "      <td>-18.980361</td>\n",
       "      <td>204.830682</td>\n",
       "      <td>-20.962017</td>\n",
       "      <td>-61.163222</td>\n",
       "      <td>122.543777</td>\n",
       "      <td>-26.694989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357972</td>\n",
       "      <td>0.111632</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.850837</td>\n",
       "      <td>12.314794</td>\n",
       "      <td>-3.387437</td>\n",
       "      <td>-5.403946</td>\n",
       "      <td>93.521862</td>\n",
       "      <td>4.187927</td>\n",
       "      <td>-35.880841</td>\n",
       "      <td>50.565405</td>\n",
       "      <td>-9.853733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684226</td>\n",
       "      <td>0.031676</td>\n",
       "      <td>...</td>\n",
       "      <td>68.287420</td>\n",
       "      <td>6.295047</td>\n",
       "      <td>37.820265</td>\n",
       "      <td>-33.841090</td>\n",
       "      <td>230.696114</td>\n",
       "      <td>-60.500167</td>\n",
       "      <td>-82.975793</td>\n",
       "      <td>174.224105</td>\n",
       "      <td>-111.569089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402629</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>...</td>\n",
       "      <td>18.025175</td>\n",
       "      <td>13.675959</td>\n",
       "      <td>21.304353</td>\n",
       "      <td>-2.702105</td>\n",
       "      <td>162.972440</td>\n",
       "      <td>-8.209692</td>\n",
       "      <td>-46.736790</td>\n",
       "      <td>62.650600</td>\n",
       "      <td>-39.056701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Specie_Chicken  Specie_Dog  Specie_Human  Specie_Mouse  Specie_Pig  \\\n",
       "0               0           0             1             0           0   \n",
       "1               0           0             1             0           0   \n",
       "2               0           0             1             0           0   \n",
       "3               0           0             1             0           0   \n",
       "4               0           0             1             0           0   \n",
       "\n",
       "   Specie_Rat  Is_Ohnolog  Is_Paralog  Sequence-1 GC  Sequence-1 Length  ...  \\\n",
       "0           0           1         0.0       0.429090           0.030467  ...   \n",
       "1           0           1         0.0       0.441268           0.053554  ...   \n",
       "2           0           1         0.0       0.357972           0.111632  ...   \n",
       "3           0           1         0.0       0.684226           0.031676  ...   \n",
       "4           0           1         0.0       0.402629           0.018732  ...   \n",
       "\n",
       "   Embedding2_91  Embedding2_92  Embedding2_93  Embedding2_94  Embedding2_95  \\\n",
       "0      35.407509      23.369914       8.144324     -26.702099     241.207709   \n",
       "1      12.556002      23.217834       3.162621     -18.980361     204.830682   \n",
       "2      -6.850837      12.314794      -3.387437      -5.403946      93.521862   \n",
       "3      68.287420       6.295047      37.820265     -33.841090     230.696114   \n",
       "4      18.025175      13.675959      21.304353      -2.702105     162.972440   \n",
       "\n",
       "   Embedding2_96  Embedding2_97  Embedding2_98  Embedding2_99  Dup_Class  \n",
       "0     -12.695194     -79.573883     121.379307     -69.633950          1  \n",
       "1     -20.962017     -61.163222     122.543777     -26.694989          1  \n",
       "2       4.187927     -35.880841      50.565405      -9.853733          1  \n",
       "3     -60.500167     -82.975793     174.224105    -111.569089          1  \n",
       "4      -8.209692     -46.736790      62.650600     -39.056701          1  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = []\n",
    "for index, row in dataset_complete_soft.iterrows():\n",
    "    if(row[\"Is_Ohnolog\"] == 1):\n",
    "        new_classes.append(1)\n",
    "    else:\n",
    "        if(row[\"Is_Paralog\"] == 0):\n",
    "            new_classes.append(0)\n",
    "        else:\n",
    "            new_classes.append(2)\n",
    "dataset_complete_soft[\"Dup_Class\"] = new_classes\n",
    "dataset_complete_soft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specie_Chicken</th>\n",
       "      <th>Specie_Dog</th>\n",
       "      <th>Specie_Human</th>\n",
       "      <th>Specie_Mouse</th>\n",
       "      <th>Specie_Pig</th>\n",
       "      <th>Specie_Rat</th>\n",
       "      <th>Is_Ohnolog</th>\n",
       "      <th>Is_Paralog</th>\n",
       "      <th>Sequence-1 GC</th>\n",
       "      <th>Sequence-1 Length</th>\n",
       "      <th>...</th>\n",
       "      <th>Embedding2_91</th>\n",
       "      <th>Embedding2_92</th>\n",
       "      <th>Embedding2_93</th>\n",
       "      <th>Embedding2_94</th>\n",
       "      <th>Embedding2_95</th>\n",
       "      <th>Embedding2_96</th>\n",
       "      <th>Embedding2_97</th>\n",
       "      <th>Embedding2_98</th>\n",
       "      <th>Embedding2_99</th>\n",
       "      <th>Dup_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429090</td>\n",
       "      <td>0.115183</td>\n",
       "      <td>...</td>\n",
       "      <td>35.407509</td>\n",
       "      <td>23.369914</td>\n",
       "      <td>8.144324</td>\n",
       "      <td>-26.702099</td>\n",
       "      <td>241.207709</td>\n",
       "      <td>-12.695194</td>\n",
       "      <td>-79.573883</td>\n",
       "      <td>121.379307</td>\n",
       "      <td>-69.633950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441268</td>\n",
       "      <td>0.202706</td>\n",
       "      <td>...</td>\n",
       "      <td>12.556002</td>\n",
       "      <td>23.217834</td>\n",
       "      <td>3.162621</td>\n",
       "      <td>-18.980361</td>\n",
       "      <td>204.830682</td>\n",
       "      <td>-20.962017</td>\n",
       "      <td>-61.163222</td>\n",
       "      <td>122.543777</td>\n",
       "      <td>-26.694989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357972</td>\n",
       "      <td>0.422880</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.850837</td>\n",
       "      <td>12.314794</td>\n",
       "      <td>-3.387437</td>\n",
       "      <td>-5.403946</td>\n",
       "      <td>93.521862</td>\n",
       "      <td>4.187927</td>\n",
       "      <td>-35.880841</td>\n",
       "      <td>50.565405</td>\n",
       "      <td>-9.853733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684226</td>\n",
       "      <td>0.119763</td>\n",
       "      <td>...</td>\n",
       "      <td>68.287420</td>\n",
       "      <td>6.295047</td>\n",
       "      <td>37.820265</td>\n",
       "      <td>-33.841090</td>\n",
       "      <td>230.696114</td>\n",
       "      <td>-60.500167</td>\n",
       "      <td>-82.975793</td>\n",
       "      <td>174.224105</td>\n",
       "      <td>-111.569089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402629</td>\n",
       "      <td>0.070693</td>\n",
       "      <td>...</td>\n",
       "      <td>18.025175</td>\n",
       "      <td>13.675959</td>\n",
       "      <td>21.304353</td>\n",
       "      <td>-2.702105</td>\n",
       "      <td>162.972440</td>\n",
       "      <td>-8.209692</td>\n",
       "      <td>-46.736790</td>\n",
       "      <td>62.650600</td>\n",
       "      <td>-39.056701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Specie_Chicken  Specie_Dog  Specie_Human  Specie_Mouse  Specie_Pig  \\\n",
       "0               0           0             1             0           0   \n",
       "1               0           0             1             0           0   \n",
       "2               0           0             1             0           0   \n",
       "3               0           0             1             0           0   \n",
       "4               0           0             1             0           0   \n",
       "\n",
       "   Specie_Rat  Is_Ohnolog  Is_Paralog  Sequence-1 GC  Sequence-1 Length  ...  \\\n",
       "0           0           1         0.0       0.429090           0.115183  ...   \n",
       "1           0           1         0.0       0.441268           0.202706  ...   \n",
       "2           0           1         0.0       0.357972           0.422880  ...   \n",
       "3           0           1         0.0       0.684226           0.119763  ...   \n",
       "4           0           1         0.0       0.402629           0.070693  ...   \n",
       "\n",
       "   Embedding2_91  Embedding2_92  Embedding2_93  Embedding2_94  Embedding2_95  \\\n",
       "0      35.407509      23.369914       8.144324     -26.702099     241.207709   \n",
       "1      12.556002      23.217834       3.162621     -18.980361     204.830682   \n",
       "2      -6.850837      12.314794      -3.387437      -5.403946      93.521862   \n",
       "3      68.287420       6.295047      37.820265     -33.841090     230.696114   \n",
       "4      18.025175      13.675959      21.304353      -2.702105     162.972440   \n",
       "\n",
       "   Embedding2_96  Embedding2_97  Embedding2_98  Embedding2_99  Dup_Class  \n",
       "0     -12.695194     -79.573883     121.379307     -69.633950          1  \n",
       "1     -20.962017     -61.163222     122.543777     -26.694989          1  \n",
       "2       4.187927     -35.880841      50.565405      -9.853733          1  \n",
       "3     -60.500167     -82.975793     174.224105    -111.569089          1  \n",
       "4      -8.209692     -46.736790      62.650600     -39.056701          1  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = []\n",
    "for index, row in dataset_complete.iterrows():\n",
    "    if(row[\"Is_Ohnolog\"] == 1):\n",
    "        new_classes.append(1)\n",
    "    else:\n",
    "        if(row[\"Is_Paralog\"] == 0):\n",
    "            new_classes.append(0)\n",
    "        else:\n",
    "            new_classes.append(2)\n",
    "dataset_complete[\"Dup_Class\"] = new_classes\n",
    "dataset_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_columns = [\"Percent Identical Matches\",\"Aligment Length\",\"Nr Mismatch\",\"Nr Gap Open\",\"Evalue\",\"Bit Score\"]\n",
    "\n",
    "e_values_columns = [\"Evalue_Total\",\"Evalue_High\",\"Evalue_Medium\",\"Evalue_Low\"]\n",
    "\n",
    "blast_types = [\"High\",\"Medium\",\"Low\",\"Total\"]\n",
    "blast_col_Total = [i + \"_Total\" for i in blast_columns] \n",
    "blast_col_High = [i + \"_High\" for i in blast_columns]\n",
    "blast_col_Medium = [i + \"_Medium\" for i in blast_columns]\n",
    "blast_col_Low = [i + \"_Low\" for i in blast_columns]\n",
    "\n",
    "blast_cols_levels = blast_col_High + blast_col_Medium + blast_col_Low\n",
    "total_columns = (blast_col_High + blast_col_Medium + blast_col_Low + blast_col_Total + [\"Nr Hits\"])\n",
    "\n",
    "non_training_meta_features = [\"Sequence-1\",\"Sequence-2\",\"Sequence-1 Id\",\"Sequence-1-Transcript Id\",\"Sequence-2 Id\",\"Sequence-2-Transcript Id\",\"Sequence-1-Transcript-Version\",\"Sequence-2-Transcript-Version\"]\n",
    "\n",
    "sequence_1_metadata = [\"Sequence-1 GC\",\"Sequence-1 Length\",\"Sequence-1-Chromosome\",\"Seq-1-Biotype_protein_coding\"]\n",
    "sequence_2_metadata = [\"Sequence-2 GC\",\"Sequence-2 Length\",\"Sequence-2-Chromosome\",\"Seq-2-Biotype_protein_coding\"]\n",
    "\n",
    "sequence_1_metadata_diferential = [\"Sequence-1 GC\",\"Sequence-1 Length\"]\n",
    "sequence_2_metadata_diferential = [\"Sequence-2 GC\",\"Sequence-2 Length\"]\n",
    "\n",
    "sequence_1_metadata_categorical = [\"Sequence-1-Chromosome\",\"Seq-1-Biotype_protein_coding\"]\n",
    "sequence_2_metadata_categorical = [\"Sequence-2-Chromosome\",\"Seq-2-Biotype_protein_coding\"]\n",
    "\n",
    "species_metadata = [\"Specie_Chicken\",\"Specie_Dog\",\"Specie_Human\",\"Specie_Mouse\",\"Specie_Pig\",\"Specie_Rat\"]\n",
    "\n",
    "emb_size = 100\n",
    "if(type_chosen == \"cdna2\"):\n",
    "    emb_size = 200\n",
    "embedding_1_cols = [\"Embedding1_\" + str(i) for i in range(0,emb_size)]\n",
    "embedding_2_cols = [\"Embedding2_\" + str(i) for i in range(0,emb_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test(df):\n",
    "    df.sample(frac=1,random_state=7)\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2,random_state=9,stratify=df[\"Is_Ohnolog\"])\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2,random_state=3,stratify=df_train[\"Is_Ohnolog\"])\n",
    "    return (df_train,df_val,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_soft(df):\n",
    "    df.sample(frac=1,random_state=7)\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2,random_state=9,stratify=df[\"Dup_Class\"])\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2,random_state=3,stratify=df_train[\"Dup_Class\"])\n",
    "    return (df_train,df_val,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(log,name):\n",
    "    log_dict = log.history    \n",
    "    json.dump(log_dict, open(train_filepath + working_level + \"/model_run_history/\" + name + \".json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log(name):\n",
    "     return json.load(open(train_filepath + working_level + \"/model_run_history/\" + name + \".json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(keras.callbacks.Callback):\n",
    "    def __init__(self, display):\n",
    "        self.step = 0\n",
    "        self.display = display\n",
    "        self.metric_cache = {}        \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.step += 1\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
    "        if self.step % self.display == 0:\n",
    "            metrics_log_default = ''            \n",
    "            metrics_log_main = ''            \n",
    "            metrics_log_aux = ''            \n",
    "            for (k, v) in self.metric_cache.items():\n",
    "                val = v / self.display             \n",
    "                if(\"main\" in k):\n",
    "                    if abs(val) > 1e-3:\n",
    "                        metrics_log_main += ' - %s: %.4f' % (k, val)\n",
    "                        continue      \n",
    "                    else:\n",
    "                        metrics_log_main += ' - %s: %.4e' % (k, val)\n",
    "                        continue                    \n",
    "                        \n",
    "                if(\"aux\" in k): \n",
    "                    if abs(val) > 1e-3:\n",
    "                        metrics_log_aux += ' - %s: %.4f' % (k, val)\n",
    "                        continue      \n",
    "                    else:\n",
    "                        metrics_log_aux += ' - %s: %.4e' % (k, val)\n",
    "                        continue      \n",
    "                        \n",
    "                if abs(val) > 1e-3:\n",
    "                        metrics_log_default += ' - %s: %.4f' % (k, val)\n",
    "                else:\n",
    "                        metrics_log_default += ' - %s: %.4e' % (k, val)                        \n",
    "                    \n",
    "            print('step: {}/{} ... {}'.format(self.step,\n",
    "                                          self.params['epochs'],\n",
    "                                          metrics_log_default + \"\\n\" + metrics_log_main + \"\\n\" + metrics_log_aux))\n",
    "            self.metric_cache.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_level(model, log,x_test,x_emb_test,y_test,bs,metrics_used):\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([x_emb_test.values,x_test.values],[y_test.values,y_test.values], batch_size=bs,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')                \n",
    "    nr_metrics = len(metrics_used)\n",
    "    fig, axes = plt.subplots(2, nr_metrics, figsize=(18,8))   \n",
    "    \n",
    "    i = 0\n",
    "    for metric in metrics_used:\n",
    "        match_metrics = [model_metric.split('_')[0] for model_metric in metrics_names if metric in model_metric]\n",
    "        print(match_metrics)\n",
    "        if(metric == \"loss\"):\n",
    "            match_metrics.remove(\"loss\")\n",
    "        for match in match_metrics:        \n",
    "            if(i>=nr_metrics):\n",
    "                axes[1][i-nr_metrics].plot(log[match + \"_\" + metric], label=\"Train\")            \n",
    "                axes[1][i-nr_metrics].plot(log[\"val_\" + match + \"_\" + metric], label=\"Val\")       \n",
    "                axes[1][i-nr_metrics].set_xlabel('epoch'); \n",
    "                axes[1][i-nr_metrics].set_ylabel(metric + \"_\" + match)                            \n",
    "            else:\n",
    "                axes[0][i].plot(log[match + \"_\" + metric], label=\"Train\")            \n",
    "                axes[0][i].plot(log[\"val_\" + match + \"_\" + metric], label=\"Val\")       \n",
    "                axes[0][i].set_xlabel('epoch'); \n",
    "                axes[0][i].set_ylabel(metric + \"_\" + match)                            \n",
    "                \n",
    "            i += 1            \n",
    "    for ax in axes:\n",
    "        for a in ax:\n",
    "             a.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_level_RNN(model, log,x_test,x_emb_test,y_test,bs,metrics_used):\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([x_emb_test.values.reshape(x_emb_test.shape[0],x_emb_test.shape[1],1),x_test.values],[y_test.values,y_test.values], batch_size=bs,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')                \n",
    "    nr_metrics = len(metrics_used)\n",
    "    fig, axes = plt.subplots(2, nr_metrics, figsize=(18,8))   \n",
    "    \n",
    "    i = 0\n",
    "    for metric in metrics_used:\n",
    "        match_metrics = [model_metric.split('_')[0] for model_metric in metrics_names if metric in model_metric]\n",
    "        print(match_metrics)\n",
    "        if(metric == \"loss\"):\n",
    "            match_metrics.remove(\"loss\")\n",
    "        for match in match_metrics:        \n",
    "            if(i>=nr_metrics):\n",
    "                axes[1][i-nr_metrics].plot(log[match + \"_\" + metric], label=\"Train\")            \n",
    "                axes[1][i-nr_metrics].plot(log[\"val_\" + match + \"_\" + metric], label=\"Val\")       \n",
    "                axes[1][i-nr_metrics].set_xlabel('epoch'); \n",
    "                axes[1][i-nr_metrics].set_ylabel(metric + \"_\" + match)                            \n",
    "            else:\n",
    "                axes[0][i].plot(log[match + \"_\" + metric], label=\"Train\")            \n",
    "                axes[0][i].plot(log[\"val_\" + match + \"_\" + metric], label=\"Val\")       \n",
    "                axes[0][i].set_xlabel('epoch'); \n",
    "                axes[0][i].set_ylabel(metric + \"_\" + match)                            \n",
    "                \n",
    "            i += 1            \n",
    "    for ax in axes:\n",
    "        for a in ax:\n",
    "             a.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_model(df_meta_input,df_embeddings,name):    \n",
    "    input_embedding = Input(shape=(len(df_embeddings.columns),), name='embedding_input')        \n",
    "    emb_x = Dense(512, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.01))(input_embedding)    \n",
    "    emb_x = BatchNormalization()(emb_x)\n",
    "    emb_x = Dropout(0.4)(emb_x)\n",
    "    emb_x = Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_x)\n",
    "    emb_x = Dropout(0.4)(emb_x)\n",
    "    emb_x = Dense(256, activation='relu',use_bias = False,kernel_regularizer=regularizers.l2(0.01))(emb_x)    \n",
    "    emb_x = Dropout(0.3)(emb_x)\n",
    "    emb_x = BatchNormalization()(emb_x)\n",
    "    emb_x = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_x)\n",
    "    emb_x = Dropout(0.3)(emb_x)\n",
    "    emb_x = Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_x)    \n",
    "    emb_x = Dropout(0.3)(emb_x)\n",
    "    emb_x = Dense(32, activation='relu',use_bias = False)(emb_x)\n",
    "    emb_x = BatchNormalization()(emb_x)\n",
    "    emb_x = Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_x)        \n",
    "    emb_x_out = Dense(1, activation='sigmoid',name=\"aux\")(emb_x)\n",
    "    \n",
    "    \n",
    "    meta_input = Input(shape=(len(df_meta_input.columns),), name='meta_input')\n",
    "    x = keras.layers.concatenate([emb_x, meta_input])\n",
    "    x = Dense(128, activation='relu',use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)   \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.0005))(x)    \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(8, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.0005))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    predictions = Dense(1, activation='sigmoid',name=\"main\")(x)\n",
    "\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and three Dense layers                       \n",
    "    model_created = Model(inputs=[input_embedding, meta_input], outputs=[emb_x_out,predictions])\n",
    "    model_created.Name = name\n",
    "    return model_created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_model_soft(df_meta_input,df_embeddings,name):    \n",
    "    input_embedding = Input(shape=(len(df_embeddings.columns),), name='embedding_input')        \n",
    "    emb_x = Dense(512, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.01))(input_embedding)    \n",
    "    emb_x = BatchNormalization()(emb_x)\n",
    "    emb_x = Dropout(0.4)(emb_x)\n",
    "    emb_x = Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_x)\n",
    "    emb_x = Dropout(0.4)(emb_x)\n",
    "    emb_x = Dense(256, activation='relu',use_bias = False,kernel_regularizer=regularizers.l2(0.01))(emb_x)    \n",
    "    emb_x = Dropout(0.3)(emb_x)\n",
    "    emb_x = BatchNormalization()(emb_x)\n",
    "    emb_x = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_x)\n",
    "    emb_x = Dropout(0.3)(emb_x)\n",
    "    emb_x = Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_x)    \n",
    "    emb_x = Dropout(0.3)(emb_x)\n",
    "    emb_x = Dense(32, activation='relu',use_bias = False)(emb_x)\n",
    "    emb_x = BatchNormalization()(emb_x)\n",
    "    emb_x = Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_x)        \n",
    "    emb_x_out = Dense(3, activation='softmax',name=\"aux\")(emb_x)\n",
    "    \n",
    "    \n",
    "    meta_input = Input(shape=(len(df_meta_input.columns),), name='meta_input')\n",
    "    x = keras.layers.concatenate([emb_x, meta_input])\n",
    "    x = Dense(128, activation='relu',use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)   \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.0005))(x)    \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(8, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.0005))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    predictions = Dense(3, activation='softmax',name=\"main\")(x)\n",
    "\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and three Dense layers                       \n",
    "    model_created = Model(inputs=[input_embedding, meta_input], outputs=[emb_x_out,predictions])\n",
    "    model_created.Name = name\n",
    "    return model_created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_level(train_x,train_emb_x,train_y,val_x,val_emb_x,val_y,model_train,n_epochs,optimizer,batchsize,loss_weigths,verb):\n",
    "    tensorboard = TensorBoard(log_dir=train_filepath + working_level + \"/board_logs/\" + model_train.Name + \"-\" + \"-{}\".format(time()))\n",
    "    checkpoint = ModelCheckpoint(train_filepath + working_level + \"/model_checkpoints/{0}-check-{{epoch:02d}}-{{val_main_acc:.2f}}.hdf5\".format(model_train.Name),save_weights_only=True, period = int(n_epochs/5))\n",
    "    best_model_save = ModelCheckpoint(train_filepath + working_level + \"/model_checkpoints/{0}-best.hdf5\".format(model_train.Name), monitor='val_main_acc',save_weights_only=True,  save_best_only=True, mode='max')\n",
    "    logger = EpochLogger(display=50)\n",
    "\n",
    "    model_train.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy',km.binary_recall()],loss_weights=loss_weigths)\n",
    "    size = len(train_emb_x)\n",
    "    return model_train.fit([train_emb_x,train_x], y= [train_y,train_y],verbose = verb,validation_data=([val_emb_x,val_x],[val_y,val_y]),epochs = n_epochs,batch_size=batchsize,callbacks = [tensorboard,checkpoint,best_model_save,logger])  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_level_soft(train_x,train_emb_x,train_y,val_x,val_emb_x,val_y,model_train,n_epochs,optimizer,batchsize,loss_weigths,verb):\n",
    "    tensorboard = TensorBoard(log_dir=train_filepath + working_level + \"/board_logs/\" + model_train.Name + \"-\" + \"-{}\".format(time()))\n",
    "    checkpoint = ModelCheckpoint(train_filepath + working_level + \"/model_checkpoints/{0}-check-{{epoch:02d}}-{{val_main_acc:.2f}}.hdf5\".format(model_train.Name),save_weights_only=True, period = int(n_epochs/5))\n",
    "    best_model_save = ModelCheckpoint(train_filepath + working_level + \"/model_checkpoints/{0}-best.hdf5\".format(model_train.Name), monitor='val_main_acc',save_weights_only=True,  save_best_only=True, mode='max')\n",
    "    logger = EpochLogger(display=50)\n",
    "\n",
    "    model_train.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',km.sparse_categorical_recall()],loss_weights=loss_weigths)\n",
    "    size = len(train_emb_x)\n",
    "    return model_train.fit([train_emb_x,train_x], y= [train_y,train_y],verbose = verb,validation_data=([val_emb_x,val_x],[val_y,val_y]),epochs = n_epochs,batch_size=batchsize,callbacks = [tensorboard,checkpoint,best_model_save,logger])  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50/600 ...  - loss: 1.5250 - val_loss: 1.3687\n",
      " - main_loss: 0.3903 - main_acc: 0.8202 - main_recall: 0.6250 - val_main_loss: 0.3704 - val_main_acc: 0.8363 - val_main_recall: 0.6594\n",
      " - aux_loss: 0.5159 - aux_acc: 0.7143 - aux_recall: 0.6225 - val_aux_loss: 0.5042 - val_aux_acc: 0.7390 - val_aux_recall: 0.6435\n",
      "step: 100/600 ...  - loss: 0.4519 - val_loss: 0.4422\n",
      " - main_loss: 0.3249 - main_acc: 0.8589 - main_recall: 0.6438 - val_main_loss: 0.3203 - val_main_acc: 0.8578 - val_main_recall: 0.6701\n",
      " - aux_loss: 0.4986 - aux_acc: 0.7226 - aux_recall: 0.6408 - val_aux_loss: 0.4738 - val_aux_acc: 0.7437 - val_aux_recall: 0.6537\n",
      "step: 150/600 ...  - loss: 0.4240 - val_loss: 0.4215\n",
      " - main_loss: 0.3054 - main_acc: 0.8680 - main_recall: 0.6502 - val_main_loss: 0.3075 - val_main_acc: 0.8628 - val_main_recall: 0.6749\n",
      " - aux_loss: 0.4958 - aux_acc: 0.7239 - aux_recall: 0.6471 - val_aux_loss: 0.4728 - val_aux_acc: 0.7450 - val_aux_recall: 0.6583\n",
      "step: 200/600 ...  - loss: 0.4124 - val_loss: 0.4127\n",
      " - main_loss: 0.2947 - main_acc: 0.8725 - main_recall: 0.6523 - val_main_loss: 0.2998 - val_main_acc: 0.8663 - val_main_recall: 0.6793\n",
      " - aux_loss: 0.4963 - aux_acc: 0.7240 - aux_recall: 0.6492 - val_aux_loss: 0.4726 - val_aux_acc: 0.7448 - val_aux_recall: 0.6625\n",
      "step: 250/600 ...  - loss: 0.4029 - val_loss: 0.4080\n",
      " - main_loss: 0.2860 - main_acc: 0.8763 - main_recall: 0.6544 - val_main_loss: 0.2957 - val_main_acc: 0.8690 - val_main_recall: 0.6814\n",
      " - aux_loss: 0.4963 - aux_acc: 0.7239 - aux_recall: 0.6513 - val_aux_loss: 0.4730 - val_aux_acc: 0.7451 - val_aux_recall: 0.6644\n",
      "step: 300/600 ...  - loss: 0.3977 - val_loss: 0.4060\n",
      " - main_loss: 0.2808 - main_acc: 0.8786 - main_recall: 0.6557 - val_main_loss: 0.2937 - val_main_acc: 0.8698 - val_main_recall: 0.6817\n",
      " - aux_loss: 0.4963 - aux_acc: 0.7241 - aux_recall: 0.6526 - val_aux_loss: 0.4733 - val_aux_acc: 0.7452 - val_aux_recall: 0.6647\n",
      "step: 350/600 ...  - loss: 0.3928 - val_loss: 0.4045\n",
      " - main_loss: 0.2759 - main_acc: 0.8811 - main_recall: 0.6567 - val_main_loss: 0.2923 - val_main_acc: 0.8712 - val_main_recall: 0.6841\n",
      " - aux_loss: 0.4969 - aux_acc: 0.7241 - aux_recall: 0.6536 - val_aux_loss: 0.4738 - val_aux_acc: 0.7453 - val_aux_recall: 0.6672\n",
      "step: 400/600 ...  - loss: 0.3879 - val_loss: 0.4023\n",
      " - main_loss: 0.2712 - main_acc: 0.8830 - main_recall: 0.6582 - val_main_loss: 0.2902 - val_main_acc: 0.8721 - val_main_recall: 0.6840\n",
      " - aux_loss: 0.4961 - aux_acc: 0.7239 - aux_recall: 0.6549 - val_aux_loss: 0.4726 - val_aux_acc: 0.7446 - val_aux_recall: 0.6668\n",
      "step: 450/600 ...  - loss: 0.3851 - val_loss: 0.4033\n",
      " - main_loss: 0.2685 - main_acc: 0.8839 - main_recall: 0.6587 - val_main_loss: 0.2914 - val_main_acc: 0.8730 - val_main_recall: 0.6848\n",
      " - aux_loss: 0.4973 - aux_acc: 0.7241 - aux_recall: 0.6554 - val_aux_loss: 0.4738 - val_aux_acc: 0.7451 - val_aux_recall: 0.6677\n",
      "step: 500/600 ...  - loss: 0.3823 - val_loss: 0.4023\n",
      " - main_loss: 0.2656 - main_acc: 0.8856 - main_recall: 0.6595 - val_main_loss: 0.2902 - val_main_acc: 0.8726 - val_main_recall: 0.6841\n",
      " - aux_loss: 0.4974 - aux_acc: 0.7241 - aux_recall: 0.6563 - val_aux_loss: 0.4746 - val_aux_acc: 0.7448 - val_aux_recall: 0.6671\n",
      "step: 550/600 ...  - loss: 0.3801 - val_loss: 0.4030\n",
      " - main_loss: 0.2637 - main_acc: 0.8861 - main_recall: 0.6602 - val_main_loss: 0.2914 - val_main_acc: 0.8725 - val_main_recall: 0.6867\n",
      " - aux_loss: 0.4976 - aux_acc: 0.7242 - aux_recall: 0.6570 - val_aux_loss: 0.4741 - val_aux_acc: 0.7451 - val_aux_recall: 0.6692\n",
      "step: 600/600 ...  - loss: 0.3781 - val_loss: 0.4028\n",
      " - main_loss: 0.2615 - main_acc: 0.8872 - main_recall: 0.6602 - val_main_loss: 0.2910 - val_main_acc: 0.8723 - val_main_recall: 0.6837\n",
      " - aux_loss: 0.4983 - aux_acc: 0.7239 - aux_recall: 0.6569 - val_aux_loss: 0.4743 - val_aux_acc: 0.7453 - val_aux_recall: 0.6668\n",
      "Evaluando especie Test: Specie_Rat\n",
      "loss     = 0.4095\n",
      "aux_loss     = 0.4879\n",
      "main_loss     = 0.2950\n",
      "aux_acc     = 0.7340\n",
      "aux_recall     = 0.6753\n",
      "main_acc     = 0.8734\n",
      "main_recall     = 0.6794\n",
      "\n",
      "\n",
      "Evaluando especie sin balancear: Specie_Rat\n",
      "loss     = 0.8887\n",
      "aux_loss     = 1.6698\n",
      "main_loss     = 0.5378\n",
      "aux_acc     = 0.5412\n",
      "aux_recall     = 0.8479\n",
      "main_acc     = 0.7417\n",
      "main_recall     = 0.8479\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Rat\n",
      "loss     = 0.9076\n",
      "aux_loss     = 1.7789\n",
      "main_loss     = 0.5349\n",
      "aux_acc     = 0.5115\n",
      "aux_recall     = 0.8535\n",
      "main_acc     = 0.7436\n",
      "main_recall     = 0.8412\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "species_dict = {}\n",
    "for specie in species_metadata:\n",
    "    if(specie in [\"Specie_Chicken\",\"Specie_Dog\",\"Specie_Human\",\"Specie_Mouse\",\"Specie_Pig\"]):\n",
    "        continue\n",
    "        \n",
    "    dataset_complete_no_species = dataset_complete[dataset_complete[specie] == 0]    \n",
    "    dataset_complete_species = dataset_complete[dataset_complete[specie] == 1]    \n",
    "    \n",
    "    df_train,df_val,df_test = get_train_val_test(dataset_complete_no_species)\n",
    "    \n",
    "    df_train_x = df_train.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_train_x = df_train_x.drop(embedding_1_cols,axis=1)\n",
    "    df_train_x = df_train_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_train_emb_x = pd.concat([df_train[embedding_1_cols],df_train[embedding_2_cols]],axis=1,sort=False)\n",
    "    df_train_y = df_train[\"Is_Ohnolog\"]\n",
    "\n",
    "    df_val_x = df_val.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_val_x = df_val_x.drop(embedding_1_cols,axis=1)\n",
    "    df_val_x = df_val_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_val_emb_x = pd.concat([df_val[embedding_1_cols],df_val[embedding_2_cols]],axis=1,sort=False)\n",
    "    df_val_y = df_val[\"Is_Ohnolog\"]\n",
    "\n",
    "    df_test_x = df_test.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_x = df_test_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_x = df_test_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_emb_x =  pd.concat([df_test[embedding_1_cols],df_test[embedding_2_cols]],axis=1,sort=False)\n",
    "    df_test_y = df_test[\"Is_Ohnolog\"]\n",
    "    \n",
    "    model = level_model(df_train_x,df_train_emb_x,\"Level_model \" + specie)\n",
    "    \n",
    "    log = fit_model_level(df_train_x,df_train_emb_x,df_train_y,df_val_x,df_val_emb_x,df_val_y,model,600,Adamax(),256,[0.2,1],0)\n",
    "    \n",
    "    df_test_species_x = dataset_complete_species.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_species_emb_x =  pd.concat([dataset_complete_species[embedding_1_cols],dataset_complete_species[embedding_2_cols]],axis=1,sort=False)\n",
    "    df_test_species_y = dataset_complete_species[\"Is_Ohnolog\"]\n",
    "    \n",
    "    species_dict[specie] = {}\n",
    "    \n",
    "    print(\"Evaluando especie Test: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_emb_x.values,df_test_x.values],[df_test_y.values,df_test_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_dict[specie][\"Test\"] = metrics[5]\n",
    "            \n",
    "        \n",
    "    print(\"Evaluando especie sin balancear: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_species_emb_x.values,df_test_species_x.values],[df_test_species_y.values,df_test_species_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_dict[specie][\"Sin Balanceo\"] = metrics[5]\n",
    "    \n",
    "    df_species_ohnologs = dataset_complete_species[dataset_complete_species[\"Is_Ohnolog\"] == 1]\n",
    "    df_species_no_ohnologs = dataset_complete_species[dataset_complete_species[\"Is_Ohnolog\"] == 0]\n",
    "    \n",
    "    if(len(df_species_ohnologs)>len(df_species_no_ohnologs)):\n",
    "        df_species_new = df_species_no_ohnologs.append(df_species_ohnologs.sample(len(df_species_no_ohnologs)))        \n",
    "    else:\n",
    "        df_species_new = df_species_ohnologs.append(df_species_no_ohnologs.sample(len(df_species_ohnologs)))\n",
    "                 \n",
    "    if(len(df_species_new) == 0):\n",
    "        df_species_new = df_species_ohnologs\n",
    "        \n",
    "    df_test_species_x = df_species_new.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_species_emb_x =  pd.concat([df_species_new[embedding_1_cols],df_species_new[embedding_2_cols]],axis=1,sort=False)\n",
    "    df_test_species_y = df_species_new[\"Is_Ohnolog\"]    \n",
    "    \n",
    "    print(\"Evaluando especie balanceada: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_species_emb_x.values,df_test_species_x.values],[df_test_species_y.values,df_test_species_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_dict[specie][\"Balanceadas\"] = metrics[5]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Specie_Rat': {'Test': 0.8733780763293273,\n",
       "  'Sin Balanceo': 0.7416687553402656,\n",
       "  'Balanceadas': 0.7435828884017659}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando sin especie: Specie_Dog\n",
      "step: 50/150 ...  - loss: 1.9420 - val_loss: 1.7840\n",
      " - main_loss: 0.4532 - main_acc: 0.7884 - main_recall: 0.5635 - val_main_loss: 0.4332 - val_main_acc: 0.8038 - val_main_recall: 0.5704\n",
      " - aux_loss: 0.5818 - aux_acc: 0.6635 - aux_recall: 0.5613 - val_aux_loss: 0.5780 - val_aux_acc: 0.6690 - val_aux_recall: 0.5645\n",
      "step: 100/150 ...  - loss: 0.5249 - val_loss: 0.5220\n",
      " - main_loss: 0.3823 - main_acc: 0.8320 - main_recall: 0.6063 - val_main_loss: 0.3803 - val_main_acc: 0.8348 - val_main_recall: 0.6305\n",
      " - aux_loss: 0.5697 - aux_acc: 0.6688 - aux_recall: 0.6036 - val_aux_loss: 0.5658 - val_aux_acc: 0.6779 - val_aux_recall: 0.6248\n",
      "step: 150/150 ...  - loss: 0.4962 - val_loss: 0.4931\n",
      " - main_loss: 0.3631 - main_acc: 0.8409 - main_recall: 0.6105 - val_main_loss: 0.3608 - val_main_acc: 0.8426 - val_main_recall: 0.6471\n",
      " - aux_loss: 0.5671 - aux_acc: 0.6696 - aux_recall: 0.6079 - val_aux_loss: 0.5633 - val_aux_acc: 0.6772 - val_aux_recall: 0.6422\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 50/150 ...  - loss: 0.3936 - val_loss: 0.4071\n",
      " - main_loss: 0.2834 - main_acc: 0.8779 - main_recall: 0.7894 - val_main_loss: 0.2964 - val_main_acc: 0.8681 - val_main_recall: 0.7760\n",
      " - aux_loss: 0.4578 - aux_acc: 0.7296 - aux_recall: 0.7879 - val_aux_loss: 0.4612 - val_aux_acc: 0.7249 - val_aux_recall: 0.7709\n",
      "step: 100/150 ...  - loss: 0.3766 - val_loss: 0.3993\n",
      " - main_loss: 0.2696 - main_acc: 0.8839 - main_recall: 0.7980 - val_main_loss: 0.2915 - val_main_acc: 0.8690 - val_main_recall: 0.7832\n",
      " - aux_loss: 0.4561 - aux_acc: 0.7310 - aux_recall: 0.7965 - val_aux_loss: 0.4600 - val_aux_acc: 0.7262 - val_aux_recall: 0.7785\n",
      "step: 150/150 ...  - loss: 0.3700 - val_loss: 0.3962\n",
      " - main_loss: 0.2635 - main_acc: 0.8865 - main_recall: 0.7988 - val_main_loss: 0.2890 - val_main_acc: 0.8714 - val_main_recall: 0.7851\n",
      " - aux_loss: 0.4564 - aux_acc: 0.7305 - aux_recall: 0.7972 - val_aux_loss: 0.4597 - val_aux_acc: 0.7284 - val_aux_recall: 0.7803\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 50/150 ...  - loss: 0.4867 - val_loss: 0.4674\n",
      " - main_loss: 0.3533 - main_acc: 0.8468 - main_recall: 0.6065 - val_main_loss: 0.3358 - val_main_acc: 0.8555 - val_main_recall: 0.6246\n",
      " - aux_loss: 0.5765 - aux_acc: 0.6672 - aux_recall: 0.6058 - val_aux_loss: 0.5685 - val_aux_acc: 0.6818 - val_aux_recall: 0.6195\n",
      "step: 100/150 ...  - loss: 0.4709 - val_loss: 0.4596\n",
      " - main_loss: 0.3397 - main_acc: 0.8532 - main_recall: 0.6156 - val_main_loss: 0.3298 - val_main_acc: 0.8577 - val_main_recall: 0.6414\n",
      " - aux_loss: 0.5744 - aux_acc: 0.6691 - aux_recall: 0.6149 - val_aux_loss: 0.5679 - val_aux_acc: 0.6814 - val_aux_recall: 0.6365\n",
      "step: 150/150 ...  - loss: 0.4658 - val_loss: 0.4597\n",
      " - main_loss: 0.3343 - main_acc: 0.8558 - main_recall: 0.6200 - val_main_loss: 0.3299 - val_main_acc: 0.8576 - val_main_recall: 0.6539\n",
      " - aux_loss: 0.5745 - aux_acc: 0.6694 - aux_recall: 0.6194 - val_aux_loss: 0.5664 - val_aux_acc: 0.6862 - val_aux_recall: 0.6497\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 50/150 ...  - loss: 0.3716 - val_loss: 0.3691\n",
      " - main_loss: 0.2635 - main_acc: 0.8885 - main_recall: 0.8037 - val_main_loss: 0.2603 - val_main_acc: 0.8924 - val_main_recall: 0.8194\n",
      " - aux_loss: 0.4485 - aux_acc: 0.7466 - aux_recall: 0.8037 - val_aux_loss: 0.4533 - val_aux_acc: 0.7425 - val_aux_recall: 0.8170\n",
      "step: 100/150 ...  - loss: 0.3585 - val_loss: 0.3647\n",
      " - main_loss: 0.2522 - main_acc: 0.8925 - main_recall: 0.8047 - val_main_loss: 0.2573 - val_main_acc: 0.8931 - val_main_recall: 0.8220\n",
      " - aux_loss: 0.4455 - aux_acc: 0.7467 - aux_recall: 0.8047 - val_aux_loss: 0.4518 - val_aux_acc: 0.7412 - val_aux_recall: 0.8197\n",
      "step: 150/150 ...  - loss: 0.3542 - val_loss: 0.3628\n",
      " - main_loss: 0.2477 - main_acc: 0.8937 - main_recall: 0.8090 - val_main_loss: 0.2553 - val_main_acc: 0.8942 - val_main_recall: 0.8217\n",
      " - aux_loss: 0.4430 - aux_acc: 0.7489 - aux_recall: 0.8090 - val_aux_loss: 0.4483 - val_aux_acc: 0.7439 - val_aux_recall: 0.8195\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 50/150 ...  - loss: 0.3899 - val_loss: 0.3797\n",
      " - main_loss: 0.2754 - main_acc: 0.8807 - main_recall: 0.6908 - val_main_loss: 0.2673 - val_main_acc: 0.8899 - val_main_recall: 0.7031\n",
      " - aux_loss: 0.4775 - aux_acc: 0.7363 - aux_recall: 0.6907 - val_aux_loss: 0.4678 - val_aux_acc: 0.7445 - val_aux_recall: 0.6959\n",
      "step: 100/150 ...  - loss: 0.3809 - val_loss: 0.3797\n",
      " - main_loss: 0.2681 - main_acc: 0.8843 - main_recall: 0.6928 - val_main_loss: 0.2689 - val_main_acc: 0.8890 - val_main_recall: 0.7041\n",
      " - aux_loss: 0.4759 - aux_acc: 0.7381 - aux_recall: 0.6927 - val_aux_loss: 0.4662 - val_aux_acc: 0.7454 - val_aux_recall: 0.6969\n",
      "step: 150/150 ...  - loss: 0.3766 - val_loss: 0.3799\n",
      " - main_loss: 0.2649 - main_acc: 0.8858 - main_recall: 0.6911 - val_main_loss: 0.2702 - val_main_acc: 0.8888 - val_main_recall: 0.7013\n",
      " - aux_loss: 0.4755 - aux_acc: 0.7380 - aux_recall: 0.6910 - val_aux_loss: 0.4660 - val_aux_acc: 0.7447 - val_aux_recall: 0.6940\n",
      "Evaluando especie sin balancear: Specie_Chicken\n",
      "loss     = 0.9503\n",
      "aux_loss     = 2.1005\n",
      "main_loss     = 0.5132\n",
      "aux_acc     = 0.4490\n",
      "aux_recall     = 0.9190\n",
      "main_acc     = 0.8183\n",
      "main_recall     = 0.9190\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Chicken\n",
      "loss     = 0.8010\n",
      "aux_loss     = 1.6143\n",
      "main_loss     = 0.4611\n",
      "aux_acc     = 0.5696\n",
      "aux_recall     = 0.9190\n",
      "main_acc     = 0.8295\n",
      "main_recall     = 0.9190\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 50/150 ...  - loss: 1.7678 - val_loss: 1.6114\n",
      " - main_loss: 0.4551 - main_acc: 0.7856 - main_recall: 0.5779 - val_main_loss: 0.4364 - val_main_acc: 0.8028 - val_main_recall: 0.6014\n",
      " - aux_loss: 0.5811 - aux_acc: 0.6651 - aux_recall: 0.5759 - val_aux_loss: 0.5787 - val_aux_acc: 0.6773 - val_aux_recall: 0.5956\n",
      "step: 100/150 ...  - loss: 0.5217 - val_loss: 0.5186\n",
      " - main_loss: 0.3804 - main_acc: 0.8331 - main_recall: 0.5941 - val_main_loss: 0.3784 - val_main_acc: 0.8361 - val_main_recall: 0.6243\n",
      " - aux_loss: 0.5710 - aux_acc: 0.6680 - aux_recall: 0.5914 - val_aux_loss: 0.5667 - val_aux_acc: 0.6761 - val_aux_recall: 0.6183\n",
      "step: 150/150 ...  - loss: 0.4947 - val_loss: 0.4934\n",
      " - main_loss: 0.3623 - main_acc: 0.8409 - main_recall: 0.6108 - val_main_loss: 0.3619 - val_main_acc: 0.8422 - val_main_recall: 0.6295\n",
      " - aux_loss: 0.5684 - aux_acc: 0.6682 - aux_recall: 0.6083 - val_aux_loss: 0.5642 - val_aux_acc: 0.6788 - val_aux_recall: 0.6235\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 50/150 ...  - loss: 0.4575 - val_loss: 0.4546\n",
      " - main_loss: 0.3299 - main_acc: 0.8583 - main_recall: 0.6969 - val_main_loss: 0.3273 - val_main_acc: 0.8575 - val_main_recall: 0.7120\n",
      " - aux_loss: 0.5477 - aux_acc: 0.6790 - aux_recall: 0.6941 - val_aux_loss: 0.5471 - val_aux_acc: 0.6848 - val_aux_recall: 0.7062\n",
      "step: 100/150 ...  - loss: 0.4416 - val_loss: 0.4487\n",
      " - main_loss: 0.3150 - main_acc: 0.8647 - main_recall: 0.6960 - val_main_loss: 0.3224 - val_main_acc: 0.8602 - val_main_recall: 0.7188\n",
      " - aux_loss: 0.5470 - aux_acc: 0.6784 - aux_recall: 0.6930 - val_aux_loss: 0.5455 - val_aux_acc: 0.6852 - val_aux_recall: 0.7129\n",
      "step: 150/150 ...  - loss: 0.4335 - val_loss: 0.4479\n",
      " - main_loss: 0.3069 - main_acc: 0.8687 - main_recall: 0.7048 - val_main_loss: 0.3213 - val_main_acc: 0.8609 - val_main_recall: 0.7096\n",
      " - aux_loss: 0.5463 - aux_acc: 0.6792 - aux_recall: 0.7017 - val_aux_loss: 0.5459 - val_aux_acc: 0.6818 - val_aux_recall: 0.7030\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 50/150 ...  - loss: 0.5268 - val_loss: 0.5266\n",
      " - main_loss: 0.3797 - main_acc: 0.8367 - main_recall: 0.4908 - val_main_loss: 0.3797 - val_main_acc: 0.8345 - val_main_recall: 0.4779\n",
      " - aux_loss: 0.6395 - aux_acc: 0.6326 - aux_recall: 0.4889 - val_aux_loss: 0.6396 - val_aux_acc: 0.6394 - val_aux_recall: 0.4703\n",
      "step: 100/150 ...  - loss: 0.5108 - val_loss: 0.5224\n",
      " - main_loss: 0.3657 - main_acc: 0.8425 - main_recall: 0.5040 - val_main_loss: 0.3770 - val_main_acc: 0.8353 - val_main_recall: 0.5131\n",
      " - aux_loss: 0.6377 - aux_acc: 0.6352 - aux_recall: 0.5021 - val_aux_loss: 0.6398 - val_aux_acc: 0.6424 - val_aux_recall: 0.5067\n",
      "step: 150/150 ...  - loss: 0.5050 - val_loss: 0.5204\n",
      " - main_loss: 0.3596 - main_acc: 0.8447 - main_recall: 0.5039 - val_main_loss: 0.3746 - val_main_acc: 0.8361 - val_main_recall: 0.5207\n",
      " - aux_loss: 0.6377 - aux_acc: 0.6350 - aux_recall: 0.5021 - val_aux_loss: 0.6403 - val_aux_acc: 0.6407 - val_aux_recall: 0.5145\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 50/150 ...  - loss: 0.4324 - val_loss: 0.4345\n",
      " - main_loss: 0.3038 - main_acc: 0.8696 - main_recall: 0.6999 - val_main_loss: 0.2928 - val_main_acc: 0.8791 - val_main_recall: 0.8784\n",
      " - aux_loss: 0.5419 - aux_acc: 0.6902 - aux_recall: 0.6993 - val_aux_loss: 0.6079 - val_aux_acc: 0.6432 - val_aux_recall: 0.8784\n",
      "step: 100/150 ...  - loss: 0.4198 - val_loss: 0.4384\n",
      " - main_loss: 0.2935 - main_acc: 0.8735 - main_recall: 0.7060 - val_main_loss: 0.2956 - val_main_acc: 0.8791 - val_main_recall: 0.9042\n",
      " - aux_loss: 0.5357 - aux_acc: 0.6908 - aux_recall: 0.7053 - val_aux_loss: 0.6184 - val_aux_acc: 0.6218 - val_aux_recall: 0.9048\n",
      "step: 150/150 ...  - loss: 0.4157 - val_loss: 0.4357\n",
      " - main_loss: 0.2892 - main_acc: 0.8750 - main_recall: 0.7131 - val_main_loss: 0.2971 - val_main_acc: 0.8784 - val_main_recall: 0.8954\n",
      " - aux_loss: 0.5350 - aux_acc: 0.6928 - aux_recall: 0.7124 - val_aux_loss: 0.5956 - val_aux_acc: 0.6294 - val_aux_recall: 0.8959\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 50/150 ...  - loss: 0.4332 - val_loss: 0.4490\n",
      " - main_loss: 0.3046 - main_acc: 0.8680 - main_recall: 0.5757 - val_main_loss: 0.3065 - val_main_acc: 0.8690 - val_main_recall: 0.8215\n",
      " - aux_loss: 0.5510 - aux_acc: 0.6971 - aux_recall: 0.5748 - val_aux_loss: 0.6213 - val_aux_acc: 0.5861 - val_aux_recall: 0.8216\n",
      "step: 100/150 ...  - loss: 0.4246 - val_loss: 0.4466\n",
      " - main_loss: 0.2969 - main_acc: 0.8710 - main_recall: 0.5773 - val_main_loss: 0.3077 - val_main_acc: 0.8689 - val_main_recall: 0.7893\n",
      " - aux_loss: 0.5505 - aux_acc: 0.6976 - aux_recall: 0.5764 - val_aux_loss: 0.6067 - val_aux_acc: 0.6192 - val_aux_recall: 0.7880\n",
      "step: 150/150 ...  - loss: 0.4201 - val_loss: 0.4460\n",
      " - main_loss: 0.2926 - main_acc: 0.8727 - main_recall: 0.5755 - val_main_loss: 0.3080 - val_main_acc: 0.8695 - val_main_recall: 0.7869\n",
      " - aux_loss: 0.5499 - aux_acc: 0.6976 - aux_recall: 0.5746 - val_aux_loss: 0.6029 - val_aux_acc: 0.6242 - val_aux_recall: 0.7859\n",
      "Evaluando especie sin balancear: Specie_Dog\n",
      "loss     = 0.7309\n",
      "aux_loss     = 0.5272\n",
      "main_loss     = 0.6083\n",
      "aux_acc     = 0.7258\n",
      "aux_recall     = 0.7268\n",
      "main_acc     = 0.7151\n",
      "main_recall     = 0.7209\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Dog\n",
      "loss     = 0.7309\n",
      "aux_loss     = 0.5272\n",
      "main_loss     = 0.6083\n",
      "aux_acc     = 0.7258\n",
      "aux_recall     = 0.7268\n",
      "main_acc     = 0.7151\n",
      "main_recall     = 0.7209\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 50/150 ...  - loss: 1.8240 - val_loss: 1.6775\n",
      " - main_loss: 0.3802 - main_acc: 0.8279 - main_recall: 0.7718 - val_main_loss: 0.3697 - val_main_acc: 0.8338 - val_main_recall: 0.7795\n",
      " - aux_loss: 0.4810 - aux_acc: 0.7174 - aux_recall: 0.7704 - val_aux_loss: 0.4889 - val_aux_acc: 0.7163 - val_aux_recall: 0.7747\n",
      "step: 100/150 ...  - loss: 0.4387 - val_loss: 0.4528\n",
      " - main_loss: 0.3074 - main_acc: 0.8671 - main_recall: 0.7828 - val_main_loss: 0.3212 - val_main_acc: 0.8576 - val_main_recall: 0.7731\n",
      " - aux_loss: 0.4630 - aux_acc: 0.7218 - aux_recall: 0.7813 - val_aux_loss: 0.4669 - val_aux_acc: 0.7193 - val_aux_recall: 0.7682\n",
      "step: 150/150 ...  - loss: 0.4054 - val_loss: 0.4238\n",
      " - main_loss: 0.2895 - main_acc: 0.8745 - main_recall: 0.7877 - val_main_loss: 0.3074 - val_main_acc: 0.8639 - val_main_recall: 0.7862\n",
      " - aux_loss: 0.4635 - aux_acc: 0.7163 - aux_recall: 0.7863 - val_aux_loss: 0.4661 - val_aux_acc: 0.7148 - val_aux_recall: 0.7818\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 50/150 ...  - loss: 0.4724 - val_loss: 0.4694\n",
      " - main_loss: 0.3393 - main_acc: 0.8540 - main_recall: 0.6775 - val_main_loss: 0.3365 - val_main_acc: 0.8530 - val_main_recall: 0.6682\n",
      " - aux_loss: 0.5542 - aux_acc: 0.6639 - aux_recall: 0.6743 - val_aux_loss: 0.5540 - val_aux_acc: 0.6702 - val_aux_recall: 0.6601\n",
      "step: 100/150 ...  - loss: 0.4536 - val_loss: 0.4594\n",
      " - main_loss: 0.3238 - main_acc: 0.8607 - main_recall: 0.6928 - val_main_loss: 0.3297 - val_main_acc: 0.8564 - val_main_recall: 0.6938\n",
      " - aux_loss: 0.5515 - aux_acc: 0.6679 - aux_recall: 0.6897 - val_aux_loss: 0.5509 - val_aux_acc: 0.6749 - val_aux_recall: 0.6861\n",
      "step: 150/150 ...  - loss: 0.4451 - val_loss: 0.4571\n",
      " - main_loss: 0.3163 - main_acc: 0.8631 - main_recall: 0.6938 - val_main_loss: 0.3284 - val_main_acc: 0.8565 - val_main_recall: 0.6953\n",
      " - aux_loss: 0.5496 - aux_acc: 0.6691 - aux_recall: 0.6907 - val_aux_loss: 0.5491 - val_aux_acc: 0.6766 - val_aux_recall: 0.6876\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 50/150 ...  - loss: 0.4482 - val_loss: 0.4663\n",
      " - main_loss: 0.3145 - main_acc: 0.8646 - main_recall: 0.6888 - val_main_loss: 0.3331 - val_main_acc: 0.8539 - val_main_recall: 0.6759\n",
      " - aux_loss: 0.5605 - aux_acc: 0.6652 - aux_recall: 0.6877 - val_aux_loss: 0.5591 - val_aux_acc: 0.6717 - val_aux_recall: 0.6708\n",
      "step: 100/150 ...  - loss: 0.4375 - val_loss: 0.4609\n",
      " - main_loss: 0.3074 - main_acc: 0.8676 - main_recall: 0.6879 - val_main_loss: 0.3311 - val_main_acc: 0.8544 - val_main_recall: 0.6788\n",
      " - aux_loss: 0.5579 - aux_acc: 0.6686 - aux_recall: 0.6869 - val_aux_loss: 0.5565 - val_aux_acc: 0.6749 - val_aux_recall: 0.6736\n",
      "step: 150/150 ...  - loss: 0.4332 - val_loss: 0.4598\n",
      " - main_loss: 0.3039 - main_acc: 0.8690 - main_recall: 0.6918 - val_main_loss: 0.3306 - val_main_acc: 0.8560 - val_main_recall: 0.6845\n",
      " - aux_loss: 0.5551 - aux_acc: 0.6761 - aux_recall: 0.6908 - val_aux_loss: 0.5544 - val_aux_acc: 0.6805 - val_aux_recall: 0.6790\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 50/150 ...  - loss: 0.2982 - val_loss: 0.3048\n",
      " - main_loss: 0.2041 - main_acc: 0.9149 - main_recall: 0.8964 - val_main_loss: 0.2095 - val_main_acc: 0.9138 - val_main_recall: 0.9044\n",
      " - aux_loss: 0.3679 - aux_acc: 0.7857 - aux_recall: 0.8963 - val_aux_loss: 0.3752 - val_aux_acc: 0.7907 - val_aux_recall: 0.9043\n",
      "step: 100/150 ...  - loss: 0.2788 - val_loss: 0.2944\n",
      " - main_loss: 0.1893 - main_acc: 0.9199 - main_recall: 0.9026 - val_main_loss: 0.2029 - val_main_acc: 0.9154 - val_main_recall: 0.9025\n",
      " - aux_loss: 0.3632 - aux_acc: 0.7883 - aux_recall: 0.9025 - val_aux_loss: 0.3734 - val_aux_acc: 0.7871 - val_aux_recall: 0.9023\n",
      "step: 150/150 ...  - loss: 0.2732 - val_loss: 0.2949\n",
      " - main_loss: 0.1838 - main_acc: 0.9224 - main_recall: 0.9041 - val_main_loss: 0.2038 - val_main_acc: 0.9137 - val_main_recall: 0.8915\n",
      " - aux_loss: 0.3634 - aux_acc: 0.7889 - aux_recall: 0.9039 - val_aux_loss: 0.3722 - val_aux_acc: 0.7924 - val_aux_recall: 0.8914\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 50/150 ...  - loss: 0.3331 - val_loss: 0.3373\n",
      " - main_loss: 0.2333 - main_acc: 0.9006 - main_recall: 0.7574 - val_main_loss: 0.2368 - val_main_acc: 0.8957 - val_main_recall: 0.7474\n",
      " - aux_loss: 0.4223 - aux_acc: 0.7662 - aux_recall: 0.7571 - val_aux_loss: 0.4267 - val_aux_acc: 0.7576 - val_aux_recall: 0.7418\n",
      "step: 100/150 ...  - loss: 0.3203 - val_loss: 0.3352\n",
      " - main_loss: 0.2218 - main_acc: 0.9059 - main_recall: 0.7585 - val_main_loss: 0.2359 - val_main_acc: 0.8962 - val_main_recall: 0.7491\n",
      " - aux_loss: 0.4215 - aux_acc: 0.7670 - aux_recall: 0.7581 - val_aux_loss: 0.4263 - val_aux_acc: 0.7584 - val_aux_recall: 0.7435\n",
      "step: 150/150 ...  - loss: 0.3153 - val_loss: 0.3369\n",
      " - main_loss: 0.2165 - main_acc: 0.9082 - main_recall: 0.7598 - val_main_loss: 0.2373 - val_main_acc: 0.8955 - val_main_recall: 0.7500\n",
      " - aux_loss: 0.4224 - aux_acc: 0.7671 - aux_recall: 0.7594 - val_aux_loss: 0.4268 - val_aux_acc: 0.7593 - val_aux_recall: 0.7445\n",
      "Evaluando especie sin balancear: Specie_Human\n",
      "loss     = 1.1808\n",
      "aux_loss     = 1.9833\n",
      "main_loss     = 0.7700\n",
      "aux_acc     = 0.3728\n",
      "aux_recall     = 0.8414\n",
      "main_acc     = 0.7562\n",
      "main_recall     = 0.8414\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Human\n",
      "loss     = 0.9984\n",
      "aux_loss     = 1.5316\n",
      "main_loss     = 0.6780\n",
      "aux_acc     = 0.5019\n",
      "aux_recall     = 0.8414\n",
      "main_acc     = 0.7606\n",
      "main_recall     = 0.8414\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 50/150 ...  - loss: 2.2017 - val_loss: 2.0353\n",
      " - main_loss: 0.4782 - main_acc: 0.7730 - main_recall: 0.5546 - val_main_loss: 0.4508 - val_main_acc: 0.7926 - val_main_recall: 0.5314\n",
      " - aux_loss: 0.5975 - aux_acc: 0.6554 - aux_recall: 0.5540 - val_aux_loss: 0.5939 - val_aux_acc: 0.6632 - val_aux_recall: 0.5255\n",
      "step: 100/150 ...  - loss: 0.5455 - val_loss: 0.5367\n",
      " - main_loss: 0.3957 - main_acc: 0.8254 - main_recall: 0.5860 - val_main_loss: 0.3885 - val_main_acc: 0.8322 - val_main_recall: 0.6166\n",
      " - aux_loss: 0.5790 - aux_acc: 0.6655 - aux_recall: 0.5853 - val_aux_loss: 0.5725 - val_aux_acc: 0.6761 - val_aux_recall: 0.6113\n",
      "step: 150/150 ...  - loss: 0.5083 - val_loss: 0.5002\n",
      " - main_loss: 0.3720 - main_acc: 0.8362 - main_recall: 0.6028 - val_main_loss: 0.3651 - val_main_acc: 0.8421 - val_main_recall: 0.6278\n",
      " - aux_loss: 0.5756 - aux_acc: 0.6673 - aux_recall: 0.6021 - val_aux_loss: 0.5699 - val_aux_acc: 0.6785 - val_aux_recall: 0.6226\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 50/150 ...  - loss: 0.5414 - val_loss: 0.5440\n",
      " - main_loss: 0.3948 - main_acc: 0.8293 - main_recall: 0.4743 - val_main_loss: 0.3978 - val_main_acc: 0.8258 - val_main_recall: 0.4607\n",
      " - aux_loss: 0.6379 - aux_acc: 0.6329 - aux_recall: 0.4723 - val_aux_loss: 0.6368 - val_aux_acc: 0.6376 - val_aux_recall: 0.4527\n",
      "step: 100/150 ...  - loss: 0.5245 - val_loss: 0.5322\n",
      " - main_loss: 0.3792 - main_acc: 0.8360 - main_recall: 0.4852 - val_main_loss: 0.3872 - val_main_acc: 0.8297 - val_main_recall: 0.4689\n",
      " - aux_loss: 0.6370 - aux_acc: 0.6321 - aux_recall: 0.4834 - val_aux_loss: 0.6358 - val_aux_acc: 0.6417 - val_aux_recall: 0.4610\n",
      "step: 150/150 ...  - loss: 0.5167 - val_loss: 0.5303\n",
      " - main_loss: 0.3715 - main_acc: 0.8395 - main_recall: 0.4903 - val_main_loss: 0.3849 - val_main_acc: 0.8311 - val_main_recall: 0.4745\n",
      " - aux_loss: 0.6373 - aux_acc: 0.6327 - aux_recall: 0.4883 - val_aux_loss: 0.6380 - val_aux_acc: 0.6394 - val_aux_recall: 0.4667\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 50/150 ...  - loss: 0.4509 - val_loss: 0.4523\n",
      " - main_loss: 0.3188 - main_acc: 0.8643 - main_recall: 0.7081 - val_main_loss: 0.3197 - val_main_acc: 0.8627 - val_main_recall: 0.7582\n",
      " - aux_loss: 0.5627 - aux_acc: 0.6727 - aux_recall: 0.7072 - val_aux_loss: 0.5658 - val_aux_acc: 0.6760 - val_aux_recall: 0.7540\n",
      "step: 100/150 ...  - loss: 0.4375 - val_loss: 0.4494\n",
      " - main_loss: 0.3078 - main_acc: 0.8683 - main_recall: 0.7074 - val_main_loss: 0.3194 - val_main_acc: 0.8642 - val_main_recall: 0.7647\n",
      " - aux_loss: 0.5590 - aux_acc: 0.6745 - aux_recall: 0.7065 - val_aux_loss: 0.5605 - val_aux_acc: 0.6739 - val_aux_recall: 0.7610\n",
      "step: 150/150 ...  - loss: 0.4319 - val_loss: 0.4489\n",
      " - main_loss: 0.3024 - main_acc: 0.8705 - main_recall: 0.7139 - val_main_loss: 0.3193 - val_main_acc: 0.8630 - val_main_recall: 0.7582\n",
      " - aux_loss: 0.5577 - aux_acc: 0.6764 - aux_recall: 0.7129 - val_aux_loss: 0.5586 - val_aux_acc: 0.6766 - val_aux_recall: 0.7542\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 50/150 ...  - loss: 0.4447 - val_loss: 0.4346\n",
      " - main_loss: 0.3154 - main_acc: 0.8637 - main_recall: 0.7028 - val_main_loss: 0.3045 - val_main_acc: 0.8737 - val_main_recall: 0.7879\n",
      " - aux_loss: 0.5459 - aux_acc: 0.6882 - aux_recall: 0.7012 - val_aux_loss: 0.5503 - val_aux_acc: 0.6827 - val_aux_recall: 0.7867\n",
      "step: 100/150 ...  - loss: 0.4323 - val_loss: 0.4330\n",
      " - main_loss: 0.3043 - main_acc: 0.8693 - main_recall: 0.7114 - val_main_loss: 0.3038 - val_main_acc: 0.8744 - val_main_recall: 0.8097\n",
      " - aux_loss: 0.5434 - aux_acc: 0.6887 - aux_recall: 0.7101 - val_aux_loss: 0.5499 - val_aux_acc: 0.6772 - val_aux_recall: 0.8088\n",
      "step: 150/150 ...  - loss: 0.4271 - val_loss: 0.4334\n",
      " - main_loss: 0.2990 - main_acc: 0.8713 - main_recall: 0.7113 - val_main_loss: 0.3039 - val_main_acc: 0.8747 - val_main_recall: 0.8000\n",
      " - aux_loss: 0.5432 - aux_acc: 0.6884 - aux_recall: 0.7097 - val_aux_loss: 0.5501 - val_aux_acc: 0.6791 - val_aux_recall: 0.7991\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 50/150 ...  - loss: 0.4426 - val_loss: 0.4407\n",
      " - main_loss: 0.3131 - main_acc: 0.8645 - main_recall: 0.5653 - val_main_loss: 0.3109 - val_main_acc: 0.8675 - val_main_recall: 0.5713\n",
      " - aux_loss: 0.5576 - aux_acc: 0.6925 - aux_recall: 0.5629 - val_aux_loss: 0.5601 - val_aux_acc: 0.6988 - val_aux_recall: 0.5644\n",
      "step: 100/150 ...  - loss: 0.4334 - val_loss: 0.4415\n",
      " - main_loss: 0.3048 - main_acc: 0.8684 - main_recall: 0.5628 - val_main_loss: 0.3125 - val_main_acc: 0.8673 - val_main_recall: 0.5657\n",
      " - aux_loss: 0.5576 - aux_acc: 0.6927 - aux_recall: 0.5604 - val_aux_loss: 0.5592 - val_aux_acc: 0.6979 - val_aux_recall: 0.5587\n",
      "step: 150/150 ...  - loss: 0.4290 - val_loss: 0.4433\n",
      " - main_loss: 0.3004 - main_acc: 0.8702 - main_recall: 0.5639 - val_main_loss: 0.3142 - val_main_acc: 0.8663 - val_main_recall: 0.5678\n",
      " - aux_loss: 0.5574 - aux_acc: 0.6925 - aux_recall: 0.5614 - val_aux_loss: 0.5596 - val_aux_acc: 0.6981 - val_aux_recall: 0.5607\n",
      "Evaluando especie sin balancear: Specie_Mouse\n",
      "loss     = 0.5903\n",
      "aux_loss     = 0.8684\n",
      "main_loss     = 0.3995\n",
      "aux_acc     = 0.0000\n",
      "aux_recall     = 0.3995\n",
      "main_acc     = 0.8073\n",
      "main_recall     = 0.4099\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Mouse\n",
      "loss     = 0.5903\n",
      "aux_loss     = 0.8684\n",
      "main_loss     = 0.3995\n",
      "aux_acc     = 0.0000\n",
      "aux_recall     = 0.3995\n",
      "main_acc     = 0.8073\n",
      "main_recall     = 0.4099\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 50/150 ...  - loss: 3.3391 - val_loss: 3.1557\n",
      " - main_loss: 0.4276 - main_acc: 0.7907 - main_recall: 0.7246 - val_main_loss: 0.3828 - val_main_acc: 0.8181 - val_main_recall: 0.7299\n",
      " - aux_loss: 0.4725 - aux_acc: 0.7333 - aux_recall: 0.7245 - val_aux_loss: 0.4703 - val_aux_acc: 0.7321 - val_aux_recall: 0.7288\n",
      "step: 100/150 ...  - loss: 0.6278 - val_loss: 0.6164\n",
      " - main_loss: 0.3377 - main_acc: 0.8510 - main_recall: 0.7886 - val_main_loss: 0.3285 - val_main_acc: 0.8549 - val_main_recall: 0.8009\n",
      " - aux_loss: 0.4451 - aux_acc: 0.7496 - aux_recall: 0.7885 - val_aux_loss: 0.4548 - val_aux_acc: 0.7389 - val_aux_recall: 0.7994\n",
      "step: 150/150 ...  - loss: 0.4867 - val_loss: 0.4860\n",
      " - main_loss: 0.3227 - main_acc: 0.8575 - main_recall: 0.7846 - val_main_loss: 0.3200 - val_main_acc: 0.8603 - val_main_recall: 0.7891\n",
      " - aux_loss: 0.4428 - aux_acc: 0.7496 - aux_recall: 0.7846 - val_aux_loss: 0.4556 - val_aux_acc: 0.7394 - val_aux_recall: 0.7873\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 50/150 ...  - loss: 0.5161 - val_loss: 0.4952\n",
      " - main_loss: 0.3677 - main_acc: 0.8382 - main_recall: 0.6843 - val_main_loss: 0.3470 - val_main_acc: 0.8543 - val_main_recall: 0.7273\n",
      " - aux_loss: 0.5334 - aux_acc: 0.6958 - aux_recall: 0.6837 - val_aux_loss: 0.5353 - val_aux_acc: 0.6990 - val_aux_recall: 0.7255\n",
      "step: 100/150 ...  - loss: 0.4767 - val_loss: 0.4672\n",
      " - main_loss: 0.3442 - main_acc: 0.8495 - main_recall: 0.6883 - val_main_loss: 0.3347 - val_main_acc: 0.8585 - val_main_recall: 0.7177\n",
      " - aux_loss: 0.5308 - aux_acc: 0.6939 - aux_recall: 0.6877 - val_aux_loss: 0.5315 - val_aux_acc: 0.6957 - val_aux_recall: 0.7157\n",
      "step: 150/150 ...  - loss: 0.4601 - val_loss: 0.4555\n",
      " - main_loss: 0.3315 - main_acc: 0.8551 - main_recall: 0.7010 - val_main_loss: 0.3266 - val_main_acc: 0.8626 - val_main_recall: 0.7250\n",
      " - aux_loss: 0.5296 - aux_acc: 0.6970 - aux_recall: 0.7004 - val_aux_loss: 0.5315 - val_aux_acc: 0.6972 - val_aux_recall: 0.7231\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 50/150 ...  - loss: 0.3161 - val_loss: 0.3239\n",
      " - main_loss: 0.2205 - main_acc: 0.9079 - main_recall: 0.8912 - val_main_loss: 0.2272 - val_main_acc: 0.9033 - val_main_recall: 0.9010\n",
      " - aux_loss: 0.3680 - aux_acc: 0.7850 - aux_recall: 0.8911 - val_aux_loss: 0.3746 - val_aux_acc: 0.7876 - val_aux_recall: 0.9009\n",
      "step: 100/150 ...  - loss: 0.2948 - val_loss: 0.3119\n",
      " - main_loss: 0.2040 - main_acc: 0.9122 - main_recall: 0.8992 - val_main_loss: 0.2197 - val_main_acc: 0.9068 - val_main_recall: 0.8991\n",
      " - aux_loss: 0.3635 - aux_acc: 0.7891 - aux_recall: 0.8991 - val_aux_loss: 0.3711 - val_aux_acc: 0.7922 - val_aux_recall: 0.8990\n",
      "step: 150/150 ...  - loss: 0.2873 - val_loss: 0.3102\n",
      " - main_loss: 0.1975 - main_acc: 0.9158 - main_recall: 0.9066 - val_main_loss: 0.2185 - val_main_acc: 0.9078 - val_main_recall: 0.9030\n",
      " - aux_loss: 0.3609 - aux_acc: 0.7917 - aux_recall: 0.9065 - val_aux_loss: 0.3706 - val_aux_acc: 0.7921 - val_aux_recall: 0.9029\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 50/150 ...  - loss: 0.4656 - val_loss: 0.4541\n",
      " - main_loss: 0.3348 - main_acc: 0.8544 - main_recall: 0.6786 - val_main_loss: 0.3242 - val_main_acc: 0.8625 - val_main_recall: 0.6975\n",
      " - aux_loss: 0.5454 - aux_acc: 0.6848 - aux_recall: 0.6768 - val_aux_loss: 0.5416 - val_aux_acc: 0.6898 - val_aux_recall: 0.6955\n",
      "step: 100/150 ...  - loss: 0.4444 - val_loss: 0.4421\n",
      " - main_loss: 0.3166 - main_acc: 0.8622 - main_recall: 0.6878 - val_main_loss: 0.3151 - val_main_acc: 0.8692 - val_main_recall: 0.7324\n",
      " - aux_loss: 0.5414 - aux_acc: 0.6896 - aux_recall: 0.6862 - val_aux_loss: 0.5371 - val_aux_acc: 0.6968 - val_aux_recall: 0.7308\n",
      "step: 150/150 ...  - loss: 0.4375 - val_loss: 0.4387\n",
      " - main_loss: 0.3094 - main_acc: 0.8661 - main_recall: 0.6959 - val_main_loss: 0.3112 - val_main_acc: 0.8715 - val_main_recall: 0.7301\n",
      " - aux_loss: 0.5401 - aux_acc: 0.6897 - aux_recall: 0.6942 - val_aux_loss: 0.5374 - val_aux_acc: 0.6961 - val_aux_recall: 0.7284\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 50/150 ...  - loss: 0.3322 - val_loss: 0.3401\n",
      " - main_loss: 0.2300 - main_acc: 0.9030 - main_recall: 0.7527 - val_main_loss: 0.2371 - val_main_acc: 0.8961 - val_main_recall: 0.7464\n",
      " - aux_loss: 0.4143 - aux_acc: 0.7746 - aux_recall: 0.7517 - val_aux_loss: 0.4188 - val_aux_acc: 0.7689 - val_aux_recall: 0.7447\n",
      "step: 100/150 ...  - loss: 0.3202 - val_loss: 0.3376\n",
      " - main_loss: 0.2202 - main_acc: 0.9073 - main_recall: 0.7540 - val_main_loss: 0.2364 - val_main_acc: 0.8964 - val_main_recall: 0.7429\n",
      " - aux_loss: 0.4119 - aux_acc: 0.7749 - aux_recall: 0.7529 - val_aux_loss: 0.4181 - val_aux_acc: 0.7688 - val_aux_recall: 0.7411\n",
      "step: 150/150 ...  - loss: 0.3157 - val_loss: 0.3406\n",
      " - main_loss: 0.2155 - main_acc: 0.9093 - main_recall: 0.7544 - val_main_loss: 0.2391 - val_main_acc: 0.8951 - val_main_recall: 0.7435\n",
      " - aux_loss: 0.4111 - aux_acc: 0.7751 - aux_recall: 0.7532 - val_aux_loss: 0.4181 - val_aux_acc: 0.7689 - val_aux_recall: 0.7417\n",
      "Evaluando especie sin balancear: Specie_Pig\n",
      "loss     = 1.1193\n",
      "aux_loss     = 2.7832\n",
      "main_loss     = 0.5453\n",
      "aux_acc     = 0.4046\n",
      "aux_recall     = 0.7995\n",
      "main_acc     = 0.7972\n",
      "main_recall     = 0.7995\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Pig\n",
      "loss     = 1.0475\n",
      "aux_loss     = 2.2294\n",
      "main_loss     = 0.5842\n",
      "aux_acc     = 0.5132\n",
      "aux_recall     = 0.7995\n",
      "main_acc     = 0.7712\n",
      "main_recall     = 0.7995\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 50/150 ...  - loss: 3.2944 - val_loss: 3.1156\n",
      " - main_loss: 0.4299 - main_acc: 0.7963 - main_recall: 0.6287 - val_main_loss: 0.3904 - val_main_acc: 0.8242 - val_main_recall: 0.6429\n",
      " - aux_loss: 0.4964 - aux_acc: 0.7295 - aux_recall: 0.6287 - val_aux_loss: 0.4797 - val_aux_acc: 0.7427 - val_aux_recall: 0.6379\n",
      "step: 100/150 ...  - loss: 0.6100 - val_loss: 0.5897\n",
      " - main_loss: 0.3529 - main_acc: 0.8444 - main_recall: 0.6564 - val_main_loss: 0.3381 - val_main_acc: 0.8521 - val_main_recall: 0.6808\n",
      " - aux_loss: 0.4769 - aux_acc: 0.7377 - aux_recall: 0.6564 - val_aux_loss: 0.4699 - val_aux_acc: 0.7431 - val_aux_recall: 0.6739\n",
      "step: 150/150 ...  - loss: 0.4860 - val_loss: 0.4741\n",
      " - main_loss: 0.3382 - main_acc: 0.8517 - main_recall: 0.6630 - val_main_loss: 0.3283 - val_main_acc: 0.8582 - val_main_recall: 0.6834\n",
      " - aux_loss: 0.4748 - aux_acc: 0.7378 - aux_recall: 0.6630 - val_aux_loss: 0.4675 - val_aux_acc: 0.7435 - val_aux_recall: 0.6763\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 50/150 ...  - loss: 0.5071 - val_loss: 0.4983\n",
      " - main_loss: 0.3661 - main_acc: 0.8404 - main_recall: 0.5494 - val_main_loss: 0.3590 - val_main_acc: 0.8460 - val_main_recall: 0.5564\n",
      " - aux_loss: 0.5516 - aux_acc: 0.6972 - aux_recall: 0.5485 - val_aux_loss: 0.5470 - val_aux_acc: 0.7007 - val_aux_recall: 0.5467\n",
      "step: 100/150 ...  - loss: 0.4757 - val_loss: 0.4708\n",
      " - main_loss: 0.3443 - main_acc: 0.8505 - main_recall: 0.5546 - val_main_loss: 0.3405 - val_main_acc: 0.8560 - val_main_recall: 0.5603\n",
      " - aux_loss: 0.5502 - aux_acc: 0.6977 - aux_recall: 0.5536 - val_aux_loss: 0.5454 - val_aux_acc: 0.7010 - val_aux_recall: 0.5505\n",
      "step: 150/150 ...  - loss: 0.4586 - val_loss: 0.4609\n",
      " - main_loss: 0.3301 - main_acc: 0.8563 - main_recall: 0.5615 - val_main_loss: 0.3333 - val_main_acc: 0.8581 - val_main_recall: 0.5638\n",
      " - aux_loss: 0.5475 - aux_acc: 0.6980 - aux_recall: 0.5605 - val_aux_loss: 0.5432 - val_aux_acc: 0.7015 - val_aux_recall: 0.5538\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 50/150 ...  - loss: 0.3483 - val_loss: 0.3481\n",
      " - main_loss: 0.2453 - main_acc: 0.8965 - main_recall: 0.7515 - val_main_loss: 0.2445 - val_main_acc: 0.8957 - val_main_recall: 0.7460\n",
      " - aux_loss: 0.4234 - aux_acc: 0.7653 - aux_recall: 0.7511 - val_aux_loss: 0.4272 - val_aux_acc: 0.7570 - val_aux_recall: 0.7404\n",
      "step: 100/150 ...  - loss: 0.3339 - val_loss: 0.3395\n",
      " - main_loss: 0.2342 - main_acc: 0.9005 - main_recall: 0.7555 - val_main_loss: 0.2390 - val_main_acc: 0.8972 - val_main_recall: 0.7470\n",
      " - aux_loss: 0.4204 - aux_acc: 0.7671 - aux_recall: 0.7551 - val_aux_loss: 0.4244 - val_aux_acc: 0.7587 - val_aux_recall: 0.7414\n",
      "step: 150/150 ...  - loss: 0.3273 - val_loss: 0.3381\n",
      " - main_loss: 0.2279 - main_acc: 0.9025 - main_recall: 0.7560 - val_main_loss: 0.2379 - val_main_acc: 0.8981 - val_main_recall: 0.7464\n",
      " - aux_loss: 0.4206 - aux_acc: 0.7674 - aux_recall: 0.7556 - val_aux_loss: 0.4250 - val_aux_acc: 0.7586 - val_aux_recall: 0.7409\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 50/150 ...  - loss: 0.4560 - val_loss: 0.4537\n",
      " - main_loss: 0.3258 - main_acc: 0.8595 - main_recall: 0.5605 - val_main_loss: 0.3245 - val_main_acc: 0.8600 - val_main_recall: 0.5521\n",
      " - aux_loss: 0.5567 - aux_acc: 0.6931 - aux_recall: 0.5581 - val_aux_loss: 0.5521 - val_aux_acc: 0.6986 - val_aux_recall: 0.5454\n",
      "step: 100/150 ...  - loss: 0.4409 - val_loss: 0.4487\n",
      " - main_loss: 0.3129 - main_acc: 0.8652 - main_recall: 0.5618 - val_main_loss: 0.3213 - val_main_acc: 0.8618 - val_main_recall: 0.5577\n",
      " - aux_loss: 0.5547 - aux_acc: 0.6941 - aux_recall: 0.5593 - val_aux_loss: 0.5517 - val_aux_acc: 0.6990 - val_aux_recall: 0.5508\n",
      "step: 150/150 ...  - loss: 0.4360 - val_loss: 0.4488\n",
      " - main_loss: 0.3075 - main_acc: 0.8674 - main_recall: 0.5623 - val_main_loss: 0.3208 - val_main_acc: 0.8628 - val_main_recall: 0.5604\n",
      " - aux_loss: 0.5548 - aux_acc: 0.6941 - aux_recall: 0.5598 - val_aux_loss: 0.5522 - val_aux_acc: 0.6989 - val_aux_recall: 0.5534\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 50/150 ...  - loss: 0.3260 - val_loss: 0.3357\n",
      " - main_loss: 0.2246 - main_acc: 0.9063 - main_recall: 0.7553 - val_main_loss: 0.2336 - val_main_acc: 0.8995 - val_main_recall: 0.7485\n",
      " - aux_loss: 0.4130 - aux_acc: 0.7751 - aux_recall: 0.7542 - val_aux_loss: 0.4171 - val_aux_acc: 0.7700 - val_aux_recall: 0.7468\n",
      "step: 100/150 ...  - loss: 0.3148 - val_loss: 0.3362\n",
      " - main_loss: 0.2153 - main_acc: 0.9097 - main_recall: 0.7590 - val_main_loss: 0.2356 - val_main_acc: 0.8985 - val_main_recall: 0.7466\n",
      " - aux_loss: 0.4112 - aux_acc: 0.7759 - aux_recall: 0.7579 - val_aux_loss: 0.4167 - val_aux_acc: 0.7703 - val_aux_recall: 0.7448\n",
      "step: 150/150 ...  - loss: 0.3097 - val_loss: 0.3380\n",
      " - main_loss: 0.2104 - main_acc: 0.9111 - main_recall: 0.7592 - val_main_loss: 0.2374 - val_main_acc: 0.8978 - val_main_recall: 0.7445\n",
      " - aux_loss: 0.4106 - aux_acc: 0.7760 - aux_recall: 0.7581 - val_aux_loss: 0.4174 - val_aux_acc: 0.7702 - val_aux_recall: 0.7427\n",
      "Evaluando especie sin balancear: Specie_Rat\n",
      "loss     = 1.3268\n",
      "aux_loss     = 2.0792\n",
      "main_loss     = 0.8940\n",
      "aux_acc     = 0.5485\n",
      "aux_recall     = 0.7461\n",
      "main_acc     = 0.6898\n",
      "main_recall     = 0.7461\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Rat\n",
      "loss     = 1.3264\n",
      "aux_loss     = 2.2144\n",
      "main_loss     = 0.8666\n",
      "aux_acc     = 0.5211\n",
      "aux_recall     = 0.7553\n",
      "main_acc     = 0.6997\n",
      "main_recall     = 0.7377\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "species_cross_dict = {}\n",
    "for specie in species_metadata:\n",
    "    dataset_complete_no_species = dataset_complete[dataset_complete[specie] == 0]    \n",
    "    dataset_complete_species = dataset_complete[dataset_complete[specie] == 1]    \n",
    "        \n",
    "    df_no_species = dataset_complete_no_species[dataset_complete_no_species[specie] == 0]\n",
    "    df_train, df_val = train_test_split(df_no_species, test_size=0.2,random_state=9,stratify=df_no_species[\"Is_Ohnolog\"])\n",
    "    df_train_x = df_train.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_train_x = df_train_x.drop(embedding_1_cols,axis=1)\n",
    "    df_train_x = df_train_x.drop(embedding_2_cols,axis=1)\n",
    "    df_train_emb_x = pd.concat([df_train[embedding_1_cols],df_train[embedding_2_cols]],axis=1,sort=False)\n",
    "\n",
    "    model = level_model(df_train_x,df_train_emb_x,\"Level_model_cross\" + specie  )\n",
    "    specie_metadata_copy = species_metadata[:]\n",
    "    specie_metadata_copy.remove(specie)\n",
    "\n",
    "    for specie_cross in specie_metadata_copy:\n",
    "        df_no_species = dataset_complete_no_species[dataset_complete_no_species[specie_cross] == 0]\n",
    "        df_train, df_val = train_test_split(df_no_species, test_size=0.2,random_state=9,stratify=df_no_species[\"Is_Ohnolog\"])\n",
    "\n",
    "        df_train_x = df_train.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "        df_train_x = df_train_x.drop(embedding_1_cols,axis=1)\n",
    "        df_train_x = df_train_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "        df_train_emb_x = pd.concat([df_train[embedding_1_cols],df_train[embedding_2_cols]],axis=1,sort=False)\n",
    "        df_train_y = df_train[\"Is_Ohnolog\"]\n",
    "\n",
    "        df_val_x = df_val.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "        df_val_x = df_val_x.drop(embedding_1_cols,axis=1)\n",
    "        df_val_x = df_val_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "        df_val_emb_x = pd.concat([df_val[embedding_1_cols],df_val[embedding_2_cols]],axis=1,sort=False)\n",
    "        df_val_y = df_val[\"Is_Ohnolog\"]\n",
    "\n",
    "        print(\"Entrenando sin especie: \" + specie_cross)\n",
    "        log = fit_model_level(df_train_x,df_train_emb_x,df_train_y,df_val_x,df_val_emb_x,df_val_y,model,150,Adamax(),256,[0.2,1],0)\n",
    "        \n",
    "    \n",
    "    df_test_species_x = dataset_complete_species.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_species_emb_x =  pd.concat([dataset_complete_species[embedding_1_cols],dataset_complete_species[embedding_2_cols]],axis=1,sort=False)\n",
    "    df_test_species_y = dataset_complete_species[\"Is_Ohnolog\"]\n",
    "    \n",
    "    species_cross_dict[specie] = {}\n",
    "    \n",
    "    print(\"Evaluando especie sin balancear: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_species_emb_x.values,df_test_species_x.values],[df_test_species_y.values,df_test_species_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_cross_dict[specie][\"Sin Balanceo\"] = metrics[5]\n",
    "    \n",
    "    df_species_ohnologs = dataset_complete_species[dataset_complete_species[\"Is_Ohnolog\"] == 1]\n",
    "    df_species_no_ohnologs = dataset_complete_species[dataset_complete_species[\"Is_Ohnolog\"] == 0]\n",
    "    \n",
    "    if(len(df_species_ohnologs)>len(df_species_no_ohnologs)):\n",
    "        df_species_new = df_species_no_ohnologs.append(df_species_ohnologs.sample(len(df_species_no_ohnologs)))        \n",
    "    else:\n",
    "        df_species_new = df_species_ohnologs.append(df_species_no_ohnologs.sample(len(df_species_ohnologs)))\n",
    "        \n",
    "        \n",
    "    if(len(df_species_new) == 0):\n",
    "        df_species_new = df_species_ohnologs\n",
    "        \n",
    "    df_test_species_x = df_species_new.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_species_emb_x =  pd.concat([df_species_new[embedding_1_cols],df_species_new[embedding_2_cols]],axis=1,sort=False)\n",
    "    df_test_species_y = df_species_new[\"Is_Ohnolog\"]                    \n",
    "    \n",
    "    print(\"Evaluando especie balanceada: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_species_emb_x.values,df_test_species_x.values],[df_test_species_y.values,df_test_species_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_cross_dict[specie][\"Balanceadas\"] = metrics[5]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Specie_Chicken': {'Sin Balanceo': 0.8183273321249429,\n",
       "  'Balanceadas': 0.8295318115086687},\n",
       " 'Specie_Dog': {'Sin Balanceo': 0.7151090978422789,\n",
       "  'Balanceadas': 0.7151090978422789},\n",
       " 'Specie_Human': {'Sin Balanceo': 0.7561962573770689,\n",
       "  'Balanceadas': 0.7606221555035465},\n",
       " 'Specie_Mouse': {'Sin Balanceo': 0.8072699741042504,\n",
       "  'Balanceadas': 0.8072699741042504},\n",
       " 'Specie_Pig': {'Sin Balanceo': 0.7972048334479072,\n",
       "  'Balanceadas': 0.7712235953191117},\n",
       " 'Specie_Rat': {'Sin Balanceo': 0.6898020546975754,\n",
       "  'Balanceadas': 0.6997326202571074}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_cross_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_embedding_layer(input_embedding):    \n",
    "    emb_x = Dense(512, activation='elu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(input_embedding)       \n",
    "    emb_x = BatchNormalization()(emb_x)\n",
    "    emb_x = Dropout(0.4)(emb_x)    \n",
    "    emb_x = Dense(256,use_bias = False, activation='elu',kernel_regularizer=regularizers.l1(0.0005))(emb_x)            \n",
    "    emb_x = BatchNormalization()(emb_x)    \n",
    "    emb_x = Dropout(0.4)(emb_x)    \n",
    "    emb_x = Dense(128,use_bias = False, activation='elu',kernel_regularizer=regularizers.l1(0.0005))(emb_x)            \n",
    "    emb_x = BatchNormalization()(emb_x)    \n",
    "    emb_x = Dense(64, use_bias = False, activation='elu',kernel_regularizer=regularizers.l1(0.0005))(emb_x)            \n",
    "    emb_x = BatchNormalization()(emb_x)    \n",
    "    emb_x = Dense(32, use_bias = False, activation='elu',kernel_regularizer=regularizers.l1(0.0005))(emb_x)                \n",
    "    emb_x = BatchNormalization()(emb_x)    \n",
    "    return emb_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_siames_merge_layer(df_meta_input,df_embeddings_1,df_embeddings_2,name,bs):    \n",
    "    \n",
    "    input_embedding_1 = Input(shape=(len(df_embeddings_1.columns),), name='embedding_input_1')        \n",
    "    input_embedding_2 = Input(shape=(len(df_embeddings_2.columns),), name='embedding_input_2')        \n",
    "    \n",
    "    emb_x_1 = get_tensor_embedding_layer(input_embedding_1)    \n",
    "    emb_x_2 = get_tensor_embedding_layer(input_embedding_2)    \n",
    "    \n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([emb_x_1, emb_x_2])\n",
    "    \n",
    "    emb_x_out = Dense(1, activation='sigmoid',name=\"aux\")(L1_distance)                \n",
    "    \n",
    "    meta_input = Input(shape=(len(df_meta_input.columns),), name='meta_input')    \n",
    "    \n",
    "    x = keras.layers.concatenate([L1_distance,meta_input])\n",
    "    x = Dense(128, activation='relu',use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)   \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.0005))(x)    \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(8, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.0005))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    predictions = Dense(1, activation='sigmoid',name=\"main\")(x)\n",
    "        \n",
    "    model_created = Model(inputs=[input_embedding_1,input_embedding_2,meta_input], outputs=[predictions,emb_x_out])\n",
    "    model_created.Name = name\n",
    "    return model_created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_siames_merge_layer_soft(df_meta_input,df_embeddings_1,df_embeddings_2,name,bs):    \n",
    "    \n",
    "    input_embedding_1 = Input(shape=(len(df_embeddings_1.columns),), name='embedding_input_1')        \n",
    "    input_embedding_2 = Input(shape=(len(df_embeddings_2.columns),), name='embedding_input_2')        \n",
    "    \n",
    "    emb_x_1 = get_tensor_embedding_layer(input_embedding_1)    \n",
    "    emb_x_2 = get_tensor_embedding_layer(input_embedding_2)    \n",
    "    \n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([emb_x_1, emb_x_2])\n",
    "    \n",
    "    emb_x_out = Dense(3, activation='softmax',name=\"aux\")(L1_distance)                \n",
    "    \n",
    "    meta_input = Input(shape=(len(df_meta_input.columns),), name='meta_input')    \n",
    "    \n",
    "    x = keras.layers.concatenate([L1_distance,meta_input])\n",
    "    x = Dense(128, activation='relu',use_bias=False)(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)   \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.001))(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.0005))(x)    \n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(8, activation='relu',use_bias=False,kernel_regularizer=regularizers.l2(0.0005))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    predictions = Dense(3, activation='softmax',name=\"main\")(x)\n",
    "        \n",
    "    model_created = Model(inputs=[input_embedding_1,input_embedding_2,meta_input], outputs=[predictions,emb_x_out])\n",
    "    model_created.Name = name\n",
    "    return model_created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x,y):    \n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_siames(train_x,train_emb_x_1,train_emb_x_2,train_y,val_x,val_emb_x_1,val_emb_x_2,val_y,model_train,n_epochs,optimizer,batchsize,loss_weigths,verb):\n",
    "    tensorboard = TensorBoard(log_dir= train_filepath + working_level + \"/board_logs/\" + model_train.Name + \"-{}\".format(time()))\n",
    "    checkpoint = ModelCheckpoint(train_filepath + working_level + \"/model_checkpoints/{0}-check-{{epoch:02d}}-{{val_main_acc:.2f}}.hdf5\".format(model_train.Name),save_weights_only=True,  period = int(n_epochs/5))\n",
    "    best_model_save = ModelCheckpoint(train_filepath + working_level + \"/model_checkpoints/{0}-best.hdf5\".format(model_train.Name), monitor='val_main_acc', save_weights_only=True, save_best_only=True, mode='max')\n",
    "    logger = EpochLogger(display=25)\n",
    "\n",
    "    model_train.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy',km.binary_recall()],loss_weights=loss_weigths)    \n",
    "    return model_train.fit([train_emb_x_1,train_emb_x_2,train_x], y = [train_y,train_y],verbose = verb,validation_data=([val_emb_x_1,val_emb_x_2,val_x],[val_y,val_y]),epochs = n_epochs,batch_size=batchsize,callbacks = [tensorboard,checkpoint,best_model_save,logger])  # starts training\n",
    "\n",
    "\n",
    "def fit_model_siames_soft(train_x,train_emb_x_1,train_emb_x_2,train_y,val_x,val_emb_x_1,val_emb_x_2,val_y,model_train,n_epochs,optimizer,batchsize,loss_weigths,verb):\n",
    "    tensorboard = TensorBoard(log_dir=train_filepath + working_level + \"/board_logs/\" + model_train.Name + \"-{}\".format(time()))\n",
    "    checkpoint = ModelCheckpoint(train_filepath + working_level + \"/model_checkpoints/{0}-check-{{epoch:02d}}-{{val_main_acc:.2f}}.hdf5\".format(model_train.Name),save_weights_only=True,  period = int(n_epochs/5))\n",
    "    best_model_save = ModelCheckpoint(train_filepath + working_level + \"/model_checkpoints/{0}-best.hdf5\".format(model_train.Name), monitor='val_main_acc', save_weights_only=True, save_best_only=True, mode='max')\n",
    "    logger = EpochLogger(display=25)\n",
    "\n",
    "    model_train.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',km.sparse_categorical_recall()],loss_weights=loss_weigths)    \n",
    "    return model_train.fit([train_emb_x_1,train_emb_x_2,train_x], y = [train_y,train_y],verbose = verb,validation_data=([val_emb_x_1,val_emb_x_2,val_x],[val_y,val_y]),epochs = n_epochs,batch_size=batchsize,callbacks = [tensorboard,checkpoint,best_model_save,logger])  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 25/800 ...  - loss: 4.2965 - val_loss: 4.0877\n",
      " - main_loss: 0.5136 - main_acc: 0.7410 - main_recall: 0.5639 - val_main_loss: 0.4786 - val_main_acc: 0.7689 - val_main_recall: 0.5765\n",
      " - aux_loss: 0.5890 - aux_acc: 0.6669 - aux_recall: 0.5632 - val_aux_loss: 0.5845 - val_aux_acc: 0.6695 - val_aux_recall: 0.5713\n",
      "step: 50/800 ...  - loss: 0.9584 - val_loss: 0.9528\n",
      " - main_loss: 0.4195 - main_acc: 0.8115 - main_recall: 0.6217 - val_main_loss: 0.4222 - val_main_acc: 0.8152 - val_main_recall: 0.6179\n",
      " - aux_loss: 0.5711 - aux_acc: 0.6730 - aux_recall: 0.6196 - val_aux_loss: 0.5898 - val_aux_acc: 0.6606 - val_aux_recall: 0.6070\n",
      "step: 75/800 ...  - loss: 0.7209 - val_loss: 0.7265\n",
      " - main_loss: 0.3971 - main_acc: 0.8238 - main_recall: 0.6260 - val_main_loss: 0.4012 - val_main_acc: 0.8254 - val_main_recall: 0.6156\n",
      " - aux_loss: 0.5698 - aux_acc: 0.6722 - aux_recall: 0.6241 - val_aux_loss: 0.5871 - val_aux_acc: 0.6634 - val_aux_recall: 0.6039\n",
      "step: 100/800 ...  - loss: 0.6638 - val_loss: 0.6736\n",
      " - main_loss: 0.3822 - main_acc: 0.8317 - main_recall: 0.6335 - val_main_loss: 0.3890 - val_main_acc: 0.8324 - val_main_recall: 0.6431\n",
      " - aux_loss: 0.5660 - aux_acc: 0.6741 - aux_recall: 0.6314 - val_aux_loss: 0.5848 - val_aux_acc: 0.6602 - val_aux_recall: 0.6326\n",
      "step: 125/800 ...  - loss: 0.6273 - val_loss: 0.6346\n",
      " - main_loss: 0.3684 - main_acc: 0.8386 - main_recall: 0.6418 - val_main_loss: 0.3740 - val_main_acc: 0.8383 - val_main_recall: 0.6454\n",
      " - aux_loss: 0.5618 - aux_acc: 0.6775 - aux_recall: 0.6398 - val_aux_loss: 0.5792 - val_aux_acc: 0.6662 - val_aux_recall: 0.6344\n",
      "step: 150/800 ...  - loss: 0.6031 - val_loss: 0.6196\n",
      " - main_loss: 0.3569 - main_acc: 0.8442 - main_recall: 0.6413 - val_main_loss: 0.3676 - val_main_acc: 0.8416 - val_main_recall: 0.6379\n",
      " - aux_loss: 0.5585 - aux_acc: 0.6789 - aux_recall: 0.6392 - val_aux_loss: 0.5801 - val_aux_acc: 0.6643 - val_aux_recall: 0.6267\n",
      "step: 175/800 ...  - loss: 0.5804 - val_loss: 0.5973\n",
      " - main_loss: 0.3468 - main_acc: 0.8485 - main_recall: 0.6504 - val_main_loss: 0.3606 - val_main_acc: 0.8439 - val_main_recall: 0.6491\n",
      " - aux_loss: 0.5551 - aux_acc: 0.6835 - aux_recall: 0.6483 - val_aux_loss: 0.5735 - val_aux_acc: 0.6707 - val_aux_recall: 0.6378\n",
      "step: 200/800 ...  - loss: 0.5693 - val_loss: 0.5887\n",
      " - main_loss: 0.3394 - main_acc: 0.8521 - main_recall: 0.6579 - val_main_loss: 0.3546 - val_main_acc: 0.8477 - val_main_recall: 0.6506\n",
      " - aux_loss: 0.5538 - aux_acc: 0.6844 - aux_recall: 0.6558 - val_aux_loss: 0.5720 - val_aux_acc: 0.6714 - val_aux_recall: 0.6386\n",
      "step: 225/800 ...  - loss: 0.5568 - val_loss: 0.5840\n",
      " - main_loss: 0.3316 - main_acc: 0.8561 - main_recall: 0.6643 - val_main_loss: 0.3545 - val_main_acc: 0.8481 - val_main_recall: 0.6614\n",
      " - aux_loss: 0.5510 - aux_acc: 0.6872 - aux_recall: 0.6624 - val_aux_loss: 0.5715 - val_aux_acc: 0.6730 - val_aux_recall: 0.6489\n",
      "step: 250/800 ...  - loss: 0.5479 - val_loss: 0.5782\n",
      " - main_loss: 0.3256 - main_acc: 0.8591 - main_recall: 0.6711 - val_main_loss: 0.3525 - val_main_acc: 0.8500 - val_main_recall: 0.6501\n",
      " - aux_loss: 0.5485 - aux_acc: 0.6889 - aux_recall: 0.6691 - val_aux_loss: 0.5702 - val_aux_acc: 0.6738 - val_aux_recall: 0.6371\n",
      "step: 275/800 ...  - loss: 0.5377 - val_loss: 0.5746\n",
      " - main_loss: 0.3193 - main_acc: 0.8622 - main_recall: 0.6729 - val_main_loss: 0.3506 - val_main_acc: 0.8507 - val_main_recall: 0.6587\n",
      " - aux_loss: 0.5461 - aux_acc: 0.6909 - aux_recall: 0.6708 - val_aux_loss: 0.5730 - val_aux_acc: 0.6741 - val_aux_recall: 0.6454\n",
      "step: 300/800 ...  - loss: 0.5296 - val_loss: 0.5685\n",
      " - main_loss: 0.3144 - main_acc: 0.8651 - main_recall: 0.6781 - val_main_loss: 0.3484 - val_main_acc: 0.8529 - val_main_recall: 0.6627\n",
      " - aux_loss: 0.5444 - aux_acc: 0.6919 - aux_recall: 0.6760 - val_aux_loss: 0.5671 - val_aux_acc: 0.6770 - val_aux_recall: 0.6495\n",
      "step: 325/800 ...  - loss: 0.5253 - val_loss: 0.5717\n",
      " - main_loss: 0.3097 - main_acc: 0.8671 - main_recall: 0.6810 - val_main_loss: 0.3484 - val_main_acc: 0.8528 - val_main_recall: 0.6713\n",
      " - aux_loss: 0.5430 - aux_acc: 0.6928 - aux_recall: 0.6788 - val_aux_loss: 0.5718 - val_aux_acc: 0.6732 - val_aux_recall: 0.6583\n",
      "step: 350/800 ...  - loss: 0.5148 - val_loss: 0.5648\n",
      " - main_loss: 0.3038 - main_acc: 0.8702 - main_recall: 0.6864 - val_main_loss: 0.3477 - val_main_acc: 0.8542 - val_main_recall: 0.6640\n",
      " - aux_loss: 0.5401 - aux_acc: 0.6948 - aux_recall: 0.6844 - val_aux_loss: 0.5691 - val_aux_acc: 0.6756 - val_aux_recall: 0.6511\n",
      "step: 375/800 ...  - loss: 0.5107 - val_loss: 0.5617\n",
      " - main_loss: 0.2999 - main_acc: 0.8713 - main_recall: 0.6890 - val_main_loss: 0.3452 - val_main_acc: 0.8548 - val_main_recall: 0.6768\n",
      " - aux_loss: 0.5397 - aux_acc: 0.6956 - aux_recall: 0.6869 - val_aux_loss: 0.5688 - val_aux_acc: 0.6755 - val_aux_recall: 0.6641\n",
      "step: 400/800 ...  - loss: 0.5069 - val_loss: 0.5659\n",
      " - main_loss: 0.2955 - main_acc: 0.8735 - main_recall: 0.6944 - val_main_loss: 0.3481 - val_main_acc: 0.8545 - val_main_recall: 0.6796\n",
      " - aux_loss: 0.5377 - aux_acc: 0.6975 - aux_recall: 0.6923 - val_aux_loss: 0.5689 - val_aux_acc: 0.6769 - val_aux_recall: 0.6668\n",
      "step: 425/800 ...  - loss: 0.5006 - val_loss: 0.5612\n",
      " - main_loss: 0.2923 - main_acc: 0.8745 - main_recall: 0.6973 - val_main_loss: 0.3468 - val_main_acc: 0.8562 - val_main_recall: 0.6725\n",
      " - aux_loss: 0.5359 - aux_acc: 0.6967 - aux_recall: 0.6953 - val_aux_loss: 0.5673 - val_aux_acc: 0.6791 - val_aux_recall: 0.6591\n",
      "step: 450/800 ...  - loss: 0.4967 - val_loss: 0.5573\n",
      " - main_loss: 0.2889 - main_acc: 0.8766 - main_recall: 0.6981 - val_main_loss: 0.3428 - val_main_acc: 0.8568 - val_main_recall: 0.6776\n",
      " - aux_loss: 0.5346 - aux_acc: 0.6979 - aux_recall: 0.6962 - val_aux_loss: 0.5686 - val_aux_acc: 0.6773 - val_aux_recall: 0.6649\n",
      "step: 475/800 ...  - loss: 0.4921 - val_loss: 0.5601\n",
      " - main_loss: 0.2867 - main_acc: 0.8779 - main_recall: 0.7026 - val_main_loss: 0.3471 - val_main_acc: 0.8557 - val_main_recall: 0.6831\n",
      " - aux_loss: 0.5336 - aux_acc: 0.6984 - aux_recall: 0.7008 - val_aux_loss: 0.5692 - val_aux_acc: 0.6788 - val_aux_recall: 0.6703\n",
      "step: 500/800 ...  - loss: 0.4863 - val_loss: 0.5572\n",
      " - main_loss: 0.2823 - main_acc: 0.8797 - main_recall: 0.7084 - val_main_loss: 0.3452 - val_main_acc: 0.8574 - val_main_recall: 0.6768\n",
      " - aux_loss: 0.5309 - aux_acc: 0.6995 - aux_recall: 0.7064 - val_aux_loss: 0.5690 - val_aux_acc: 0.6804 - val_aux_recall: 0.6638\n",
      "step: 525/800 ...  - loss: 0.4798 - val_loss: 0.5526\n",
      " - main_loss: 0.2798 - main_acc: 0.8808 - main_recall: 0.7068 - val_main_loss: 0.3454 - val_main_acc: 0.8584 - val_main_recall: 0.6746\n",
      " - aux_loss: 0.5304 - aux_acc: 0.7009 - aux_recall: 0.7048 - val_aux_loss: 0.5685 - val_aux_acc: 0.6803 - val_aux_recall: 0.6612\n",
      "step: 550/800 ...  - loss: 0.4782 - val_loss: 0.5539\n",
      " - main_loss: 0.2763 - main_acc: 0.8819 - main_recall: 0.7119 - val_main_loss: 0.3442 - val_main_acc: 0.8583 - val_main_recall: 0.6841\n",
      " - aux_loss: 0.5298 - aux_acc: 0.7007 - aux_recall: 0.7099 - val_aux_loss: 0.5705 - val_aux_acc: 0.6782 - val_aux_recall: 0.6707\n",
      "step: 575/800 ...  - loss: 0.4752 - val_loss: 0.5571\n",
      " - main_loss: 0.2746 - main_acc: 0.8832 - main_recall: 0.7119 - val_main_loss: 0.3475 - val_main_acc: 0.8583 - val_main_recall: 0.6869\n",
      " - aux_loss: 0.5276 - aux_acc: 0.7022 - aux_recall: 0.7101 - val_aux_loss: 0.5707 - val_aux_acc: 0.6787 - val_aux_recall: 0.6745\n",
      "step: 600/800 ...  - loss: 0.4702 - val_loss: 0.5566\n",
      " - main_loss: 0.2711 - main_acc: 0.8851 - main_recall: 0.7168 - val_main_loss: 0.3492 - val_main_acc: 0.8574 - val_main_recall: 0.6926\n",
      " - aux_loss: 0.5262 - aux_acc: 0.7028 - aux_recall: 0.7150 - val_aux_loss: 0.5706 - val_aux_acc: 0.6809 - val_aux_recall: 0.6794\n",
      "step: 625/800 ...  - loss: 0.4671 - val_loss: 0.5574\n",
      " - main_loss: 0.2693 - main_acc: 0.8860 - main_recall: 0.7145 - val_main_loss: 0.3505 - val_main_acc: 0.8559 - val_main_recall: 0.6775\n",
      " - aux_loss: 0.5255 - aux_acc: 0.7034 - aux_recall: 0.7124 - val_aux_loss: 0.5708 - val_aux_acc: 0.6781 - val_aux_recall: 0.6638\n",
      "step: 650/800 ...  - loss: 0.4626 - val_loss: 0.5532\n",
      " - main_loss: 0.2656 - main_acc: 0.8877 - main_recall: 0.7219 - val_main_loss: 0.3478 - val_main_acc: 0.8586 - val_main_recall: 0.6811\n",
      " - aux_loss: 0.5238 - aux_acc: 0.7050 - aux_recall: 0.7200 - val_aux_loss: 0.5695 - val_aux_acc: 0.6823 - val_aux_recall: 0.6688\n",
      "step: 675/800 ...  - loss: 0.4596 - val_loss: 0.5561\n",
      " - main_loss: 0.2639 - main_acc: 0.8886 - main_recall: 0.7240 - val_main_loss: 0.3509 - val_main_acc: 0.8552 - val_main_recall: 0.6952\n",
      " - aux_loss: 0.5229 - aux_acc: 0.7055 - aux_recall: 0.7221 - val_aux_loss: 0.5705 - val_aux_acc: 0.6816 - val_aux_recall: 0.6831\n",
      "step: 700/800 ...  - loss: 0.4566 - val_loss: 0.5573\n",
      " - main_loss: 0.2620 - main_acc: 0.8893 - main_recall: 0.7241 - val_main_loss: 0.3524 - val_main_acc: 0.8571 - val_main_recall: 0.6897\n",
      " - aux_loss: 0.5218 - aux_acc: 0.7063 - aux_recall: 0.7223 - val_aux_loss: 0.5716 - val_aux_acc: 0.6802 - val_aux_recall: 0.6775\n",
      "step: 725/800 ...  - loss: 0.4531 - val_loss: 0.5540\n",
      " - main_loss: 0.2596 - main_acc: 0.8912 - main_recall: 0.7274 - val_main_loss: 0.3503 - val_main_acc: 0.8570 - val_main_recall: 0.6898\n",
      " - aux_loss: 0.5211 - aux_acc: 0.7075 - aux_recall: 0.7257 - val_aux_loss: 0.5710 - val_aux_acc: 0.6810 - val_aux_recall: 0.6775\n",
      "step: 750/800 ...  - loss: 0.4493 - val_loss: 0.5558\n",
      " - main_loss: 0.2572 - main_acc: 0.8918 - main_recall: 0.7257 - val_main_loss: 0.3537 - val_main_acc: 0.8569 - val_main_recall: 0.6882\n",
      " - aux_loss: 0.5210 - aux_acc: 0.7068 - aux_recall: 0.7238 - val_aux_loss: 0.5722 - val_aux_acc: 0.6803 - val_aux_recall: 0.6755\n",
      "step: 775/800 ...  - loss: 0.4479 - val_loss: 0.5640\n",
      " - main_loss: 0.2560 - main_acc: 0.8926 - main_recall: 0.7285 - val_main_loss: 0.3606 - val_main_acc: 0.8546 - val_main_recall: 0.6845\n",
      " - aux_loss: 0.5186 - aux_acc: 0.7067 - aux_recall: 0.7265 - val_aux_loss: 0.5747 - val_aux_acc: 0.6808 - val_aux_recall: 0.6719\n",
      "step: 800/800 ...  - loss: 0.4459 - val_loss: 0.5585\n",
      " - main_loss: 0.2543 - main_acc: 0.8934 - main_recall: 0.7303 - val_main_loss: 0.3551 - val_main_acc: 0.8557 - val_main_recall: 0.6860\n",
      " - aux_loss: 0.5179 - aux_acc: 0.7083 - aux_recall: 0.7284 - val_aux_loss: 0.5754 - val_aux_acc: 0.6810 - val_aux_recall: 0.6733\n",
      "Evaluando especie Test: Specie_Dog\n",
      "loss     = 0.5671\n",
      "main_loss     = 0.3640\n",
      "aux_loss     = 0.5728\n",
      "main_acc     = 0.8532\n",
      "main_recall     = 0.7601\n",
      "aux_acc     = 0.6819\n",
      "aux_recall     = 0.7578\n",
      "\n",
      "\n",
      "Evaluando especie sin balancear: Specie_Dog\n",
      "loss     = 6.7890\n",
      "main_loss     = 5.5768\n",
      "aux_loss     = 5.6179\n",
      "main_acc     = 0.1387\n",
      "main_recall     = 0.0860\n",
      "aux_acc     = 0.0305\n",
      "aux_recall     = 0.0849\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Dog\n",
      "loss     = 6.7890\n",
      "main_loss     = 5.5768\n",
      "aux_loss     = 5.6179\n",
      "main_acc     = 0.1387\n",
      "main_recall     = 0.0860\n",
      "aux_acc     = 0.0305\n",
      "aux_recall     = 0.0849\n",
      "\n",
      "\n",
      "step: 25/800 ...  - loss: 4.8842 - val_loss: 4.6670\n",
      " - main_loss: 0.4709 - main_acc: 0.7579 - main_recall: 0.7441 - val_main_loss: 0.4151 - val_main_acc: 0.7936 - val_main_recall: 0.7343\n",
      " - aux_loss: 0.5001 - aux_acc: 0.7130 - aux_recall: 0.7440 - val_aux_loss: 0.4910 - val_aux_acc: 0.7193 - val_aux_recall: 0.7302\n",
      "step: 50/800 ...  - loss: 1.5723 - val_loss: 1.5279\n",
      " - main_loss: 0.3559 - main_acc: 0.8447 - main_recall: 0.7754 - val_main_loss: 0.3417 - val_main_acc: 0.8526 - val_main_recall: 0.7652\n",
      " - aux_loss: 0.4611 - aux_acc: 0.7347 - aux_recall: 0.7754 - val_aux_loss: 0.4795 - val_aux_acc: 0.7260 - val_aux_recall: 0.7602\n",
      "step: 75/800 ...  - loss: 0.9311 - val_loss: 0.9222\n",
      " - main_loss: 0.3347 - main_acc: 0.8544 - main_recall: 0.7885 - val_main_loss: 0.3351 - val_main_acc: 0.8559 - val_main_recall: 0.7844\n",
      " - aux_loss: 0.4562 - aux_acc: 0.7382 - aux_recall: 0.7884 - val_aux_loss: 0.4806 - val_aux_acc: 0.7262 - val_aux_recall: 0.7800\n",
      "step: 100/800 ...  - loss: 0.7336 - val_loss: 0.7339\n",
      " - main_loss: 0.3216 - main_acc: 0.8617 - main_recall: 0.7945 - val_main_loss: 0.3276 - val_main_acc: 0.8572 - val_main_recall: 0.7698\n",
      " - aux_loss: 0.4514 - aux_acc: 0.7420 - aux_recall: 0.7944 - val_aux_loss: 0.4806 - val_aux_acc: 0.7267 - val_aux_recall: 0.7645\n",
      "step: 125/800 ...  - loss: 0.6447 - val_loss: 0.6539\n",
      " - main_loss: 0.3100 - main_acc: 0.8666 - main_recall: 0.8001 - val_main_loss: 0.3221 - val_main_acc: 0.8608 - val_main_recall: 0.7844\n",
      " - aux_loss: 0.4474 - aux_acc: 0.7465 - aux_recall: 0.8000 - val_aux_loss: 0.4783 - val_aux_acc: 0.7268 - val_aux_recall: 0.7801\n",
      "step: 150/800 ...  - loss: 0.5967 - val_loss: 0.6180\n",
      " - main_loss: 0.2998 - main_acc: 0.8715 - main_recall: 0.8054 - val_main_loss: 0.3192 - val_main_acc: 0.8636 - val_main_recall: 0.7822\n",
      " - aux_loss: 0.4423 - aux_acc: 0.7509 - aux_recall: 0.8053 - val_aux_loss: 0.4831 - val_aux_acc: 0.7239 - val_aux_recall: 0.7773\n",
      "step: 175/800 ...  - loss: 0.5728 - val_loss: 0.5937\n",
      " - main_loss: 0.2916 - main_acc: 0.8756 - main_recall: 0.8093 - val_main_loss: 0.3131 - val_main_acc: 0.8649 - val_main_recall: 0.7879\n",
      " - aux_loss: 0.4407 - aux_acc: 0.7527 - aux_recall: 0.8092 - val_aux_loss: 0.4781 - val_aux_acc: 0.7280 - val_aux_recall: 0.7832\n",
      "step: 200/800 ...  - loss: 0.5457 - val_loss: 0.5717\n",
      " - main_loss: 0.2816 - main_acc: 0.8801 - main_recall: 0.8145 - val_main_loss: 0.3074 - val_main_acc: 0.8679 - val_main_recall: 0.7876\n",
      " - aux_loss: 0.4356 - aux_acc: 0.7575 - aux_recall: 0.8144 - val_aux_loss: 0.4752 - val_aux_acc: 0.7308 - val_aux_recall: 0.7828\n",
      "step: 225/800 ...  - loss: 0.5238 - val_loss: 0.5613\n",
      " - main_loss: 0.2728 - main_acc: 0.8846 - main_recall: 0.8185 - val_main_loss: 0.3067 - val_main_acc: 0.8673 - val_main_recall: 0.7909\n",
      " - aux_loss: 0.4302 - aux_acc: 0.7588 - aux_recall: 0.8184 - val_aux_loss: 0.4753 - val_aux_acc: 0.7296 - val_aux_recall: 0.7862\n",
      "step: 250/800 ...  - loss: 0.5067 - val_loss: 0.5529\n",
      " - main_loss: 0.2652 - main_acc: 0.8883 - main_recall: 0.8258 - val_main_loss: 0.3059 - val_main_acc: 0.8670 - val_main_recall: 0.7966\n",
      " - aux_loss: 0.4268 - aux_acc: 0.7628 - aux_recall: 0.8258 - val_aux_loss: 0.4785 - val_aux_acc: 0.7289 - val_aux_recall: 0.7920\n",
      "step: 275/800 ...  - loss: 0.4932 - val_loss: 0.5412\n",
      " - main_loss: 0.2589 - main_acc: 0.8905 - main_recall: 0.8287 - val_main_loss: 0.3023 - val_main_acc: 0.8696 - val_main_recall: 0.8029\n",
      " - aux_loss: 0.4241 - aux_acc: 0.7638 - aux_recall: 0.8286 - val_aux_loss: 0.4745 - val_aux_acc: 0.7311 - val_aux_recall: 0.7988\n",
      "step: 300/800 ...  - loss: 0.4876 - val_loss: 0.5411\n",
      " - main_loss: 0.2538 - main_acc: 0.8938 - main_recall: 0.8331 - val_main_loss: 0.3023 - val_main_acc: 0.8708 - val_main_recall: 0.8016\n",
      " - aux_loss: 0.4231 - aux_acc: 0.7659 - aux_recall: 0.8330 - val_aux_loss: 0.4759 - val_aux_acc: 0.7317 - val_aux_recall: 0.7973\n",
      "step: 325/800 ...  - loss: 0.4728 - val_loss: 0.5342\n",
      " - main_loss: 0.2481 - main_acc: 0.8960 - main_recall: 0.8344 - val_main_loss: 0.3040 - val_main_acc: 0.8689 - val_main_recall: 0.8034\n",
      " - aux_loss: 0.4190 - aux_acc: 0.7661 - aux_recall: 0.8344 - val_aux_loss: 0.4742 - val_aux_acc: 0.7296 - val_aux_recall: 0.7995\n",
      "step: 350/800 ...  - loss: 0.4624 - val_loss: 0.5291\n",
      " - main_loss: 0.2445 - main_acc: 0.8981 - main_recall: 0.8340 - val_main_loss: 0.3045 - val_main_acc: 0.8703 - val_main_recall: 0.7928\n",
      " - aux_loss: 0.4169 - aux_acc: 0.7684 - aux_recall: 0.8339 - val_aux_loss: 0.4734 - val_aux_acc: 0.7321 - val_aux_recall: 0.7880\n",
      "step: 375/800 ...  - loss: 0.4576 - val_loss: 0.5266\n",
      " - main_loss: 0.2395 - main_acc: 0.9001 - main_recall: 0.8389 - val_main_loss: 0.3021 - val_main_acc: 0.8716 - val_main_recall: 0.8137\n",
      " - aux_loss: 0.4144 - aux_acc: 0.7709 - aux_recall: 0.8388 - val_aux_loss: 0.4748 - val_aux_acc: 0.7285 - val_aux_recall: 0.8101\n",
      "step: 400/800 ...  - loss: 0.4448 - val_loss: 0.5261\n",
      " - main_loss: 0.2340 - main_acc: 0.9031 - main_recall: 0.8428 - val_main_loss: 0.3057 - val_main_acc: 0.8711 - val_main_recall: 0.8044\n",
      " - aux_loss: 0.4114 - aux_acc: 0.7729 - aux_recall: 0.8427 - val_aux_loss: 0.4780 - val_aux_acc: 0.7317 - val_aux_recall: 0.8003\n",
      "step: 425/800 ...  - loss: 0.4446 - val_loss: 0.5284\n",
      " - main_loss: 0.2309 - main_acc: 0.9044 - main_recall: 0.8429 - val_main_loss: 0.3056 - val_main_acc: 0.8711 - val_main_recall: 0.8116\n",
      " - aux_loss: 0.4115 - aux_acc: 0.7721 - aux_recall: 0.8427 - val_aux_loss: 0.4776 - val_aux_acc: 0.7289 - val_aux_recall: 0.8078\n",
      "step: 450/800 ...  - loss: 0.4408 - val_loss: 0.5313\n",
      " - main_loss: 0.2277 - main_acc: 0.9063 - main_recall: 0.8472 - val_main_loss: 0.3089 - val_main_acc: 0.8700 - val_main_recall: 0.8106\n",
      " - aux_loss: 0.4094 - aux_acc: 0.7716 - aux_recall: 0.8472 - val_aux_loss: 0.4829 - val_aux_acc: 0.7275 - val_aux_recall: 0.8065\n",
      "step: 475/800 ...  - loss: 0.4233 - val_loss: 0.5188\n",
      " - main_loss: 0.2215 - main_acc: 0.9086 - main_recall: 0.8497 - val_main_loss: 0.3058 - val_main_acc: 0.8717 - val_main_recall: 0.8057\n",
      " - aux_loss: 0.4058 - aux_acc: 0.7764 - aux_recall: 0.8496 - val_aux_loss: 0.4770 - val_aux_acc: 0.7310 - val_aux_recall: 0.8015\n",
      "step: 500/800 ...  - loss: 0.4370 - val_loss: 0.5339\n",
      " - main_loss: 0.2213 - main_acc: 0.9087 - main_recall: 0.8497 - val_main_loss: 0.3091 - val_main_acc: 0.8695 - val_main_recall: 0.8095\n",
      " - aux_loss: 0.4054 - aux_acc: 0.7765 - aux_recall: 0.8496 - val_aux_loss: 0.4801 - val_aux_acc: 0.7305 - val_aux_recall: 0.8057\n",
      "step: 525/800 ...  - loss: 0.4151 - val_loss: 0.5139\n",
      " - main_loss: 0.2162 - main_acc: 0.9115 - main_recall: 0.8508 - val_main_loss: 0.3041 - val_main_acc: 0.8736 - val_main_recall: 0.8089\n",
      " - aux_loss: 0.4034 - aux_acc: 0.7780 - aux_recall: 0.8508 - val_aux_loss: 0.4769 - val_aux_acc: 0.7325 - val_aux_recall: 0.8050\n",
      "step: 550/800 ...  - loss: 0.4218 - val_loss: 0.5308\n",
      " - main_loss: 0.2114 - main_acc: 0.9136 - main_recall: 0.8541 - val_main_loss: 0.3096 - val_main_acc: 0.8707 - val_main_recall: 0.8097\n",
      " - aux_loss: 0.4004 - aux_acc: 0.7803 - aux_recall: 0.8540 - val_aux_loss: 0.4817 - val_aux_acc: 0.7304 - val_aux_recall: 0.8056\n",
      "step: 575/800 ...  - loss: 0.4034 - val_loss: 0.5196\n",
      " - main_loss: 0.2068 - main_acc: 0.9154 - main_recall: 0.8571 - val_main_loss: 0.3113 - val_main_acc: 0.8713 - val_main_recall: 0.8045\n",
      " - aux_loss: 0.3974 - aux_acc: 0.7813 - aux_recall: 0.8570 - val_aux_loss: 0.4789 - val_aux_acc: 0.7330 - val_aux_recall: 0.8003\n",
      "step: 600/800 ...  - loss: 0.4035 - val_loss: 0.5209\n",
      " - main_loss: 0.2057 - main_acc: 0.9163 - main_recall: 0.8560 - val_main_loss: 0.3110 - val_main_acc: 0.8707 - val_main_recall: 0.8117\n",
      " - aux_loss: 0.3989 - aux_acc: 0.7813 - aux_recall: 0.8559 - val_aux_loss: 0.4793 - val_aux_acc: 0.7302 - val_aux_recall: 0.8074\n",
      "step: 625/800 ...  - loss: 0.4024 - val_loss: 0.5236\n",
      " - main_loss: 0.2036 - main_acc: 0.9177 - main_recall: 0.8593 - val_main_loss: 0.3128 - val_main_acc: 0.8697 - val_main_recall: 0.8067\n",
      " - aux_loss: 0.3957 - aux_acc: 0.7838 - aux_recall: 0.8592 - val_aux_loss: 0.4828 - val_aux_acc: 0.7325 - val_aux_recall: 0.8026\n",
      "step: 650/800 ...  - loss: 0.4007 - val_loss: 0.5296\n",
      " - main_loss: 0.1991 - main_acc: 0.9195 - main_recall: 0.8630 - val_main_loss: 0.3148 - val_main_acc: 0.8702 - val_main_recall: 0.8208\n",
      " - aux_loss: 0.3936 - aux_acc: 0.7862 - aux_recall: 0.8629 - val_aux_loss: 0.4854 - val_aux_acc: 0.7309 - val_aux_recall: 0.8170\n",
      "step: 675/800 ...  - loss: 0.3992 - val_loss: 0.5303\n",
      " - main_loss: 0.1973 - main_acc: 0.9201 - main_recall: 0.8628 - val_main_loss: 0.3145 - val_main_acc: 0.8709 - val_main_recall: 0.8186\n",
      " - aux_loss: 0.3920 - aux_acc: 0.7859 - aux_recall: 0.8627 - val_aux_loss: 0.4834 - val_aux_acc: 0.7314 - val_aux_recall: 0.8146\n",
      "step: 700/800 ...  - loss: 0.3906 - val_loss: 0.5232\n",
      " - main_loss: 0.1938 - main_acc: 0.9218 - main_recall: 0.8639 - val_main_loss: 0.3127 - val_main_acc: 0.8723 - val_main_recall: 0.8150\n",
      " - aux_loss: 0.3886 - aux_acc: 0.7887 - aux_recall: 0.8638 - val_aux_loss: 0.4792 - val_aux_acc: 0.7366 - val_aux_recall: 0.8110\n",
      "step: 725/800 ...  - loss: 0.4019 - val_loss: 0.5388\n",
      " - main_loss: 0.1952 - main_acc: 0.9211 - main_recall: 0.8652 - val_main_loss: 0.3187 - val_main_acc: 0.8716 - val_main_recall: 0.8099\n",
      " - aux_loss: 0.3917 - aux_acc: 0.7868 - aux_recall: 0.8651 - val_aux_loss: 0.4859 - val_aux_acc: 0.7303 - val_aux_recall: 0.8059\n",
      "step: 750/800 ...  - loss: 0.3825 - val_loss: 0.5270\n",
      " - main_loss: 0.1897 - main_acc: 0.9243 - main_recall: 0.8669 - val_main_loss: 0.3193 - val_main_acc: 0.8710 - val_main_recall: 0.8072\n",
      " - aux_loss: 0.3870 - aux_acc: 0.7888 - aux_recall: 0.8668 - val_aux_loss: 0.4856 - val_aux_acc: 0.7366 - val_aux_recall: 0.8033\n",
      "step: 775/800 ...  - loss: 0.3871 - val_loss: 0.5353\n",
      " - main_loss: 0.1890 - main_acc: 0.9243 - main_recall: 0.8672 - val_main_loss: 0.3214 - val_main_acc: 0.8696 - val_main_recall: 0.8138\n",
      " - aux_loss: 0.3875 - aux_acc: 0.7892 - aux_recall: 0.8671 - val_aux_loss: 0.4888 - val_aux_acc: 0.7329 - val_aux_recall: 0.8099\n",
      "step: 800/800 ...  - loss: 0.3756 - val_loss: 0.5226\n",
      " - main_loss: 0.1860 - main_acc: 0.9259 - main_recall: 0.8682 - val_main_loss: 0.3174 - val_main_acc: 0.8715 - val_main_recall: 0.8157\n",
      " - aux_loss: 0.3859 - aux_acc: 0.7909 - aux_recall: 0.8681 - val_aux_loss: 0.4849 - val_aux_acc: 0.7362 - val_aux_recall: 0.8119\n",
      "Evaluando especie Test: Specie_Human\n",
      "loss     = 0.5296\n",
      "main_loss     = 0.3271\n",
      "aux_loss     = 0.5159\n",
      "main_acc     = 0.8722\n",
      "main_recall     = 0.8295\n",
      "aux_acc     = 0.7138\n",
      "aux_recall     = 0.8281\n",
      "\n",
      "\n",
      "Evaluando especie sin balancear: Specie_Human\n",
      "loss     = 4.9458\n",
      "main_loss     = 3.7971\n",
      "aux_loss     = 5.2466\n",
      "main_acc     = 0.6660\n",
      "main_recall     = 0.0002\n",
      "aux_acc     = 0.6667\n",
      "aux_recall     = 0.0002\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Human\n",
      "loss     = 7.3640\n",
      "main_loss     = 5.6906\n",
      "aux_loss     = 7.8699\n",
      "main_acc     = 0.4996\n",
      "main_recall     = 0.0002\n",
      "aux_acc     = 0.5000\n",
      "aux_recall     = 0.0002\n",
      "\n",
      "\n",
      "step: 25/800 ...  - loss: 2.6719 - val_loss: 2.4682\n",
      " - main_loss: 0.4936 - main_acc: 0.7571 - main_recall: 0.5906 - val_main_loss: 0.4703 - val_main_acc: 0.7790 - val_main_recall: 0.6211\n",
      " - aux_loss: 0.5881 - aux_acc: 0.6649 - aux_recall: 0.5902 - val_aux_loss: 0.6006 - val_aux_acc: 0.6528 - val_aux_recall: 0.6126\n",
      "step: 50/800 ...  - loss: 0.8155 - val_loss: 0.8103\n",
      " - main_loss: 0.4154 - main_acc: 0.8157 - main_recall: 0.6179 - val_main_loss: 0.4148 - val_main_acc: 0.8140 - val_main_recall: 0.6267\n",
      " - aux_loss: 0.5735 - aux_acc: 0.6700 - aux_recall: 0.6173 - val_aux_loss: 0.5967 - val_aux_acc: 0.6549 - val_aux_recall: 0.6166\n",
      "step: 75/800 ...  - loss: 0.7056 - val_loss: 0.7103\n",
      " - main_loss: 0.3936 - main_acc: 0.8274 - main_recall: 0.6204 - val_main_loss: 0.3964 - val_main_acc: 0.8218 - val_main_recall: 0.6370\n",
      " - aux_loss: 0.5690 - aux_acc: 0.6735 - aux_recall: 0.6199 - val_aux_loss: 0.5864 - val_aux_acc: 0.6580 - val_aux_recall: 0.6279\n",
      "step: 100/800 ...  - loss: 0.6610 - val_loss: 0.6674\n",
      " - main_loss: 0.3787 - main_acc: 0.8348 - main_recall: 0.6363 - val_main_loss: 0.3857 - val_main_acc: 0.8289 - val_main_recall: 0.6516\n",
      " - aux_loss: 0.5647 - aux_acc: 0.6754 - aux_recall: 0.6357 - val_aux_loss: 0.5804 - val_aux_acc: 0.6627 - val_aux_recall: 0.6416\n",
      "step: 125/800 ...  - loss: 0.6342 - val_loss: 0.6469\n",
      " - main_loss: 0.3656 - main_acc: 0.8411 - main_recall: 0.6458 - val_main_loss: 0.3765 - val_main_acc: 0.8329 - val_main_recall: 0.6275\n",
      " - aux_loss: 0.5608 - aux_acc: 0.6795 - aux_recall: 0.6452 - val_aux_loss: 0.5809 - val_aux_acc: 0.6642 - val_aux_recall: 0.6166\n",
      "step: 150/800 ...  - loss: 0.6141 - val_loss: 0.6241\n",
      " - main_loss: 0.3553 - main_acc: 0.8454 - main_recall: 0.6520 - val_main_loss: 0.3667 - val_main_acc: 0.8382 - val_main_recall: 0.6654\n",
      " - aux_loss: 0.5593 - aux_acc: 0.6801 - aux_recall: 0.6514 - val_aux_loss: 0.5751 - val_aux_acc: 0.6646 - val_aux_recall: 0.6555\n",
      "step: 175/800 ...  - loss: 0.6008 - val_loss: 0.6194\n",
      " - main_loss: 0.3467 - main_acc: 0.8496 - main_recall: 0.6575 - val_main_loss: 0.3643 - val_main_acc: 0.8403 - val_main_recall: 0.6439\n",
      " - aux_loss: 0.5572 - aux_acc: 0.6821 - aux_recall: 0.6569 - val_aux_loss: 0.5731 - val_aux_acc: 0.6685 - val_aux_recall: 0.6326\n",
      "step: 200/800 ...  - loss: 0.5895 - val_loss: 0.6101\n",
      " - main_loss: 0.3378 - main_acc: 0.8542 - main_recall: 0.6669 - val_main_loss: 0.3571 - val_main_acc: 0.8423 - val_main_recall: 0.6701\n",
      " - aux_loss: 0.5558 - aux_acc: 0.6838 - aux_recall: 0.6663 - val_aux_loss: 0.5730 - val_aux_acc: 0.6655 - val_aux_recall: 0.6602\n",
      "step: 225/800 ...  - loss: 0.5769 - val_loss: 0.5990\n",
      " - main_loss: 0.3317 - main_acc: 0.8579 - main_recall: 0.6723 - val_main_loss: 0.3538 - val_main_acc: 0.8449 - val_main_recall: 0.6574\n",
      " - aux_loss: 0.5528 - aux_acc: 0.6863 - aux_recall: 0.6718 - val_aux_loss: 0.5682 - val_aux_acc: 0.6718 - val_aux_recall: 0.6465\n",
      "step: 250/800 ...  - loss: 0.5613 - val_loss: 0.5976\n",
      " - main_loss: 0.3239 - main_acc: 0.8603 - main_recall: 0.6782 - val_main_loss: 0.3559 - val_main_acc: 0.8436 - val_main_recall: 0.6725\n",
      " - aux_loss: 0.5502 - aux_acc: 0.6879 - aux_recall: 0.6777 - val_aux_loss: 0.5720 - val_aux_acc: 0.6695 - val_aux_recall: 0.6628\n",
      "step: 275/800 ...  - loss: 0.5520 - val_loss: 0.5890\n",
      " - main_loss: 0.3186 - main_acc: 0.8623 - main_recall: 0.6831 - val_main_loss: 0.3527 - val_main_acc: 0.8447 - val_main_recall: 0.6774\n",
      " - aux_loss: 0.5487 - aux_acc: 0.6893 - aux_recall: 0.6826 - val_aux_loss: 0.5680 - val_aux_acc: 0.6744 - val_aux_recall: 0.6678\n",
      "step: 300/800 ...  - loss: 0.5524 - val_loss: 0.5964\n",
      " - main_loss: 0.3128 - main_acc: 0.8651 - main_recall: 0.6875 - val_main_loss: 0.3528 - val_main_acc: 0.8447 - val_main_recall: 0.6644\n",
      " - aux_loss: 0.5474 - aux_acc: 0.6913 - aux_recall: 0.6869 - val_aux_loss: 0.5718 - val_aux_acc: 0.6721 - val_aux_recall: 0.6546\n",
      "step: 325/800 ...  - loss: 0.5375 - val_loss: 0.5837\n",
      " - main_loss: 0.3073 - main_acc: 0.8679 - main_recall: 0.6916 - val_main_loss: 0.3498 - val_main_acc: 0.8462 - val_main_recall: 0.6760\n",
      " - aux_loss: 0.5448 - aux_acc: 0.6935 - aux_recall: 0.6911 - val_aux_loss: 0.5702 - val_aux_acc: 0.6725 - val_aux_recall: 0.6664\n",
      "step: 350/800 ...  - loss: 0.5314 - val_loss: 0.5851\n",
      " - main_loss: 0.3028 - main_acc: 0.8705 - main_recall: 0.6955 - val_main_loss: 0.3518 - val_main_acc: 0.8445 - val_main_recall: 0.6736\n",
      " - aux_loss: 0.5437 - aux_acc: 0.6939 - aux_recall: 0.6950 - val_aux_loss: 0.5693 - val_aux_acc: 0.6735 - val_aux_recall: 0.6638\n",
      "step: 375/800 ...  - loss: 0.5259 - val_loss: 0.5837\n",
      " - main_loss: 0.2987 - main_acc: 0.8726 - main_recall: 0.6981 - val_main_loss: 0.3521 - val_main_acc: 0.8456 - val_main_recall: 0.6879\n",
      " - aux_loss: 0.5427 - aux_acc: 0.6950 - aux_recall: 0.6975 - val_aux_loss: 0.5697 - val_aux_acc: 0.6732 - val_aux_recall: 0.6787\n",
      "step: 400/800 ...  - loss: 0.5192 - val_loss: 0.5787\n",
      " - main_loss: 0.2940 - main_acc: 0.8741 - main_recall: 0.6987 - val_main_loss: 0.3509 - val_main_acc: 0.8458 - val_main_recall: 0.6783\n",
      " - aux_loss: 0.5420 - aux_acc: 0.6958 - aux_recall: 0.6982 - val_aux_loss: 0.5706 - val_aux_acc: 0.6751 - val_aux_recall: 0.6690\n",
      "step: 425/800 ...  - loss: 0.5120 - val_loss: 0.5771\n",
      " - main_loss: 0.2907 - main_acc: 0.8765 - main_recall: 0.7015 - val_main_loss: 0.3513 - val_main_acc: 0.8460 - val_main_recall: 0.6745\n",
      " - aux_loss: 0.5391 - aux_acc: 0.6983 - aux_recall: 0.7009 - val_aux_loss: 0.5693 - val_aux_acc: 0.6752 - val_aux_recall: 0.6654\n",
      "step: 450/800 ...  - loss: 0.5071 - val_loss: 0.5777\n",
      " - main_loss: 0.2869 - main_acc: 0.8782 - main_recall: 0.7044 - val_main_loss: 0.3521 - val_main_acc: 0.8464 - val_main_recall: 0.6758\n",
      " - aux_loss: 0.5385 - aux_acc: 0.6990 - aux_recall: 0.7038 - val_aux_loss: 0.5705 - val_aux_acc: 0.6746 - val_aux_recall: 0.6663\n",
      "step: 475/800 ...  - loss: 0.4986 - val_loss: 0.5740\n",
      " - main_loss: 0.2825 - main_acc: 0.8804 - main_recall: 0.7115 - val_main_loss: 0.3520 - val_main_acc: 0.8465 - val_main_recall: 0.6787\n",
      " - aux_loss: 0.5348 - aux_acc: 0.7020 - aux_recall: 0.7109 - val_aux_loss: 0.5686 - val_aux_acc: 0.6770 - val_aux_recall: 0.6695\n",
      "step: 500/800 ...  - loss: 0.4997 - val_loss: 0.5767\n",
      " - main_loss: 0.2812 - main_acc: 0.8807 - main_recall: 0.7115 - val_main_loss: 0.3520 - val_main_acc: 0.8463 - val_main_recall: 0.6731\n",
      " - aux_loss: 0.5343 - aux_acc: 0.7013 - aux_recall: 0.7111 - val_aux_loss: 0.5722 - val_aux_acc: 0.6752 - val_aux_recall: 0.6641\n",
      "step: 525/800 ...  - loss: 0.4918 - val_loss: 0.5782\n",
      " - main_loss: 0.2754 - main_acc: 0.8832 - main_recall: 0.7149 - val_main_loss: 0.3546 - val_main_acc: 0.8456 - val_main_recall: 0.6801\n",
      " - aux_loss: 0.5315 - aux_acc: 0.7034 - aux_recall: 0.7144 - val_aux_loss: 0.5719 - val_aux_acc: 0.6756 - val_aux_recall: 0.6711\n",
      "step: 550/800 ...  - loss: 0.4880 - val_loss: 0.5748\n",
      " - main_loss: 0.2737 - main_acc: 0.8847 - main_recall: 0.7176 - val_main_loss: 0.3538 - val_main_acc: 0.8471 - val_main_recall: 0.6790\n",
      " - aux_loss: 0.5322 - aux_acc: 0.7037 - aux_recall: 0.7170 - val_aux_loss: 0.5722 - val_aux_acc: 0.6774 - val_aux_recall: 0.6697\n",
      "step: 575/800 ...  - loss: 0.4784 - val_loss: 0.5720\n",
      " - main_loss: 0.2689 - main_acc: 0.8870 - main_recall: 0.7239 - val_main_loss: 0.3546 - val_main_acc: 0.8469 - val_main_recall: 0.6757\n",
      " - aux_loss: 0.5302 - aux_acc: 0.7043 - aux_recall: 0.7233 - val_aux_loss: 0.5737 - val_aux_acc: 0.6765 - val_aux_recall: 0.6666\n",
      "step: 600/800 ...  - loss: 0.4768 - val_loss: 0.5749\n",
      " - main_loss: 0.2665 - main_acc: 0.8878 - main_recall: 0.7239 - val_main_loss: 0.3572 - val_main_acc: 0.8465 - val_main_recall: 0.6880\n",
      " - aux_loss: 0.5290 - aux_acc: 0.7063 - aux_recall: 0.7234 - val_aux_loss: 0.5731 - val_aux_acc: 0.6788 - val_aux_recall: 0.6790\n",
      "step: 625/800 ...  - loss: 0.4721 - val_loss: 0.5759\n",
      " - main_loss: 0.2641 - main_acc: 0.8889 - main_recall: 0.7230 - val_main_loss: 0.3587 - val_main_acc: 0.8448 - val_main_recall: 0.6810\n",
      " - aux_loss: 0.5277 - aux_acc: 0.7071 - aux_recall: 0.7225 - val_aux_loss: 0.5754 - val_aux_acc: 0.6758 - val_aux_recall: 0.6718\n",
      "step: 650/800 ...  - loss: 0.4711 - val_loss: 0.5763\n",
      " - main_loss: 0.2621 - main_acc: 0.8900 - main_recall: 0.7267 - val_main_loss: 0.3587 - val_main_acc: 0.8457 - val_main_recall: 0.6840\n",
      " - aux_loss: 0.5265 - aux_acc: 0.7080 - aux_recall: 0.7262 - val_aux_loss: 0.5736 - val_aux_acc: 0.6794 - val_aux_recall: 0.6752\n",
      "step: 675/800 ...  - loss: 0.4653 - val_loss: 0.5727\n",
      " - main_loss: 0.2597 - main_acc: 0.8914 - main_recall: 0.7261 - val_main_loss: 0.3575 - val_main_acc: 0.8462 - val_main_recall: 0.6935\n",
      " - aux_loss: 0.5253 - aux_acc: 0.7078 - aux_recall: 0.7257 - val_aux_loss: 0.5758 - val_aux_acc: 0.6764 - val_aux_recall: 0.6845\n",
      "step: 700/800 ...  - loss: 0.4634 - val_loss: 0.5808\n",
      " - main_loss: 0.2571 - main_acc: 0.8919 - main_recall: 0.7283 - val_main_loss: 0.3645 - val_main_acc: 0.8453 - val_main_recall: 0.6963\n",
      " - aux_loss: 0.5250 - aux_acc: 0.7084 - aux_recall: 0.7277 - val_aux_loss: 0.5764 - val_aux_acc: 0.6778 - val_aux_recall: 0.6877\n",
      "step: 725/800 ...  - loss: 0.4628 - val_loss: 0.5830\n",
      " - main_loss: 0.2554 - main_acc: 0.8933 - main_recall: 0.7308 - val_main_loss: 0.3652 - val_main_acc: 0.8461 - val_main_recall: 0.6874\n",
      " - aux_loss: 0.5240 - aux_acc: 0.7094 - aux_recall: 0.7303 - val_aux_loss: 0.5763 - val_aux_acc: 0.6780 - val_aux_recall: 0.6785\n",
      "step: 750/800 ...  - loss: 0.4544 - val_loss: 0.5732\n",
      " - main_loss: 0.2520 - main_acc: 0.8945 - main_recall: 0.7328 - val_main_loss: 0.3612 - val_main_acc: 0.8461 - val_main_recall: 0.6933\n",
      " - aux_loss: 0.5224 - aux_acc: 0.7107 - aux_recall: 0.7322 - val_aux_loss: 0.5761 - val_aux_acc: 0.6779 - val_aux_recall: 0.6840\n",
      "step: 775/800 ...  - loss: 0.4553 - val_loss: 0.5795\n",
      " - main_loss: 0.2518 - main_acc: 0.8946 - main_recall: 0.7325 - val_main_loss: 0.3652 - val_main_acc: 0.8455 - val_main_recall: 0.6912\n",
      " - aux_loss: 0.5217 - aux_acc: 0.7102 - aux_recall: 0.7319 - val_aux_loss: 0.5800 - val_aux_acc: 0.6775 - val_aux_recall: 0.6820\n",
      "step: 800/800 ...  - loss: 0.4513 - val_loss: 0.5728\n",
      " - main_loss: 0.2506 - main_acc: 0.8953 - main_recall: 0.7309 - val_main_loss: 0.3617 - val_main_acc: 0.8459 - val_main_recall: 0.6851\n",
      " - aux_loss: 0.5208 - aux_acc: 0.7116 - aux_recall: 0.7304 - val_aux_loss: 0.5755 - val_aux_acc: 0.6804 - val_aux_recall: 0.6759\n",
      "Evaluando especie Test: Specie_Mouse\n",
      "loss     = 0.5749\n",
      "main_loss     = 0.3598\n",
      "aux_loss     = 0.5719\n",
      "main_acc     = 0.8494\n",
      "main_recall     = 0.6612\n",
      "aux_acc     = 0.6914\n",
      "aux_recall     = 0.6559\n",
      "\n",
      "\n",
      "Evaluando especie sin balancear: Specie_Mouse\n",
      "loss     = 0.9060\n",
      "main_loss     = 0.5763\n",
      "aux_loss     = 1.1455\n",
      "main_acc     = 0.7656\n",
      "main_recall     = 0.6107\n",
      "aux_acc     = 0.4544\n",
      "aux_recall     = 0.6074\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Mouse\n",
      "loss     = 0.9060\n",
      "main_loss     = 0.5763\n",
      "aux_loss     = 1.1455\n",
      "main_acc     = 0.7656\n",
      "main_recall     = 0.6107\n",
      "aux_acc     = 0.4544\n",
      "aux_recall     = 0.6074\n",
      "\n",
      "\n",
      "step: 25/800 ...  - loss: 4.3951 - val_loss: 4.1876\n",
      " - main_loss: 0.4398 - main_acc: 0.7812 - main_recall: 0.7218 - val_main_loss: 0.4022 - val_main_acc: 0.8029 - val_main_recall: 0.7196\n",
      " - aux_loss: 0.4883 - aux_acc: 0.7254 - aux_recall: 0.7214 - val_aux_loss: 0.4904 - val_aux_acc: 0.7257 - val_aux_recall: 0.7187\n",
      "step: 50/800 ...  - loss: 0.9626 - val_loss: 0.9716\n",
      " - main_loss: 0.3470 - main_acc: 0.8458 - main_recall: 0.7704 - val_main_loss: 0.3605 - val_main_acc: 0.8428 - val_main_recall: 0.7532\n",
      " - aux_loss: 0.4660 - aux_acc: 0.7339 - aux_recall: 0.7694 - val_aux_loss: 0.5019 - val_aux_acc: 0.7241 - val_aux_recall: 0.7510\n",
      "step: 75/800 ...  - loss: 0.6660 - val_loss: 0.6865\n",
      " - main_loss: 0.3285 - main_acc: 0.8561 - main_recall: 0.7784 - val_main_loss: 0.3432 - val_main_acc: 0.8496 - val_main_recall: 0.7624\n",
      " - aux_loss: 0.4638 - aux_acc: 0.7335 - aux_recall: 0.7773 - val_aux_loss: 0.5033 - val_aux_acc: 0.7158 - val_aux_recall: 0.7602\n",
      "step: 100/800 ...  - loss: 0.5901 - val_loss: 0.6103\n",
      " - main_loss: 0.3133 - main_acc: 0.8641 - main_recall: 0.7831 - val_main_loss: 0.3286 - val_main_acc: 0.8579 - val_main_recall: 0.7584\n",
      " - aux_loss: 0.4596 - aux_acc: 0.7367 - aux_recall: 0.7819 - val_aux_loss: 0.4921 - val_aux_acc: 0.7194 - val_aux_recall: 0.7562\n",
      "step: 125/800 ...  - loss: 0.5574 - val_loss: 0.5819\n",
      " - main_loss: 0.3030 - main_acc: 0.8684 - main_recall: 0.7856 - val_main_loss: 0.3216 - val_main_acc: 0.8589 - val_main_recall: 0.7699\n",
      " - aux_loss: 0.4554 - aux_acc: 0.7395 - aux_recall: 0.7845 - val_aux_loss: 0.4927 - val_aux_acc: 0.7170 - val_aux_recall: 0.7683\n",
      "step: 150/800 ...  - loss: 0.5296 - val_loss: 0.5594\n",
      " - main_loss: 0.2943 - main_acc: 0.8732 - main_recall: 0.7884 - val_main_loss: 0.3178 - val_main_acc: 0.8617 - val_main_recall: 0.7653\n",
      " - aux_loss: 0.4498 - aux_acc: 0.7420 - aux_recall: 0.7872 - val_aux_loss: 0.4817 - val_aux_acc: 0.7225 - val_aux_recall: 0.7634\n",
      "step: 175/800 ...  - loss: 0.5052 - val_loss: 0.5366\n",
      " - main_loss: 0.2863 - main_acc: 0.8767 - main_recall: 0.7963 - val_main_loss: 0.3122 - val_main_acc: 0.8648 - val_main_recall: 0.7650\n",
      " - aux_loss: 0.4443 - aux_acc: 0.7465 - aux_recall: 0.7951 - val_aux_loss: 0.4798 - val_aux_acc: 0.7234 - val_aux_recall: 0.7631\n",
      "step: 200/800 ...  - loss: 0.4898 - val_loss: 0.5268\n",
      " - main_loss: 0.2777 - main_acc: 0.8806 - main_recall: 0.7985 - val_main_loss: 0.3073 - val_main_acc: 0.8680 - val_main_recall: 0.7857\n",
      " - aux_loss: 0.4418 - aux_acc: 0.7473 - aux_recall: 0.7974 - val_aux_loss: 0.4748 - val_aux_acc: 0.7229 - val_aux_recall: 0.7839\n",
      "step: 225/800 ...  - loss: 0.4747 - val_loss: 0.5137\n",
      " - main_loss: 0.2712 - main_acc: 0.8833 - main_recall: 0.8033 - val_main_loss: 0.3037 - val_main_acc: 0.8694 - val_main_recall: 0.7779\n",
      " - aux_loss: 0.4375 - aux_acc: 0.7518 - aux_recall: 0.8022 - val_aux_loss: 0.4706 - val_aux_acc: 0.7260 - val_aux_recall: 0.7762\n",
      "step: 250/800 ...  - loss: 0.4587 - val_loss: 0.5046\n",
      " - main_loss: 0.2640 - main_acc: 0.8856 - main_recall: 0.8088 - val_main_loss: 0.3032 - val_main_acc: 0.8704 - val_main_recall: 0.7894\n",
      " - aux_loss: 0.4354 - aux_acc: 0.7533 - aux_recall: 0.8078 - val_aux_loss: 0.4689 - val_aux_acc: 0.7300 - val_aux_recall: 0.7879\n",
      "step: 275/800 ...  - loss: 0.4515 - val_loss: 0.5034\n",
      " - main_loss: 0.2590 - main_acc: 0.8882 - main_recall: 0.8106 - val_main_loss: 0.3029 - val_main_acc: 0.8705 - val_main_recall: 0.7849\n",
      " - aux_loss: 0.4333 - aux_acc: 0.7543 - aux_recall: 0.8095 - val_aux_loss: 0.4705 - val_aux_acc: 0.7274 - val_aux_recall: 0.7831\n",
      "step: 300/800 ...  - loss: 0.4477 - val_loss: 0.5025\n",
      " - main_loss: 0.2543 - main_acc: 0.8904 - main_recall: 0.8140 - val_main_loss: 0.3020 - val_main_acc: 0.8704 - val_main_recall: 0.7932\n",
      " - aux_loss: 0.4320 - aux_acc: 0.7555 - aux_recall: 0.8129 - val_aux_loss: 0.4702 - val_aux_acc: 0.7284 - val_aux_recall: 0.7916\n",
      "step: 325/800 ...  - loss: 0.4406 - val_loss: 0.4985\n",
      " - main_loss: 0.2503 - main_acc: 0.8916 - main_recall: 0.8166 - val_main_loss: 0.3009 - val_main_acc: 0.8714 - val_main_recall: 0.7928\n",
      " - aux_loss: 0.4305 - aux_acc: 0.7556 - aux_recall: 0.8155 - val_aux_loss: 0.4690 - val_aux_acc: 0.7296 - val_aux_recall: 0.7911\n",
      "step: 350/800 ...  - loss: 0.4303 - val_loss: 0.4934\n",
      " - main_loss: 0.2453 - main_acc: 0.8946 - main_recall: 0.8195 - val_main_loss: 0.3007 - val_main_acc: 0.8721 - val_main_recall: 0.7921\n",
      " - aux_loss: 0.4283 - aux_acc: 0.7580 - aux_recall: 0.8185 - val_aux_loss: 0.4686 - val_aux_acc: 0.7294 - val_aux_recall: 0.7906\n",
      "step: 375/800 ...  - loss: 0.4283 - val_loss: 0.4962\n",
      " - main_loss: 0.2420 - main_acc: 0.8958 - main_recall: 0.8216 - val_main_loss: 0.3023 - val_main_acc: 0.8722 - val_main_recall: 0.7934\n",
      " - aux_loss: 0.4272 - aux_acc: 0.7583 - aux_recall: 0.8206 - val_aux_loss: 0.4669 - val_aux_acc: 0.7332 - val_aux_recall: 0.7917\n",
      "step: 400/800 ...  - loss: 0.4215 - val_loss: 0.4903\n",
      " - main_loss: 0.2388 - main_acc: 0.8974 - main_recall: 0.8247 - val_main_loss: 0.2997 - val_main_acc: 0.8729 - val_main_recall: 0.8027\n",
      " - aux_loss: 0.4261 - aux_acc: 0.7590 - aux_recall: 0.8236 - val_aux_loss: 0.4654 - val_aux_acc: 0.7315 - val_aux_recall: 0.8011\n",
      "step: 425/800 ...  - loss: 0.4151 - val_loss: 0.4881\n",
      " - main_loss: 0.2350 - main_acc: 0.8996 - main_recall: 0.8265 - val_main_loss: 0.2994 - val_main_acc: 0.8738 - val_main_recall: 0.8056\n",
      " - aux_loss: 0.4239 - aux_acc: 0.7621 - aux_recall: 0.8256 - val_aux_loss: 0.4658 - val_aux_acc: 0.7310 - val_aux_recall: 0.8042\n",
      "step: 450/800 ...  - loss: 0.4109 - val_loss: 0.4894\n",
      " - main_loss: 0.2307 - main_acc: 0.9016 - main_recall: 0.8294 - val_main_loss: 0.3011 - val_main_acc: 0.8735 - val_main_recall: 0.8023\n",
      " - aux_loss: 0.4233 - aux_acc: 0.7613 - aux_recall: 0.8284 - val_aux_loss: 0.4676 - val_aux_acc: 0.7321 - val_aux_recall: 0.8008\n",
      "step: 475/800 ...  - loss: 0.4095 - val_loss: 0.4937\n",
      " - main_loss: 0.2295 - main_acc: 0.9021 - main_recall: 0.8277 - val_main_loss: 0.3037 - val_main_acc: 0.8729 - val_main_recall: 0.7939\n",
      " - aux_loss: 0.4231 - aux_acc: 0.7621 - aux_recall: 0.8268 - val_aux_loss: 0.4710 - val_aux_acc: 0.7311 - val_aux_recall: 0.7924\n",
      "step: 500/800 ...  - loss: 0.4044 - val_loss: 0.4917\n",
      " - main_loss: 0.2267 - main_acc: 0.9037 - main_recall: 0.8301 - val_main_loss: 0.3037 - val_main_acc: 0.8730 - val_main_recall: 0.8013\n",
      " - aux_loss: 0.4212 - aux_acc: 0.7630 - aux_recall: 0.8290 - val_aux_loss: 0.4704 - val_aux_acc: 0.7328 - val_aux_recall: 0.7998\n",
      "step: 525/800 ...  - loss: 0.3976 - val_loss: 0.4871\n",
      " - main_loss: 0.2242 - main_acc: 0.9045 - main_recall: 0.8306 - val_main_loss: 0.3041 - val_main_acc: 0.8731 - val_main_recall: 0.8009\n",
      " - aux_loss: 0.4217 - aux_acc: 0.7636 - aux_recall: 0.8296 - val_aux_loss: 0.4707 - val_aux_acc: 0.7313 - val_aux_recall: 0.7994\n",
      "step: 550/800 ...  - loss: 0.3961 - val_loss: 0.4883\n",
      " - main_loss: 0.2214 - main_acc: 0.9061 - main_recall: 0.8313 - val_main_loss: 0.3042 - val_main_acc: 0.8738 - val_main_recall: 0.7999\n",
      " - aux_loss: 0.4197 - aux_acc: 0.7642 - aux_recall: 0.8303 - val_aux_loss: 0.4692 - val_aux_acc: 0.7350 - val_aux_recall: 0.7985\n",
      "step: 575/800 ...  - loss: 0.3904 - val_loss: 0.4867\n",
      " - main_loss: 0.2176 - main_acc: 0.9072 - main_recall: 0.8343 - val_main_loss: 0.3037 - val_main_acc: 0.8733 - val_main_recall: 0.7968\n",
      " - aux_loss: 0.4186 - aux_acc: 0.7649 - aux_recall: 0.8331 - val_aux_loss: 0.4699 - val_aux_acc: 0.7331 - val_aux_recall: 0.7953\n",
      "step: 600/800 ...  - loss: 0.3871 - val_loss: 0.4869\n",
      " - main_loss: 0.2144 - main_acc: 0.9091 - main_recall: 0.8373 - val_main_loss: 0.3041 - val_main_acc: 0.8731 - val_main_recall: 0.8017\n",
      " - aux_loss: 0.4170 - aux_acc: 0.7670 - aux_recall: 0.8363 - val_aux_loss: 0.4691 - val_aux_acc: 0.7358 - val_aux_recall: 0.8001\n",
      "step: 625/800 ...  - loss: 0.3829 - val_loss: 0.4888\n",
      " - main_loss: 0.2121 - main_acc: 0.9107 - main_recall: 0.8376 - val_main_loss: 0.3061 - val_main_acc: 0.8735 - val_main_recall: 0.8090\n",
      " - aux_loss: 0.4159 - aux_acc: 0.7670 - aux_recall: 0.8365 - val_aux_loss: 0.4756 - val_aux_acc: 0.7307 - val_aux_recall: 0.8075\n",
      "step: 650/800 ...  - loss: 0.3784 - val_loss: 0.4898\n",
      " - main_loss: 0.2096 - main_acc: 0.9119 - main_recall: 0.8418 - val_main_loss: 0.3094 - val_main_acc: 0.8724 - val_main_recall: 0.8078\n",
      " - aux_loss: 0.4131 - aux_acc: 0.7691 - aux_recall: 0.8408 - val_aux_loss: 0.4716 - val_aux_acc: 0.7342 - val_aux_recall: 0.8063\n",
      "step: 675/800 ...  - loss: 0.3765 - val_loss: 0.4926\n",
      " - main_loss: 0.2074 - main_acc: 0.9126 - main_recall: 0.8385 - val_main_loss: 0.3114 - val_main_acc: 0.8733 - val_main_recall: 0.7971\n",
      " - aux_loss: 0.4137 - aux_acc: 0.7687 - aux_recall: 0.8374 - val_aux_loss: 0.4731 - val_aux_acc: 0.7335 - val_aux_recall: 0.7954\n",
      "step: 700/800 ...  - loss: 0.3741 - val_loss: 0.4869\n",
      " - main_loss: 0.2061 - main_acc: 0.9123 - main_recall: 0.8390 - val_main_loss: 0.3076 - val_main_acc: 0.8741 - val_main_recall: 0.7999\n",
      " - aux_loss: 0.4128 - aux_acc: 0.7683 - aux_recall: 0.8378 - val_aux_loss: 0.4718 - val_aux_acc: 0.7360 - val_aux_recall: 0.7983\n",
      "step: 725/800 ...  - loss: 0.3724 - val_loss: 0.4914\n",
      " - main_loss: 0.2046 - main_acc: 0.9136 - main_recall: 0.8397 - val_main_loss: 0.3113 - val_main_acc: 0.8714 - val_main_recall: 0.7995\n",
      " - aux_loss: 0.4122 - aux_acc: 0.7689 - aux_recall: 0.8386 - val_aux_loss: 0.4736 - val_aux_acc: 0.7329 - val_aux_recall: 0.7979\n",
      "step: 750/800 ...  - loss: 0.3699 - val_loss: 0.4957\n",
      " - main_loss: 0.2023 - main_acc: 0.9152 - main_recall: 0.8421 - val_main_loss: 0.3144 - val_main_acc: 0.8733 - val_main_recall: 0.7915\n",
      " - aux_loss: 0.4096 - aux_acc: 0.7707 - aux_recall: 0.8410 - val_aux_loss: 0.4764 - val_aux_acc: 0.7356 - val_aux_recall: 0.7897\n",
      "step: 775/800 ...  - loss: 0.3652 - val_loss: 0.4951\n",
      " - main_loss: 0.1989 - main_acc: 0.9165 - main_recall: 0.8433 - val_main_loss: 0.3158 - val_main_acc: 0.8712 - val_main_recall: 0.8026\n",
      " - aux_loss: 0.4099 - aux_acc: 0.7708 - aux_recall: 0.8423 - val_aux_loss: 0.4763 - val_aux_acc: 0.7364 - val_aux_recall: 0.8011\n",
      "step: 800/800 ...  - loss: 0.3666 - val_loss: 0.4962\n",
      " - main_loss: 0.1996 - main_acc: 0.9163 - main_recall: 0.8430 - val_main_loss: 0.3157 - val_main_acc: 0.8719 - val_main_recall: 0.8021\n",
      " - aux_loss: 0.4092 - aux_acc: 0.7706 - aux_recall: 0.8419 - val_aux_loss: 0.4759 - val_aux_acc: 0.7357 - val_aux_recall: 0.8006\n",
      "Evaluando especie Test: Specie_Pig\n",
      "loss     = 0.4928\n",
      "main_loss     = 0.3101\n",
      "aux_loss     = 0.4915\n",
      "main_acc     = 0.8780\n",
      "main_recall     = 0.8112\n",
      "aux_acc     = 0.7417\n",
      "aux_recall     = 0.8112\n",
      "\n",
      "\n",
      "Evaluando especie sin balancear: Specie_Pig\n",
      "loss     = 2.2548\n",
      "main_loss     = 1.6396\n",
      "aux_loss     = 2.6538\n",
      "main_acc     = 0.6266\n",
      "main_recall     = 0.1776\n",
      "aux_acc     = 0.5895\n",
      "aux_recall     = 0.1776\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Pig\n",
      "loss     = 2.8618\n",
      "main_loss     = 2.0907\n",
      "aux_loss     = 3.4331\n",
      "main_acc     = 0.5343\n",
      "main_recall     = 0.1776\n",
      "aux_acc     = 0.4906\n",
      "aux_recall     = 0.1776\n",
      "\n",
      "\n",
      "step: 25/800 ...  - loss: 4.4516 - val_loss: 4.2221\n",
      " - main_loss: 0.4569 - main_acc: 0.7708 - main_recall: 0.6211 - val_main_loss: 0.4051 - val_main_acc: 0.8071 - val_main_recall: 0.6593\n",
      " - aux_loss: 0.5253 - aux_acc: 0.7086 - aux_recall: 0.6200 - val_aux_loss: 0.4937 - val_aux_acc: 0.7325 - val_aux_recall: 0.6531\n",
      "step: 50/800 ...  - loss: 0.9388 - val_loss: 0.9179\n",
      " - main_loss: 0.3646 - main_acc: 0.8359 - main_recall: 0.6838 - val_main_loss: 0.3581 - val_main_acc: 0.8418 - val_main_recall: 0.6813\n",
      " - aux_loss: 0.4996 - aux_acc: 0.7204 - aux_recall: 0.6817 - val_aux_loss: 0.5026 - val_aux_acc: 0.7424 - val_aux_recall: 0.6694\n",
      "step: 75/800 ...  - loss: 0.6599 - val_loss: 0.6578\n",
      " - main_loss: 0.3425 - main_acc: 0.8492 - main_recall: 0.6892 - val_main_loss: 0.3395 - val_main_acc: 0.8511 - val_main_recall: 0.7067\n",
      " - aux_loss: 0.4973 - aux_acc: 0.7217 - aux_recall: 0.6872 - val_aux_loss: 0.5024 - val_aux_acc: 0.7318 - val_aux_recall: 0.6957\n",
      "step: 100/800 ...  - loss: 0.5984 - val_loss: 0.6071\n",
      " - main_loss: 0.3270 - main_acc: 0.8578 - main_recall: 0.6972 - val_main_loss: 0.3319 - val_main_acc: 0.8536 - val_main_recall: 0.7048\n",
      " - aux_loss: 0.4905 - aux_acc: 0.7256 - aux_recall: 0.6952 - val_aux_loss: 0.5041 - val_aux_acc: 0.7300 - val_aux_recall: 0.6932\n",
      "step: 125/800 ...  - loss: 0.5720 - val_loss: 0.5857\n",
      " - main_loss: 0.3155 - main_acc: 0.8627 - main_recall: 0.7036 - val_main_loss: 0.3263 - val_main_acc: 0.8554 - val_main_recall: 0.7082\n",
      " - aux_loss: 0.4866 - aux_acc: 0.7276 - aux_recall: 0.7014 - val_aux_loss: 0.5023 - val_aux_acc: 0.7322 - val_aux_recall: 0.6976\n",
      "step: 150/800 ...  - loss: 0.5475 - val_loss: 0.5644\n",
      " - main_loss: 0.3052 - main_acc: 0.8675 - main_recall: 0.7098 - val_main_loss: 0.3213 - val_main_acc: 0.8591 - val_main_recall: 0.7028\n",
      " - aux_loss: 0.4822 - aux_acc: 0.7298 - aux_recall: 0.7075 - val_aux_loss: 0.4860 - val_aux_acc: 0.7405 - val_aux_recall: 0.6910\n",
      "step: 175/800 ...  - loss: 0.5394 - val_loss: 0.5580\n",
      " - main_loss: 0.2972 - main_acc: 0.8716 - main_recall: 0.7167 - val_main_loss: 0.3141 - val_main_acc: 0.8612 - val_main_recall: 0.7106\n",
      " - aux_loss: 0.4791 - aux_acc: 0.7315 - aux_recall: 0.7146 - val_aux_loss: 0.4856 - val_aux_acc: 0.7401 - val_aux_recall: 0.6981\n",
      "step: 200/800 ...  - loss: 0.5167 - val_loss: 0.5421\n",
      " - main_loss: 0.2888 - main_acc: 0.8756 - main_recall: 0.7214 - val_main_loss: 0.3116 - val_main_acc: 0.8614 - val_main_recall: 0.7211\n",
      " - aux_loss: 0.4754 - aux_acc: 0.7327 - aux_recall: 0.7193 - val_aux_loss: 0.4836 - val_aux_acc: 0.7385 - val_aux_recall: 0.7096\n",
      "step: 225/800 ...  - loss: 0.5130 - val_loss: 0.5381\n",
      " - main_loss: 0.2819 - main_acc: 0.8790 - main_recall: 0.7237 - val_main_loss: 0.3067 - val_main_acc: 0.8647 - val_main_recall: 0.7143\n",
      " - aux_loss: 0.4734 - aux_acc: 0.7336 - aux_recall: 0.7215 - val_aux_loss: 0.4790 - val_aux_acc: 0.7423 - val_aux_recall: 0.7025\n",
      "step: 250/800 ...  - loss: 0.5035 - val_loss: 0.5353\n",
      " - main_loss: 0.2780 - main_acc: 0.8816 - main_recall: 0.7266 - val_main_loss: 0.3073 - val_main_acc: 0.8639 - val_main_recall: 0.7279\n",
      " - aux_loss: 0.4729 - aux_acc: 0.7358 - aux_recall: 0.7244 - val_aux_loss: 0.4826 - val_aux_acc: 0.7388 - val_aux_recall: 0.7161\n",
      "step: 275/800 ...  - loss: 0.4919 - val_loss: 0.5238\n",
      " - main_loss: 0.2736 - main_acc: 0.8841 - main_recall: 0.7292 - val_main_loss: 0.3042 - val_main_acc: 0.8657 - val_main_recall: 0.7338\n",
      " - aux_loss: 0.4709 - aux_acc: 0.7362 - aux_recall: 0.7271 - val_aux_loss: 0.4792 - val_aux_acc: 0.7382 - val_aux_recall: 0.7219\n",
      "step: 300/800 ...  - loss: 0.4799 - val_loss: 0.5141\n",
      " - main_loss: 0.2684 - main_acc: 0.8861 - main_recall: 0.7321 - val_main_loss: 0.3018 - val_main_acc: 0.8671 - val_main_recall: 0.7393\n",
      " - aux_loss: 0.4698 - aux_acc: 0.7365 - aux_recall: 0.7300 - val_aux_loss: 0.4789 - val_aux_acc: 0.7401 - val_aux_recall: 0.7278\n",
      "step: 325/800 ...  - loss: 0.4782 - val_loss: 0.5153\n",
      " - main_loss: 0.2651 - main_acc: 0.8885 - main_recall: 0.7348 - val_main_loss: 0.2996 - val_main_acc: 0.8684 - val_main_recall: 0.7377\n",
      " - aux_loss: 0.4679 - aux_acc: 0.7384 - aux_recall: 0.7327 - val_aux_loss: 0.4780 - val_aux_acc: 0.7414 - val_aux_recall: 0.7255\n",
      "step: 350/800 ...  - loss: 0.4703 - val_loss: 0.5113\n",
      " - main_loss: 0.2606 - main_acc: 0.8905 - main_recall: 0.7345 - val_main_loss: 0.2987 - val_main_acc: 0.8684 - val_main_recall: 0.7259\n",
      " - aux_loss: 0.4677 - aux_acc: 0.7375 - aux_recall: 0.7322 - val_aux_loss: 0.4788 - val_aux_acc: 0.7428 - val_aux_recall: 0.7131\n",
      "step: 375/800 ...  - loss: 0.4628 - val_loss: 0.5091\n",
      " - main_loss: 0.2556 - main_acc: 0.8923 - main_recall: 0.7388 - val_main_loss: 0.3000 - val_main_acc: 0.8678 - val_main_recall: 0.7408\n",
      " - aux_loss: 0.4651 - aux_acc: 0.7391 - aux_recall: 0.7367 - val_aux_loss: 0.4754 - val_aux_acc: 0.7389 - val_aux_recall: 0.7288\n",
      "step: 400/800 ...  - loss: 0.4586 - val_loss: 0.5072\n",
      " - main_loss: 0.2534 - main_acc: 0.8937 - main_recall: 0.7398 - val_main_loss: 0.2990 - val_main_acc: 0.8687 - val_main_recall: 0.7466\n",
      " - aux_loss: 0.4644 - aux_acc: 0.7394 - aux_recall: 0.7376 - val_aux_loss: 0.4792 - val_aux_acc: 0.7383 - val_aux_recall: 0.7352\n",
      "step: 425/800 ...  - loss: 0.4580 - val_loss: 0.5047\n",
      " - main_loss: 0.2509 - main_acc: 0.8948 - main_recall: 0.7407 - val_main_loss: 0.2962 - val_main_acc: 0.8691 - val_main_recall: 0.7353\n",
      " - aux_loss: 0.4636 - aux_acc: 0.7397 - aux_recall: 0.7385 - val_aux_loss: 0.4767 - val_aux_acc: 0.7385 - val_aux_recall: 0.7234\n",
      "step: 450/800 ...  - loss: 0.4530 - val_loss: 0.5072\n",
      " - main_loss: 0.2468 - main_acc: 0.8968 - main_recall: 0.7456 - val_main_loss: 0.2974 - val_main_acc: 0.8702 - val_main_recall: 0.7309\n",
      " - aux_loss: 0.4628 - aux_acc: 0.7418 - aux_recall: 0.7435 - val_aux_loss: 0.4755 - val_aux_acc: 0.7437 - val_aux_recall: 0.7178\n",
      "step: 475/800 ...  - loss: 0.4466 - val_loss: 0.5038\n",
      " - main_loss: 0.2432 - main_acc: 0.8993 - main_recall: 0.7474 - val_main_loss: 0.2967 - val_main_acc: 0.8703 - val_main_recall: 0.7348\n",
      " - aux_loss: 0.4616 - aux_acc: 0.7422 - aux_recall: 0.7452 - val_aux_loss: 0.4755 - val_aux_acc: 0.7417 - val_aux_recall: 0.7222\n",
      "step: 500/800 ...  - loss: 0.4440 - val_loss: 0.5038\n",
      " - main_loss: 0.2403 - main_acc: 0.9003 - main_recall: 0.7480 - val_main_loss: 0.2969 - val_main_acc: 0.8709 - val_main_recall: 0.7444\n",
      " - aux_loss: 0.4604 - aux_acc: 0.7430 - aux_recall: 0.7458 - val_aux_loss: 0.4767 - val_aux_acc: 0.7420 - val_aux_recall: 0.7325\n",
      "step: 525/800 ...  - loss: 0.4389 - val_loss: 0.5051\n",
      " - main_loss: 0.2378 - main_acc: 0.9012 - main_recall: 0.7497 - val_main_loss: 0.2994 - val_main_acc: 0.8705 - val_main_recall: 0.7498\n",
      " - aux_loss: 0.4590 - aux_acc: 0.7438 - aux_recall: 0.7477 - val_aux_loss: 0.4809 - val_aux_acc: 0.7402 - val_aux_recall: 0.7383\n",
      "step: 550/800 ...  - loss: 0.4359 - val_loss: 0.5040\n",
      " - main_loss: 0.2346 - main_acc: 0.9032 - main_recall: 0.7542 - val_main_loss: 0.2990 - val_main_acc: 0.8692 - val_main_recall: 0.7434\n",
      " - aux_loss: 0.4578 - aux_acc: 0.7442 - aux_recall: 0.7518 - val_aux_loss: 0.4777 - val_aux_acc: 0.7440 - val_aux_recall: 0.7308\n",
      "step: 575/800 ...  - loss: 0.4310 - val_loss: 0.5019\n",
      " - main_loss: 0.2321 - main_acc: 0.9042 - main_recall: 0.7512 - val_main_loss: 0.2997 - val_main_acc: 0.8720 - val_main_recall: 0.7419\n",
      " - aux_loss: 0.4576 - aux_acc: 0.7437 - aux_recall: 0.7490 - val_aux_loss: 0.4779 - val_aux_acc: 0.7440 - val_aux_recall: 0.7294\n",
      "step: 600/800 ...  - loss: 0.4301 - val_loss: 0.5026\n",
      " - main_loss: 0.2315 - main_acc: 0.9043 - main_recall: 0.7529 - val_main_loss: 0.2995 - val_main_acc: 0.8714 - val_main_recall: 0.7397\n",
      " - aux_loss: 0.4570 - aux_acc: 0.7439 - aux_recall: 0.7506 - val_aux_loss: 0.4809 - val_aux_acc: 0.7435 - val_aux_recall: 0.7272\n",
      "step: 625/800 ...  - loss: 0.4266 - val_loss: 0.5050\n",
      " - main_loss: 0.2292 - main_acc: 0.9055 - main_recall: 0.7517 - val_main_loss: 0.3027 - val_main_acc: 0.8701 - val_main_recall: 0.7541\n",
      " - aux_loss: 0.4572 - aux_acc: 0.7452 - aux_recall: 0.7497 - val_aux_loss: 0.4789 - val_aux_acc: 0.7434 - val_aux_recall: 0.7428\n",
      "step: 650/800 ...  - loss: 0.4243 - val_loss: 0.5016\n",
      " - main_loss: 0.2269 - main_acc: 0.9070 - main_recall: 0.7523 - val_main_loss: 0.2998 - val_main_acc: 0.8712 - val_main_recall: 0.7564\n",
      " - aux_loss: 0.4557 - aux_acc: 0.7448 - aux_recall: 0.7501 - val_aux_loss: 0.4826 - val_aux_acc: 0.7387 - val_aux_recall: 0.7444\n",
      "step: 675/800 ...  - loss: 0.4246 - val_loss: 0.5032\n",
      " - main_loss: 0.2247 - main_acc: 0.9084 - main_recall: 0.7594 - val_main_loss: 0.2989 - val_main_acc: 0.8725 - val_main_recall: 0.7454\n",
      " - aux_loss: 0.4541 - aux_acc: 0.7477 - aux_recall: 0.7573 - val_aux_loss: 0.4790 - val_aux_acc: 0.7430 - val_aux_recall: 0.7326\n",
      "step: 700/800 ...  - loss: 0.4171 - val_loss: 0.4994\n",
      " - main_loss: 0.2220 - main_acc: 0.9091 - main_recall: 0.7614 - val_main_loss: 0.2991 - val_main_acc: 0.8715 - val_main_recall: 0.7528\n",
      " - aux_loss: 0.4530 - aux_acc: 0.7475 - aux_recall: 0.7594 - val_aux_loss: 0.4792 - val_aux_acc: 0.7435 - val_aux_recall: 0.7418\n",
      "step: 725/800 ...  - loss: 0.4173 - val_loss: 0.4990\n",
      " - main_loss: 0.2211 - main_acc: 0.9096 - main_recall: 0.7586 - val_main_loss: 0.2969 - val_main_acc: 0.8732 - val_main_recall: 0.7524\n",
      " - aux_loss: 0.4528 - aux_acc: 0.7486 - aux_recall: 0.7562 - val_aux_loss: 0.4788 - val_aux_acc: 0.7428 - val_aux_recall: 0.7406\n",
      "step: 750/800 ...  - loss: 0.4134 - val_loss: 0.4997\n",
      " - main_loss: 0.2181 - main_acc: 0.9108 - main_recall: 0.7622 - val_main_loss: 0.2989 - val_main_acc: 0.8740 - val_main_recall: 0.7556\n",
      " - aux_loss: 0.4516 - aux_acc: 0.7487 - aux_recall: 0.7600 - val_aux_loss: 0.4782 - val_aux_acc: 0.7471 - val_aux_recall: 0.7430\n",
      "step: 775/800 ...  - loss: 0.4110 - val_loss: 0.4979\n",
      " - main_loss: 0.2168 - main_acc: 0.9125 - main_recall: 0.7627 - val_main_loss: 0.2990 - val_main_acc: 0.8724 - val_main_recall: 0.7517\n",
      " - aux_loss: 0.4519 - aux_acc: 0.7481 - aux_recall: 0.7605 - val_aux_loss: 0.4770 - val_aux_acc: 0.7448 - val_aux_recall: 0.7393\n",
      "step: 800/800 ...  - loss: 0.4085 - val_loss: 0.5012\n",
      " - main_loss: 0.2151 - main_acc: 0.9126 - main_recall: 0.7632 - val_main_loss: 0.3012 - val_main_acc: 0.8718 - val_main_recall: 0.7516\n",
      " - aux_loss: 0.4505 - aux_acc: 0.7498 - aux_recall: 0.7610 - val_aux_loss: 0.4809 - val_aux_acc: 0.7469 - val_aux_recall: 0.7396\n",
      "Evaluando especie Test: Specie_Rat\n",
      "loss     = 0.5364\n",
      "main_loss     = 0.3275\n",
      "aux_loss     = 0.5048\n",
      "main_acc     = 0.8617\n",
      "main_recall     = 0.7876\n",
      "aux_acc     = 0.7123\n",
      "aux_recall     = 0.7860\n",
      "\n",
      "\n",
      "Evaluando especie sin balancear: Specie_Rat\n",
      "loss     = 1.8877\n",
      "main_loss     = 1.3555\n",
      "aux_loss     = 2.1214\n",
      "main_acc     = 0.5826\n",
      "main_recall     = 0.6176\n",
      "aux_acc     = 0.4921\n",
      "aux_recall     = 0.6176\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Rat\n",
      "loss     = 1.9341\n",
      "main_loss     = 1.3902\n",
      "aux_loss     = 2.1796\n",
      "main_acc     = 0.5751\n",
      "main_recall     = 0.6203\n",
      "aux_acc     = 0.4866\n",
      "aux_recall     = 0.6138\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "species_siames_dict = {}\n",
    "for specie in species_metadata:\n",
    "    if(specie in [\"Specie_Chicken\"]):\n",
    "        continue\n",
    "    dataset_complete_no_species = dataset_complete[dataset_complete[specie] == 0]    \n",
    "    dataset_complete_species = dataset_complete[dataset_complete[specie] == 1]    \n",
    "    \n",
    "    df_train,df_val,df_test = get_train_val_test(dataset_complete_no_species)\n",
    "    \n",
    "    df_train_x = df_train.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_train_x = df_train_x.drop(embedding_1_cols,axis=1)\n",
    "    df_train_x = df_train_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_train_emb_x_1 = df_train[embedding_1_cols]\n",
    "    df_train_emb_x_2 = df_train[embedding_2_cols]\n",
    "    df_train_y = df_train[\"Is_Ohnolog\"]\n",
    "\n",
    "    df_val_x = df_val.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_val_x = df_val_x.drop(embedding_1_cols,axis=1)\n",
    "    df_val_x = df_val_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_val_emb_x_1 = df_val[embedding_1_cols]\n",
    "    df_val_emb_x_2 = df_val[embedding_2_cols]                  \n",
    "    df_val_y = df_val[\"Is_Ohnolog\"]\n",
    "\n",
    "    df_test_x = df_test.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_x = df_test_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_x = df_test_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_emb_x_1 =  df_test[embedding_1_cols]\n",
    "    df_test_emb_x_2 =  df_test[embedding_2_cols]\n",
    "    df_test_y = df_test[\"Is_Ohnolog\"]\n",
    "    \n",
    "    model = level_siames_merge_layer(df_train_x,df_train_emb_x_1,df_train_emb_x_2,\"Siames \" + specie,128)\n",
    "    \n",
    "    log = fit_model_siames(df_train_x.values,df_train_emb_x_1.values,df_train_emb_x_2.values,df_train_y.values,df_val_x.values,df_val_emb_x_1.values,df_val_emb_x_2.values,df_val_y.values,model,800,Adamax(),256,[1,0.2],0)\n",
    "    \n",
    "    df_test_species_x = dataset_complete_species.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_species_emb_x_1 = dataset_complete_species[embedding_1_cols]\n",
    "    df_test_species_emb_x_2 = dataset_complete_species[embedding_2_cols]\n",
    "    df_test_species_y = dataset_complete_species[\"Is_Ohnolog\"]\n",
    "    \n",
    "    species_siames_dict[specie] = {}\n",
    "    \n",
    "    print(\"Evaluando especie Test: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_emb_x_1.values,df_test_emb_x_2.values,df_test_x.values],[df_test_y.values,df_test_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_siames_dict[specie][\"Test\"] = metrics[5]\n",
    "            \n",
    "        \n",
    "    print(\"Evaluando especie sin balancear: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_species_emb_x_1.values,df_test_species_emb_x_2.values,df_test_species_x.values],[df_test_species_y.values,df_test_species_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_siames_dict[specie][\"Sin Balanceo\"] = metrics[5]\n",
    "    \n",
    "    df_species_ohnologs = dataset_complete_species[dataset_complete_species[\"Is_Ohnolog\"] == 1]\n",
    "    df_species_no_ohnologs = dataset_complete_species[dataset_complete_species[\"Is_Ohnolog\"] == 0]\n",
    "    \n",
    "    if(len(df_species_ohnologs)>len(df_species_no_ohnologs)):\n",
    "        df_species_new = df_species_no_ohnologs.append(df_species_ohnologs.sample(len(df_species_no_ohnologs)))        \n",
    "    else:\n",
    "        df_species_new = df_species_ohnologs.append(df_species_no_ohnologs.sample(len(df_species_ohnologs)))\n",
    "\n",
    "    if(len(df_species_new) == 0):\n",
    "        df_species_new = df_species_ohnologs        \n",
    "                \n",
    "    df_test_species_x = df_species_new.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_species_emb_x_1 =  df_species_new[embedding_1_cols]\n",
    "    df_test_species_emb_x_2 =  df_species_new[embedding_2_cols]\n",
    "    df_test_species_y = df_species_new[\"Is_Ohnolog\"]    \n",
    "    \n",
    "    print(\"Evaluando especie balanceada: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_species_emb_x_1.values,df_test_species_emb_x_2.values,df_test_species_x.values],[df_test_species_y.values,df_test_species_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_siames_dict[specie][\"Balanceadas\"] = metrics[5]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 25/200 ...  - loss: 3.0230 - val_loss: 2.8215\n",
      " - main_loss: 0.4849 - main_acc: 0.7591 - main_recall: 0.5942 - val_main_loss: 0.4606 - val_main_acc: 0.7790 - val_main_recall: 0.5991\n",
      " - aux_loss: 0.5757 - aux_acc: 0.6693 - aux_recall: 0.5927 - val_aux_loss: 0.5753 - val_aux_acc: 0.6817 - val_aux_recall: 0.5952\n",
      "step: 50/200 ...  - loss: 0.7976 - val_loss: 0.8003\n",
      " - main_loss: 0.4130 - main_acc: 0.8150 - main_recall: 0.6312 - val_main_loss: 0.4161 - val_main_acc: 0.8141 - val_main_recall: 0.6274\n",
      " - aux_loss: 0.5661 - aux_acc: 0.6744 - aux_recall: 0.6292 - val_aux_loss: 0.5768 - val_aux_acc: 0.6804 - val_aux_recall: 0.6226\n",
      "step: 75/200 ...  - loss: 0.6785 - val_loss: 0.6850\n",
      " - main_loss: 0.3902 - main_acc: 0.8278 - main_recall: 0.6468 - val_main_loss: 0.3941 - val_main_acc: 0.8256 - val_main_recall: 0.6499\n",
      " - aux_loss: 0.5604 - aux_acc: 0.6762 - aux_recall: 0.6448 - val_aux_loss: 0.5747 - val_aux_acc: 0.6687 - val_aux_recall: 0.6455\n",
      "step: 100/200 ...  - loss: 0.6399 - val_loss: 0.6463\n",
      " - main_loss: 0.3741 - main_acc: 0.8358 - main_recall: 0.6538 - val_main_loss: 0.3780 - val_main_acc: 0.8322 - val_main_recall: 0.6469\n",
      " - aux_loss: 0.5563 - aux_acc: 0.6798 - aux_recall: 0.6519 - val_aux_loss: 0.5677 - val_aux_acc: 0.6760 - val_aux_recall: 0.6419\n",
      "step: 125/200 ...  - loss: 0.6224 - val_loss: 0.6347\n",
      " - main_loss: 0.3607 - main_acc: 0.8418 - main_recall: 0.6648 - val_main_loss: 0.3695 - val_main_acc: 0.8377 - val_main_recall: 0.6803\n",
      " - aux_loss: 0.5531 - aux_acc: 0.6832 - aux_recall: 0.6629 - val_aux_loss: 0.5642 - val_aux_acc: 0.6762 - val_aux_recall: 0.6764\n",
      "step: 150/200 ...  - loss: 0.6036 - val_loss: 0.6169\n",
      " - main_loss: 0.3519 - main_acc: 0.8459 - main_recall: 0.6700 - val_main_loss: 0.3624 - val_main_acc: 0.8413 - val_main_recall: 0.6787\n",
      " - aux_loss: 0.5517 - aux_acc: 0.6847 - aux_recall: 0.6681 - val_aux_loss: 0.5642 - val_aux_acc: 0.6777 - val_aux_recall: 0.6739\n",
      "step: 175/200 ...  - loss: 0.5876 - val_loss: 0.6057\n",
      " - main_loss: 0.3434 - main_acc: 0.8495 - main_recall: 0.6773 - val_main_loss: 0.3573 - val_main_acc: 0.8432 - val_main_recall: 0.6899\n",
      " - aux_loss: 0.5501 - aux_acc: 0.6867 - aux_recall: 0.6754 - val_aux_loss: 0.5675 - val_aux_acc: 0.6749 - val_aux_recall: 0.6855\n",
      "step: 200/200 ...  - loss: 0.5747 - val_loss: 0.5948\n",
      " - main_loss: 0.3358 - main_acc: 0.8535 - main_recall: 0.6833 - val_main_loss: 0.3527 - val_main_acc: 0.8458 - val_main_recall: 0.6831\n",
      " - aux_loss: 0.5471 - aux_acc: 0.6894 - aux_recall: 0.6814 - val_aux_loss: 0.5636 - val_aux_acc: 0.6791 - val_aux_recall: 0.6783\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 25/200 ...  - loss: 0.4920 - val_loss: 0.5023\n",
      " - main_loss: 0.2763 - main_acc: 0.8834 - main_recall: 0.8227 - val_main_loss: 0.2874 - val_main_acc: 0.8737 - val_main_recall: 0.8263\n",
      " - aux_loss: 0.4483 - aux_acc: 0.7427 - aux_recall: 0.8217 - val_aux_loss: 0.4607 - val_aux_acc: 0.7430 - val_aux_recall: 0.8224\n",
      "step: 50/200 ...  - loss: 0.4470 - val_loss: 0.4730\n",
      " - main_loss: 0.2593 - main_acc: 0.8892 - main_recall: 0.8309 - val_main_loss: 0.2817 - val_main_acc: 0.8756 - val_main_recall: 0.8262\n",
      " - aux_loss: 0.4383 - aux_acc: 0.7475 - aux_recall: 0.8299 - val_aux_loss: 0.4492 - val_aux_acc: 0.7419 - val_aux_recall: 0.8224\n",
      "step: 75/200 ...  - loss: 0.4377 - val_loss: 0.4704\n",
      " - main_loss: 0.2519 - main_acc: 0.8919 - main_recall: 0.8326 - val_main_loss: 0.2813 - val_main_acc: 0.8762 - val_main_recall: 0.8278\n",
      " - aux_loss: 0.4334 - aux_acc: 0.7512 - aux_recall: 0.8316 - val_aux_loss: 0.4479 - val_aux_acc: 0.7430 - val_aux_recall: 0.8239\n",
      "step: 100/200 ...  - loss: 0.4322 - val_loss: 0.4694\n",
      " - main_loss: 0.2472 - main_acc: 0.8943 - main_recall: 0.8328 - val_main_loss: 0.2815 - val_main_acc: 0.8759 - val_main_recall: 0.8179\n",
      " - aux_loss: 0.4322 - aux_acc: 0.7516 - aux_recall: 0.8317 - val_aux_loss: 0.4484 - val_aux_acc: 0.7427 - val_aux_recall: 0.8138\n",
      "step: 125/200 ...  - loss: 0.4210 - val_loss: 0.4647\n",
      " - main_loss: 0.2427 - main_acc: 0.8960 - main_recall: 0.8341 - val_main_loss: 0.2833 - val_main_acc: 0.8740 - val_main_recall: 0.8240\n",
      " - aux_loss: 0.4314 - aux_acc: 0.7532 - aux_recall: 0.8330 - val_aux_loss: 0.4501 - val_aux_acc: 0.7401 - val_aux_recall: 0.8201\n",
      "step: 150/200 ...  - loss: 0.4198 - val_loss: 0.4670\n",
      " - main_loss: 0.2379 - main_acc: 0.8976 - main_recall: 0.8373 - val_main_loss: 0.2819 - val_main_acc: 0.8755 - val_main_recall: 0.8321\n",
      " - aux_loss: 0.4297 - aux_acc: 0.7540 - aux_recall: 0.8362 - val_aux_loss: 0.4480 - val_aux_acc: 0.7450 - val_aux_recall: 0.8281\n",
      "step: 175/200 ...  - loss: 0.4151 - val_loss: 0.4660\n",
      " - main_loss: 0.2341 - main_acc: 0.9001 - main_recall: 0.8414 - val_main_loss: 0.2816 - val_main_acc: 0.8761 - val_main_recall: 0.8298\n",
      " - aux_loss: 0.4277 - aux_acc: 0.7555 - aux_recall: 0.8403 - val_aux_loss: 0.4474 - val_aux_acc: 0.7419 - val_aux_recall: 0.8258\n",
      "step: 200/200 ...  - loss: 0.4112 - val_loss: 0.4698\n",
      " - main_loss: 0.2307 - main_acc: 0.9015 - main_recall: 0.8440 - val_main_loss: 0.2842 - val_main_acc: 0.8752 - val_main_recall: 0.8320\n",
      " - aux_loss: 0.4265 - aux_acc: 0.7582 - aux_recall: 0.8427 - val_aux_loss: 0.4481 - val_aux_acc: 0.7428 - val_aux_recall: 0.8282\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 25/200 ...  - loss: 0.5637 - val_loss: 0.5495\n",
      " - main_loss: 0.3457 - main_acc: 0.8497 - main_recall: 0.6766 - val_main_loss: 0.3346 - val_main_acc: 0.8561 - val_main_recall: 0.6656\n",
      " - aux_loss: 0.5561 - aux_acc: 0.6863 - aux_recall: 0.6761 - val_aux_loss: 0.5582 - val_aux_acc: 0.6861 - val_aux_recall: 0.6614\n",
      "step: 50/200 ...  - loss: 0.5387 - val_loss: 0.5441\n",
      " - main_loss: 0.3261 - main_acc: 0.8577 - main_recall: 0.6850 - val_main_loss: 0.3308 - val_main_acc: 0.8563 - val_main_recall: 0.7031\n",
      " - aux_loss: 0.5505 - aux_acc: 0.6906 - aux_recall: 0.6845 - val_aux_loss: 0.5579 - val_aux_acc: 0.6868 - val_aux_recall: 0.6998\n",
      "step: 75/200 ...  - loss: 0.5298 - val_loss: 0.5427\n",
      " - main_loss: 0.3175 - main_acc: 0.8620 - main_recall: 0.6911 - val_main_loss: 0.3306 - val_main_acc: 0.8572 - val_main_recall: 0.6890\n",
      " - aux_loss: 0.5476 - aux_acc: 0.6935 - aux_recall: 0.6906 - val_aux_loss: 0.5558 - val_aux_acc: 0.6906 - val_aux_recall: 0.6852\n",
      "step: 100/200 ...  - loss: 0.5214 - val_loss: 0.5389\n",
      " - main_loss: 0.3121 - main_acc: 0.8642 - main_recall: 0.6945 - val_main_loss: 0.3288 - val_main_acc: 0.8571 - val_main_recall: 0.6857\n",
      " - aux_loss: 0.5462 - aux_acc: 0.6944 - aux_recall: 0.6941 - val_aux_loss: 0.5564 - val_aux_acc: 0.6924 - val_aux_recall: 0.6812\n",
      "step: 125/200 ...  - loss: 0.5111 - val_loss: 0.5353\n",
      " - main_loss: 0.3058 - main_acc: 0.8673 - main_recall: 0.7009 - val_main_loss: 0.3291 - val_main_acc: 0.8560 - val_main_recall: 0.7070\n",
      " - aux_loss: 0.5432 - aux_acc: 0.6974 - aux_recall: 0.7003 - val_aux_loss: 0.5544 - val_aux_acc: 0.6921 - val_aux_recall: 0.7034\n",
      "step: 150/200 ...  - loss: 0.5108 - val_loss: 0.5396\n",
      " - main_loss: 0.3035 - main_acc: 0.8682 - main_recall: 0.6998 - val_main_loss: 0.3309 - val_main_acc: 0.8558 - val_main_recall: 0.7011\n",
      " - aux_loss: 0.5433 - aux_acc: 0.6970 - aux_recall: 0.6993 - val_aux_loss: 0.5559 - val_aux_acc: 0.6908 - val_aux_recall: 0.6973\n",
      "step: 175/200 ...  - loss: 0.5066 - val_loss: 0.5349\n",
      " - main_loss: 0.3014 - main_acc: 0.8701 - main_recall: 0.7048 - val_main_loss: 0.3277 - val_main_acc: 0.8570 - val_main_recall: 0.7091\n",
      " - aux_loss: 0.5417 - aux_acc: 0.6978 - aux_recall: 0.7042 - val_aux_loss: 0.5534 - val_aux_acc: 0.6953 - val_aux_recall: 0.7057\n",
      "step: 200/200 ...  - loss: 0.5007 - val_loss: 0.5366\n",
      " - main_loss: 0.2966 - main_acc: 0.8717 - main_recall: 0.7060 - val_main_loss: 0.3301 - val_main_acc: 0.8556 - val_main_recall: 0.7014\n",
      " - aux_loss: 0.5411 - aux_acc: 0.6987 - aux_recall: 0.7055 - val_aux_loss: 0.5540 - val_aux_acc: 0.6942 - val_aux_recall: 0.6977\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 25/200 ...  - loss: 0.4314 - val_loss: 0.4218\n",
      " - main_loss: 0.2525 - main_acc: 0.8928 - main_recall: 0.8263 - val_main_loss: 0.2497 - val_main_acc: 0.8938 - val_main_recall: 0.8390\n",
      " - aux_loss: 0.4323 - aux_acc: 0.7655 - aux_recall: 0.8263 - val_aux_loss: 0.4414 - val_aux_acc: 0.7617 - val_aux_recall: 0.8368\n",
      "step: 50/200 ...  - loss: 0.3893 - val_loss: 0.3956\n",
      " - main_loss: 0.2348 - main_acc: 0.8995 - main_recall: 0.8329 - val_main_loss: 0.2414 - val_main_acc: 0.8952 - val_main_recall: 0.8395\n",
      " - aux_loss: 0.4217 - aux_acc: 0.7718 - aux_recall: 0.8329 - val_aux_loss: 0.4342 - val_aux_acc: 0.7648 - val_aux_recall: 0.8375\n",
      "step: 75/200 ...  - loss: 0.4022 - val_loss: 0.4086\n",
      " - main_loss: 0.2322 - main_acc: 0.9004 - main_recall: 0.8316 - val_main_loss: 0.2424 - val_main_acc: 0.8945 - val_main_recall: 0.8434\n",
      " - aux_loss: 0.4212 - aux_acc: 0.7718 - aux_recall: 0.8316 - val_aux_loss: 0.4335 - val_aux_acc: 0.7638 - val_aux_recall: 0.8415\n",
      "step: 100/200 ...  - loss: 0.3780 - val_loss: 0.3903\n",
      " - main_loss: 0.2269 - main_acc: 0.9032 - main_recall: 0.8344 - val_main_loss: 0.2405 - val_main_acc: 0.8955 - val_main_recall: 0.8393\n",
      " - aux_loss: 0.4169 - aux_acc: 0.7735 - aux_recall: 0.8344 - val_aux_loss: 0.4294 - val_aux_acc: 0.7658 - val_aux_recall: 0.8375\n",
      "step: 125/200 ...  - loss: 0.3886 - val_loss: 0.4047\n",
      " - main_loss: 0.2262 - main_acc: 0.9032 - main_recall: 0.8353 - val_main_loss: 0.2444 - val_main_acc: 0.8935 - val_main_recall: 0.8387\n",
      " - aux_loss: 0.4185 - aux_acc: 0.7731 - aux_recall: 0.8353 - val_aux_loss: 0.4352 - val_aux_acc: 0.7613 - val_aux_recall: 0.8367\n",
      "step: 150/200 ...  - loss: 0.3858 - val_loss: 0.4063\n",
      " - main_loss: 0.2234 - main_acc: 0.9053 - main_recall: 0.8361 - val_main_loss: 0.2451 - val_main_acc: 0.8934 - val_main_recall: 0.8388\n",
      " - aux_loss: 0.4166 - aux_acc: 0.7739 - aux_recall: 0.8360 - val_aux_loss: 0.4345 - val_aux_acc: 0.7620 - val_aux_recall: 0.8368\n",
      "step: 175/200 ...  - loss: 0.3744 - val_loss: 0.4003\n",
      " - main_loss: 0.2188 - main_acc: 0.9069 - main_recall: 0.8377 - val_main_loss: 0.2443 - val_main_acc: 0.8949 - val_main_recall: 0.8405\n",
      " - aux_loss: 0.4141 - aux_acc: 0.7760 - aux_recall: 0.8377 - val_aux_loss: 0.4340 - val_aux_acc: 0.7631 - val_aux_recall: 0.8385\n",
      "step: 200/200 ...  - loss: 0.3926 - val_loss: 0.4170\n",
      " - main_loss: 0.2192 - main_acc: 0.9060 - main_recall: 0.8358 - val_main_loss: 0.2463 - val_main_acc: 0.8937 - val_main_recall: 0.8383\n",
      " - aux_loss: 0.4160 - aux_acc: 0.7751 - aux_recall: 0.8358 - val_aux_loss: 0.4325 - val_aux_acc: 0.7644 - val_aux_recall: 0.8363\n",
      "Entrenando sin especie: Specie_Chicken\n",
      "step: 25/200 ...  - loss: 0.4487 - val_loss: 0.4372\n",
      " - main_loss: 0.2653 - main_acc: 0.8837 - main_recall: 0.7357 - val_main_loss: 0.2625 - val_main_acc: 0.8909 - val_main_recall: 0.7577\n",
      " - aux_loss: 0.4639 - aux_acc: 0.7442 - aux_recall: 0.7357 - val_aux_loss: 0.4621 - val_aux_acc: 0.7446 - val_aux_recall: 0.7515\n",
      "step: 50/200 ...  - loss: 0.4283 - val_loss: 0.4247\n",
      " - main_loss: 0.2500 - main_acc: 0.8912 - main_recall: 0.7463 - val_main_loss: 0.2543 - val_main_acc: 0.8945 - val_main_recall: 0.7610\n",
      " - aux_loss: 0.4580 - aux_acc: 0.7479 - aux_recall: 0.7463 - val_aux_loss: 0.4508 - val_aux_acc: 0.7514 - val_aux_recall: 0.7547\n",
      "step: 75/200 ...  - loss: 0.4125 - val_loss: 0.4175\n",
      " - main_loss: 0.2450 - main_acc: 0.8938 - main_recall: 0.7514 - val_main_loss: 0.2558 - val_main_acc: 0.8923 - val_main_recall: 0.7669\n",
      " - aux_loss: 0.4549 - aux_acc: 0.7495 - aux_recall: 0.7513 - val_aux_loss: 0.4503 - val_aux_acc: 0.7502 - val_aux_recall: 0.7607\n",
      "step: 100/200 ...  - loss: 0.4030 - val_loss: 0.4135\n",
      " - main_loss: 0.2395 - main_acc: 0.8960 - main_recall: 0.7562 - val_main_loss: 0.2551 - val_main_acc: 0.8931 - val_main_recall: 0.7692\n",
      " - aux_loss: 0.4536 - aux_acc: 0.7512 - aux_recall: 0.7562 - val_aux_loss: 0.4510 - val_aux_acc: 0.7500 - val_aux_recall: 0.7632\n",
      "step: 125/200 ...  - loss: 0.4188 - val_loss: 0.4291\n",
      " - main_loss: 0.2403 - main_acc: 0.8961 - main_recall: 0.7530 - val_main_loss: 0.2576 - val_main_acc: 0.8924 - val_main_recall: 0.7603\n",
      " - aux_loss: 0.4546 - aux_acc: 0.7505 - aux_recall: 0.7530 - val_aux_loss: 0.4523 - val_aux_acc: 0.7518 - val_aux_recall: 0.7541\n",
      "step: 150/200 ...  - loss: 0.4072 - val_loss: 0.4220\n",
      " - main_loss: 0.2369 - main_acc: 0.8976 - main_recall: 0.7566 - val_main_loss: 0.2572 - val_main_acc: 0.8931 - val_main_recall: 0.7632\n",
      " - aux_loss: 0.4532 - aux_acc: 0.7520 - aux_recall: 0.7565 - val_aux_loss: 0.4519 - val_aux_acc: 0.7513 - val_aux_recall: 0.7573\n",
      "step: 175/200 ...  - loss: 0.4042 - val_loss: 0.4211\n",
      " - main_loss: 0.2341 - main_acc: 0.8990 - main_recall: 0.7559 - val_main_loss: 0.2573 - val_main_acc: 0.8930 - val_main_recall: 0.7648\n",
      " - aux_loss: 0.4524 - aux_acc: 0.7529 - aux_recall: 0.7559 - val_aux_loss: 0.4505 - val_aux_acc: 0.7529 - val_aux_recall: 0.7588\n",
      "step: 200/200 ...  - loss: 0.3940 - val_loss: 0.4183\n",
      " - main_loss: 0.2316 - main_acc: 0.8998 - main_recall: 0.7611 - val_main_loss: 0.2592 - val_main_acc: 0.8914 - val_main_recall: 0.7613\n",
      " - aux_loss: 0.4510 - aux_acc: 0.7538 - aux_recall: 0.7611 - val_aux_loss: 0.4521 - val_aux_acc: 0.7524 - val_aux_recall: 0.7552\n",
      "Evaluando especie sin balancear: Specie_Chicken\n",
      "loss     = 0.9736\n",
      "main_loss     = 0.7245\n",
      "aux_loss     = 0.9116\n",
      "main_acc     = 0.7079\n",
      "main_recall     = 0.8457\n",
      "aux_acc     = 0.5034\n",
      "aux_recall     = 0.8457\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Chicken\n",
      "loss     = 0.7952\n",
      "main_loss     = 0.5679\n",
      "aux_loss     = 0.8025\n",
      "main_acc     = 0.7689\n",
      "main_recall     = 0.8457\n",
      "aux_acc     = 0.5738\n",
      "aux_recall     = 0.8457\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 25/200 ...  - loss: 3.0345 - val_loss: 2.8285\n",
      " - main_loss: 0.4862 - main_acc: 0.7588 - main_recall: 0.5917 - val_main_loss: 0.4591 - val_main_acc: 0.7818 - val_main_recall: 0.6107\n",
      " - aux_loss: 0.5776 - aux_acc: 0.6706 - aux_recall: 0.5904 - val_aux_loss: 0.5764 - val_aux_acc: 0.6801 - val_aux_recall: 0.6073\n",
      "step: 50/200 ...  - loss: 0.7973 - val_loss: 0.7942\n",
      " - main_loss: 0.4105 - main_acc: 0.8160 - main_recall: 0.6381 - val_main_loss: 0.4107 - val_main_acc: 0.8161 - val_main_recall: 0.6373\n",
      " - aux_loss: 0.5648 - aux_acc: 0.6765 - aux_recall: 0.6363 - val_aux_loss: 0.5752 - val_aux_acc: 0.6780 - val_aux_recall: 0.6326\n",
      "step: 75/200 ...  - loss: 0.6800 - val_loss: 0.6880\n",
      " - main_loss: 0.3878 - main_acc: 0.8285 - main_recall: 0.6502 - val_main_loss: 0.3930 - val_main_acc: 0.8253 - val_main_recall: 0.6299\n",
      " - aux_loss: 0.5589 - aux_acc: 0.6793 - aux_recall: 0.6485 - val_aux_loss: 0.5757 - val_aux_acc: 0.6749 - val_aux_recall: 0.6249\n",
      "step: 100/200 ...  - loss: 0.6439 - val_loss: 0.6569\n",
      " - main_loss: 0.3735 - main_acc: 0.8350 - main_recall: 0.6598 - val_main_loss: 0.3832 - val_main_acc: 0.8314 - val_main_recall: 0.6485\n",
      " - aux_loss: 0.5548 - aux_acc: 0.6817 - aux_recall: 0.6578 - val_aux_loss: 0.5717 - val_aux_acc: 0.6757 - val_aux_recall: 0.6436\n",
      "step: 125/200 ...  - loss: 0.6268 - val_loss: 0.6401\n",
      " - main_loss: 0.3626 - main_acc: 0.8401 - main_recall: 0.6695 - val_main_loss: 0.3735 - val_main_acc: 0.8366 - val_main_recall: 0.6703\n",
      " - aux_loss: 0.5513 - aux_acc: 0.6860 - aux_recall: 0.6675 - val_aux_loss: 0.5692 - val_aux_acc: 0.6763 - val_aux_recall: 0.6662\n",
      "step: 150/200 ...  - loss: 0.6087 - val_loss: 0.6193\n",
      " - main_loss: 0.3526 - main_acc: 0.8447 - main_recall: 0.6742 - val_main_loss: 0.3610 - val_main_acc: 0.8413 - val_main_recall: 0.6750\n",
      " - aux_loss: 0.5488 - aux_acc: 0.6899 - aux_recall: 0.6725 - val_aux_loss: 0.5627 - val_aux_acc: 0.6790 - val_aux_recall: 0.6705\n",
      "step: 175/200 ...  - loss: 0.5961 - val_loss: 0.6103\n",
      " - main_loss: 0.3436 - main_acc: 0.8497 - main_recall: 0.6821 - val_main_loss: 0.3548 - val_main_acc: 0.8437 - val_main_recall: 0.6771\n",
      " - aux_loss: 0.5460 - aux_acc: 0.6910 - aux_recall: 0.6802 - val_aux_loss: 0.5568 - val_aux_acc: 0.6862 - val_aux_recall: 0.6722\n",
      "step: 200/200 ...  - loss: 0.5805 - val_loss: 0.5968\n",
      " - main_loss: 0.3358 - main_acc: 0.8540 - main_recall: 0.6865 - val_main_loss: 0.3509 - val_main_acc: 0.8462 - val_main_recall: 0.6927\n",
      " - aux_loss: 0.5432 - aux_acc: 0.6939 - aux_recall: 0.6847 - val_aux_loss: 0.5568 - val_aux_acc: 0.6820 - val_aux_recall: 0.6885\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 25/200 ...  - loss: 0.5588 - val_loss: 0.5560\n",
      " - main_loss: 0.3221 - main_acc: 0.8624 - main_recall: 0.7312 - val_main_loss: 0.3213 - val_main_acc: 0.8612 - val_main_recall: 0.7344\n",
      " - aux_loss: 0.5287 - aux_acc: 0.6950 - aux_recall: 0.7287 - val_aux_loss: 0.5330 - val_aux_acc: 0.6968 - val_aux_recall: 0.7293\n",
      "step: 50/200 ...  - loss: 0.5296 - val_loss: 0.5351\n",
      " - main_loss: 0.3057 - main_acc: 0.8695 - main_recall: 0.7470 - val_main_loss: 0.3105 - val_main_acc: 0.8662 - val_main_recall: 0.7363\n",
      " - aux_loss: 0.5197 - aux_acc: 0.7014 - aux_recall: 0.7447 - val_aux_loss: 0.5262 - val_aux_acc: 0.6984 - val_aux_recall: 0.7310\n",
      "step: 75/200 ...  - loss: 0.5152 - val_loss: 0.5311\n",
      " - main_loss: 0.2963 - main_acc: 0.8732 - main_recall: 0.7480 - val_main_loss: 0.3107 - val_main_acc: 0.8666 - val_main_recall: 0.7437\n",
      " - aux_loss: 0.5165 - aux_acc: 0.7039 - aux_recall: 0.7455 - val_aux_loss: 0.5262 - val_aux_acc: 0.6979 - val_aux_recall: 0.7384\n",
      "step: 100/200 ...  - loss: 0.5038 - val_loss: 0.5269\n",
      " - main_loss: 0.2868 - main_acc: 0.8782 - main_recall: 0.7578 - val_main_loss: 0.3074 - val_main_acc: 0.8682 - val_main_recall: 0.7448\n",
      " - aux_loss: 0.5129 - aux_acc: 0.7059 - aux_recall: 0.7555 - val_aux_loss: 0.5229 - val_aux_acc: 0.7031 - val_aux_recall: 0.7399\n",
      "step: 125/200 ...  - loss: 0.4938 - val_loss: 0.5235\n",
      " - main_loss: 0.2811 - main_acc: 0.8801 - main_recall: 0.7625 - val_main_loss: 0.3080 - val_main_acc: 0.8686 - val_main_recall: 0.7566\n",
      " - aux_loss: 0.5105 - aux_acc: 0.7076 - aux_recall: 0.7602 - val_aux_loss: 0.5263 - val_aux_acc: 0.6998 - val_aux_recall: 0.7511\n",
      "step: 150/200 ...  - loss: 0.4884 - val_loss: 0.5221\n",
      " - main_loss: 0.2759 - main_acc: 0.8829 - main_recall: 0.7675 - val_main_loss: 0.3063 - val_main_acc: 0.8712 - val_main_recall: 0.7685\n",
      " - aux_loss: 0.5080 - aux_acc: 0.7092 - aux_recall: 0.7652 - val_aux_loss: 0.5233 - val_aux_acc: 0.7032 - val_aux_recall: 0.7631\n",
      "step: 175/200 ...  - loss: 0.4797 - val_loss: 0.5182\n",
      " - main_loss: 0.2704 - main_acc: 0.8853 - main_recall: 0.7719 - val_main_loss: 0.3053 - val_main_acc: 0.8701 - val_main_recall: 0.7603\n",
      " - aux_loss: 0.5058 - aux_acc: 0.7103 - aux_recall: 0.7697 - val_aux_loss: 0.5254 - val_aux_acc: 0.7031 - val_aux_recall: 0.7550\n",
      "step: 200/200 ...  - loss: 0.4742 - val_loss: 0.5220\n",
      " - main_loss: 0.2651 - main_acc: 0.8877 - main_recall: 0.7764 - val_main_loss: 0.3078 - val_main_acc: 0.8699 - val_main_recall: 0.7570\n",
      " - aux_loss: 0.5034 - aux_acc: 0.7134 - aux_recall: 0.7742 - val_aux_loss: 0.5249 - val_aux_acc: 0.7030 - val_aux_recall: 0.7514\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 25/200 ...  - loss: 0.6256 - val_loss: 0.6144\n",
      " - main_loss: 0.3775 - main_acc: 0.8394 - main_recall: 0.5547 - val_main_loss: 0.3734 - val_main_acc: 0.8374 - val_main_recall: 0.5434\n",
      " - aux_loss: 0.6263 - aux_acc: 0.6488 - aux_recall: 0.5533 - val_aux_loss: 0.6193 - val_aux_acc: 0.6540 - val_aux_recall: 0.5381\n",
      "step: 50/200 ...  - loss: 0.5852 - val_loss: 0.5950\n",
      " - main_loss: 0.3524 - main_acc: 0.8492 - main_recall: 0.5767 - val_main_loss: 0.3623 - val_main_acc: 0.8420 - val_main_recall: 0.5488\n",
      " - aux_loss: 0.6079 - aux_acc: 0.6577 - aux_recall: 0.5753 - val_aux_loss: 0.6143 - val_aux_acc: 0.6541 - val_aux_recall: 0.5425\n",
      "step: 75/200 ...  - loss: 0.5745 - val_loss: 0.5965\n",
      " - main_loss: 0.3432 - main_acc: 0.8533 - main_recall: 0.5850 - val_main_loss: 0.3623 - val_main_acc: 0.8422 - val_main_recall: 0.5775\n",
      " - aux_loss: 0.6044 - aux_acc: 0.6598 - aux_recall: 0.5837 - val_aux_loss: 0.6160 - val_aux_acc: 0.6522 - val_aux_recall: 0.5718\n",
      "step: 100/200 ...  - loss: 0.5652 - val_loss: 0.5949\n",
      " - main_loss: 0.3366 - main_acc: 0.8563 - main_recall: 0.5939 - val_main_loss: 0.3644 - val_main_acc: 0.8420 - val_main_recall: 0.5666\n",
      " - aux_loss: 0.6017 - aux_acc: 0.6621 - aux_recall: 0.5926 - val_aux_loss: 0.6141 - val_aux_acc: 0.6554 - val_aux_recall: 0.5606\n",
      "step: 125/200 ...  - loss: 0.5581 - val_loss: 0.5883\n",
      " - main_loss: 0.3332 - main_acc: 0.8581 - main_recall: 0.5958 - val_main_loss: 0.3613 - val_main_acc: 0.8442 - val_main_recall: 0.5752\n",
      " - aux_loss: 0.6005 - aux_acc: 0.6631 - aux_recall: 0.5944 - val_aux_loss: 0.6122 - val_aux_acc: 0.6561 - val_aux_recall: 0.5691\n",
      "step: 150/200 ...  - loss: 0.5500 - val_loss: 0.5897\n",
      " - main_loss: 0.3283 - main_acc: 0.8601 - main_recall: 0.6012 - val_main_loss: 0.3655 - val_main_acc: 0.8421 - val_main_recall: 0.5839\n",
      " - aux_loss: 0.5985 - aux_acc: 0.6643 - aux_recall: 0.5999 - val_aux_loss: 0.6163 - val_aux_acc: 0.6555 - val_aux_recall: 0.5784\n",
      "step: 175/200 ...  - loss: 0.5422 - val_loss: 0.5910\n",
      " - main_loss: 0.3233 - main_acc: 0.8629 - main_recall: 0.6047 - val_main_loss: 0.3676 - val_main_acc: 0.8424 - val_main_recall: 0.5655\n",
      " - aux_loss: 0.5965 - aux_acc: 0.6654 - aux_recall: 0.6032 - val_aux_loss: 0.6166 - val_aux_acc: 0.6541 - val_aux_recall: 0.5593\n",
      "step: 200/200 ...  - loss: 0.5356 - val_loss: 0.5840\n",
      " - main_loss: 0.3195 - main_acc: 0.8647 - main_recall: 0.6091 - val_main_loss: 0.3647 - val_main_acc: 0.8439 - val_main_recall: 0.5915\n",
      " - aux_loss: 0.5941 - aux_acc: 0.6670 - aux_recall: 0.6078 - val_aux_loss: 0.6130 - val_aux_acc: 0.6575 - val_aux_recall: 0.5863\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 25/200 ...  - loss: 0.4857 - val_loss: 0.4663\n",
      " - main_loss: 0.2900 - main_acc: 0.8769 - main_recall: 0.7455 - val_main_loss: 0.2732 - val_main_acc: 0.8894 - val_main_recall: 0.7732\n",
      " - aux_loss: 0.5143 - aux_acc: 0.7182 - aux_recall: 0.7450 - val_aux_loss: 0.5167 - val_aux_acc: 0.7189 - val_aux_recall: 0.7717\n",
      "step: 50/200 ...  - loss: 0.4609 - val_loss: 0.4569\n",
      " - main_loss: 0.2752 - main_acc: 0.8829 - main_recall: 0.7519 - val_main_loss: 0.2710 - val_main_acc: 0.8894 - val_main_recall: 0.7765\n",
      " - aux_loss: 0.5057 - aux_acc: 0.7215 - aux_recall: 0.7513 - val_aux_loss: 0.5110 - val_aux_acc: 0.7207 - val_aux_recall: 0.7748\n",
      "step: 75/200 ...  - loss: 0.4563 - val_loss: 0.4643\n",
      " - main_loss: 0.2702 - main_acc: 0.8844 - main_recall: 0.7544 - val_main_loss: 0.2768 - val_main_acc: 0.8859 - val_main_recall: 0.7804\n",
      " - aux_loss: 0.5033 - aux_acc: 0.7217 - aux_recall: 0.7538 - val_aux_loss: 0.5132 - val_aux_acc: 0.7192 - val_aux_recall: 0.7786\n",
      "step: 100/200 ...  - loss: 0.4481 - val_loss: 0.4610\n",
      " - main_loss: 0.2646 - main_acc: 0.8876 - main_recall: 0.7585 - val_main_loss: 0.2754 - val_main_acc: 0.8869 - val_main_recall: 0.7828\n",
      " - aux_loss: 0.4989 - aux_acc: 0.7250 - aux_recall: 0.7579 - val_aux_loss: 0.5122 - val_aux_acc: 0.7199 - val_aux_recall: 0.7811\n",
      "step: 125/200 ...  - loss: 0.4428 - val_loss: 0.4649\n",
      " - main_loss: 0.2591 - main_acc: 0.8902 - main_recall: 0.7590 - val_main_loss: 0.2783 - val_main_acc: 0.8852 - val_main_recall: 0.7697\n",
      " - aux_loss: 0.4976 - aux_acc: 0.7244 - aux_recall: 0.7584 - val_aux_loss: 0.5146 - val_aux_acc: 0.7176 - val_aux_recall: 0.7679\n",
      "step: 150/200 ...  - loss: 0.4368 - val_loss: 0.4643\n",
      " - main_loss: 0.2557 - main_acc: 0.8915 - main_recall: 0.7636 - val_main_loss: 0.2795 - val_main_acc: 0.8848 - val_main_recall: 0.7731\n",
      " - aux_loss: 0.4950 - aux_acc: 0.7264 - aux_recall: 0.7630 - val_aux_loss: 0.5139 - val_aux_acc: 0.7202 - val_aux_recall: 0.7714\n",
      "step: 175/200 ...  - loss: 0.4347 - val_loss: 0.4645\n",
      " - main_loss: 0.2535 - main_acc: 0.8932 - main_recall: 0.7624 - val_main_loss: 0.2797 - val_main_acc: 0.8848 - val_main_recall: 0.7749\n",
      " - aux_loss: 0.4933 - aux_acc: 0.7268 - aux_recall: 0.7618 - val_aux_loss: 0.5141 - val_aux_acc: 0.7204 - val_aux_recall: 0.7731\n",
      "step: 200/200 ...  - loss: 0.4311 - val_loss: 0.4660\n",
      " - main_loss: 0.2503 - main_acc: 0.8939 - main_recall: 0.7627 - val_main_loss: 0.2816 - val_main_acc: 0.8842 - val_main_recall: 0.7707\n",
      " - aux_loss: 0.4934 - aux_acc: 0.7272 - aux_recall: 0.7622 - val_aux_loss: 0.5149 - val_aux_acc: 0.7202 - val_aux_recall: 0.7690\n",
      "Entrenando sin especie: Specie_Dog\n",
      "step: 25/200 ...  - loss: 0.4847 - val_loss: 0.4813\n",
      " - main_loss: 0.2928 - main_acc: 0.8742 - main_recall: 0.6456 - val_main_loss: 0.2918 - val_main_acc: 0.8756 - val_main_recall: 0.6557\n",
      " - aux_loss: 0.5329 - aux_acc: 0.7020 - aux_recall: 0.6449 - val_aux_loss: 0.5349 - val_aux_acc: 0.7043 - val_aux_recall: 0.6480\n",
      "step: 50/200 ...  - loss: 0.4648 - val_loss: 0.4732\n",
      " - main_loss: 0.2792 - main_acc: 0.8796 - main_recall: 0.6553 - val_main_loss: 0.2878 - val_main_acc: 0.8768 - val_main_recall: 0.6535\n",
      " - aux_loss: 0.5277 - aux_acc: 0.7046 - aux_recall: 0.6546 - val_aux_loss: 0.5301 - val_aux_acc: 0.7064 - val_aux_recall: 0.6462\n",
      "step: 75/200 ...  - loss: 0.4586 - val_loss: 0.4785\n",
      " - main_loss: 0.2722 - main_acc: 0.8841 - main_recall: 0.6627 - val_main_loss: 0.2908 - val_main_acc: 0.8754 - val_main_recall: 0.6604\n",
      " - aux_loss: 0.5246 - aux_acc: 0.7074 - aux_recall: 0.6620 - val_aux_loss: 0.5316 - val_aux_acc: 0.7066 - val_aux_recall: 0.6531\n",
      "step: 100/200 ...  - loss: 0.4501 - val_loss: 0.4773\n",
      " - main_loss: 0.2665 - main_acc: 0.8866 - main_recall: 0.6663 - val_main_loss: 0.2921 - val_main_acc: 0.8750 - val_main_recall: 0.6717\n",
      " - aux_loss: 0.5217 - aux_acc: 0.7091 - aux_recall: 0.6657 - val_aux_loss: 0.5310 - val_aux_acc: 0.7061 - val_aux_recall: 0.6641\n",
      "step: 125/200 ...  - loss: 0.4495 - val_loss: 0.4760\n",
      " - main_loss: 0.2644 - main_acc: 0.8877 - main_recall: 0.6657 - val_main_loss: 0.2900 - val_main_acc: 0.8762 - val_main_recall: 0.6615\n",
      " - aux_loss: 0.5211 - aux_acc: 0.7089 - aux_recall: 0.6651 - val_aux_loss: 0.5292 - val_aux_acc: 0.7068 - val_aux_recall: 0.6538\n",
      "step: 150/200 ...  - loss: 0.4460 - val_loss: 0.4840\n",
      " - main_loss: 0.2610 - main_acc: 0.8894 - main_recall: 0.6663 - val_main_loss: 0.2967 - val_main_acc: 0.8733 - val_main_recall: 0.6592\n",
      " - aux_loss: 0.5197 - aux_acc: 0.7101 - aux_recall: 0.6655 - val_aux_loss: 0.5310 - val_aux_acc: 0.7056 - val_aux_recall: 0.6519\n",
      "step: 175/200 ...  - loss: 0.4446 - val_loss: 0.4824\n",
      " - main_loss: 0.2596 - main_acc: 0.8898 - main_recall: 0.6711 - val_main_loss: 0.2954 - val_main_acc: 0.8742 - val_main_recall: 0.6605\n",
      " - aux_loss: 0.5185 - aux_acc: 0.7103 - aux_recall: 0.6704 - val_aux_loss: 0.5298 - val_aux_acc: 0.7076 - val_aux_recall: 0.6533\n",
      "step: 200/200 ...  - loss: 0.4395 - val_loss: 0.4831\n",
      " - main_loss: 0.2561 - main_acc: 0.8917 - main_recall: 0.6756 - val_main_loss: 0.2971 - val_main_acc: 0.8723 - val_main_recall: 0.6691\n",
      " - aux_loss: 0.5175 - aux_acc: 0.7125 - aux_recall: 0.6748 - val_aux_loss: 0.5320 - val_aux_acc: 0.7074 - val_aux_recall: 0.6618\n",
      "Evaluando especie sin balancear: Specie_Dog\n",
      "loss     = 2.7660\n",
      "main_loss     = 2.1850\n",
      "aux_loss     = 2.4872\n",
      "main_acc     = 0.3594\n",
      "main_recall     = 0.3216\n",
      "aux_acc     = 0.2808\n",
      "aux_recall     = 0.3224\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Dog\n",
      "loss     = 2.7660\n",
      "main_loss     = 2.1850\n",
      "aux_loss     = 2.4872\n",
      "main_acc     = 0.3594\n",
      "main_recall     = 0.3216\n",
      "aux_acc     = 0.2808\n",
      "aux_recall     = 0.3224\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 25/200 ...  - loss: 4.2687 - val_loss: 4.0575\n",
      " - main_loss: 0.4608 - main_acc: 0.7722 - main_recall: 0.7865 - val_main_loss: 0.4190 - val_main_acc: 0.8025 - val_main_recall: 0.7929\n",
      " - aux_loss: 0.4758 - aux_acc: 0.7249 - aux_recall: 0.7857 - val_aux_loss: 0.4728 - val_aux_acc: 0.7271 - val_aux_recall: 0.7901\n",
      "step: 50/200 ...  - loss: 0.9551 - val_loss: 0.9572\n",
      " - main_loss: 0.3375 - main_acc: 0.8525 - main_recall: 0.8064 - val_main_loss: 0.3492 - val_main_acc: 0.8454 - val_main_recall: 0.7856\n",
      " - aux_loss: 0.4525 - aux_acc: 0.7364 - aux_recall: 0.8052 - val_aux_loss: 0.4770 - val_aux_acc: 0.7322 - val_aux_recall: 0.7812\n",
      "step: 75/200 ...  - loss: 0.6392 - val_loss: 0.6618\n",
      " - main_loss: 0.3133 - main_acc: 0.8651 - main_recall: 0.8101 - val_main_loss: 0.3321 - val_main_acc: 0.8526 - val_main_recall: 0.7897\n",
      " - aux_loss: 0.4484 - aux_acc: 0.7423 - aux_recall: 0.8089 - val_aux_loss: 0.4711 - val_aux_acc: 0.7303 - val_aux_recall: 0.7851\n",
      "step: 100/200 ...  - loss: 0.5556 - val_loss: 0.5857\n",
      " - main_loss: 0.2981 - main_acc: 0.8721 - main_recall: 0.8141 - val_main_loss: 0.3240 - val_main_acc: 0.8579 - val_main_recall: 0.8013\n",
      " - aux_loss: 0.4423 - aux_acc: 0.7472 - aux_recall: 0.8129 - val_aux_loss: 0.4698 - val_aux_acc: 0.7308 - val_aux_recall: 0.7970\n",
      "step: 125/200 ...  - loss: 0.5180 - val_loss: 0.5544\n",
      " - main_loss: 0.2878 - main_acc: 0.8770 - main_recall: 0.8186 - val_main_loss: 0.3183 - val_main_acc: 0.8588 - val_main_recall: 0.7920\n",
      " - aux_loss: 0.4366 - aux_acc: 0.7507 - aux_recall: 0.8175 - val_aux_loss: 0.4670 - val_aux_acc: 0.7309 - val_aux_recall: 0.7877\n",
      "step: 150/200 ...  - loss: 0.4898 - val_loss: 0.5297\n",
      " - main_loss: 0.2754 - main_acc: 0.8823 - main_recall: 0.8283 - val_main_loss: 0.3102 - val_main_acc: 0.8628 - val_main_recall: 0.8116\n",
      " - aux_loss: 0.4277 - aux_acc: 0.7568 - aux_recall: 0.8271 - val_aux_loss: 0.4564 - val_aux_acc: 0.7376 - val_aux_recall: 0.8073\n",
      "step: 175/200 ...  - loss: 0.4705 - val_loss: 0.5189\n",
      " - main_loss: 0.2654 - main_acc: 0.8869 - main_recall: 0.8355 - val_main_loss: 0.3070 - val_main_acc: 0.8648 - val_main_recall: 0.8103\n",
      " - aux_loss: 0.4229 - aux_acc: 0.7605 - aux_recall: 0.8346 - val_aux_loss: 0.4573 - val_aux_acc: 0.7370 - val_aux_recall: 0.8060\n",
      "step: 200/200 ...  - loss: 0.4643 - val_loss: 0.5193\n",
      " - main_loss: 0.2576 - main_acc: 0.8900 - main_recall: 0.8405 - val_main_loss: 0.3058 - val_main_acc: 0.8644 - val_main_recall: 0.8160\n",
      " - aux_loss: 0.4199 - aux_acc: 0.7628 - aux_recall: 0.8395 - val_aux_loss: 0.4541 - val_aux_acc: 0.7390 - val_aux_recall: 0.8116\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 25/200 ...  - loss: 0.5735 - val_loss: 0.5759\n",
      " - main_loss: 0.3225 - main_acc: 0.8640 - main_recall: 0.7383 - val_main_loss: 0.3289 - val_main_acc: 0.8580 - val_main_recall: 0.7326\n",
      " - aux_loss: 0.5208 - aux_acc: 0.7006 - aux_recall: 0.7358 - val_aux_loss: 0.5290 - val_aux_acc: 0.6978 - val_aux_recall: 0.7267\n",
      "step: 50/200 ...  - loss: 0.5288 - val_loss: 0.5502\n",
      " - main_loss: 0.3017 - main_acc: 0.8728 - main_recall: 0.7553 - val_main_loss: 0.3190 - val_main_acc: 0.8627 - val_main_recall: 0.7573\n",
      " - aux_loss: 0.5103 - aux_acc: 0.7091 - aux_recall: 0.7530 - val_aux_loss: 0.5222 - val_aux_acc: 0.7011 - val_aux_recall: 0.7515\n",
      "step: 75/200 ...  - loss: 0.5118 - val_loss: 0.5448\n",
      " - main_loss: 0.2925 - main_acc: 0.8770 - main_recall: 0.7662 - val_main_loss: 0.3209 - val_main_acc: 0.8624 - val_main_recall: 0.7512\n",
      " - aux_loss: 0.5058 - aux_acc: 0.7125 - aux_recall: 0.7639 - val_aux_loss: 0.5252 - val_aux_acc: 0.6961 - val_aux_recall: 0.7454\n",
      "step: 100/200 ...  - loss: 0.5126 - val_loss: 0.5526\n",
      " - main_loss: 0.2863 - main_acc: 0.8798 - main_recall: 0.7674 - val_main_loss: 0.3214 - val_main_acc: 0.8626 - val_main_recall: 0.7440\n",
      " - aux_loss: 0.5037 - aux_acc: 0.7127 - aux_recall: 0.7653 - val_aux_loss: 0.5266 - val_aux_acc: 0.6971 - val_aux_recall: 0.7383\n",
      "step: 125/200 ...  - loss: 0.4949 - val_loss: 0.5399\n",
      " - main_loss: 0.2769 - main_acc: 0.8841 - main_recall: 0.7756 - val_main_loss: 0.3166 - val_main_acc: 0.8641 - val_main_recall: 0.7594\n",
      " - aux_loss: 0.4996 - aux_acc: 0.7168 - aux_recall: 0.7734 - val_aux_loss: 0.5260 - val_aux_acc: 0.6983 - val_aux_recall: 0.7536\n",
      "step: 150/200 ...  - loss: 0.4845 - val_loss: 0.5338\n",
      " - main_loss: 0.2711 - main_acc: 0.8871 - main_recall: 0.7787 - val_main_loss: 0.3142 - val_main_acc: 0.8659 - val_main_recall: 0.7538\n",
      " - aux_loss: 0.4979 - aux_acc: 0.7167 - aux_recall: 0.7765 - val_aux_loss: 0.5259 - val_aux_acc: 0.6958 - val_aux_recall: 0.7480\n",
      "step: 175/200 ...  - loss: 0.4835 - val_loss: 0.5370\n",
      " - main_loss: 0.2674 - main_acc: 0.8886 - main_recall: 0.7813 - val_main_loss: 0.3154 - val_main_acc: 0.8665 - val_main_recall: 0.7582\n",
      " - aux_loss: 0.4957 - aux_acc: 0.7194 - aux_recall: 0.7792 - val_aux_loss: 0.5233 - val_aux_acc: 0.7002 - val_aux_recall: 0.7522\n",
      "step: 200/200 ...  - loss: 0.4747 - val_loss: 0.5352\n",
      " - main_loss: 0.2622 - main_acc: 0.8909 - main_recall: 0.7885 - val_main_loss: 0.3151 - val_main_acc: 0.8667 - val_main_recall: 0.7794\n",
      " - aux_loss: 0.4927 - aux_acc: 0.7206 - aux_recall: 0.7866 - val_aux_loss: 0.5278 - val_aux_acc: 0.6950 - val_aux_recall: 0.7739\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 25/200 ...  - loss: 0.4940 - val_loss: 0.5523\n",
      " - main_loss: 0.2682 - main_acc: 0.8883 - main_recall: 0.7768 - val_main_loss: 0.3239 - val_main_acc: 0.8624 - val_main_recall: 0.7437\n",
      " - aux_loss: 0.5058 - aux_acc: 0.7136 - aux_recall: 0.7761 - val_aux_loss: 0.5386 - val_aux_acc: 0.6953 - val_aux_recall: 0.7398\n",
      "step: 50/200 ...  - loss: 0.4691 - val_loss: 0.5412\n",
      " - main_loss: 0.2557 - main_acc: 0.8943 - main_recall: 0.7887 - val_main_loss: 0.3212 - val_main_acc: 0.8636 - val_main_recall: 0.7607\n",
      " - aux_loss: 0.4972 - aux_acc: 0.7180 - aux_recall: 0.7881 - val_aux_loss: 0.5353 - val_aux_acc: 0.6897 - val_aux_recall: 0.7573\n",
      "step: 75/200 ...  - loss: 0.4562 - val_loss: 0.5380\n",
      " - main_loss: 0.2502 - main_acc: 0.8970 - main_recall: 0.7917 - val_main_loss: 0.3243 - val_main_acc: 0.8626 - val_main_recall: 0.7575\n",
      " - aux_loss: 0.4938 - aux_acc: 0.7217 - aux_recall: 0.7910 - val_aux_loss: 0.5350 - val_aux_acc: 0.6901 - val_aux_recall: 0.7543\n",
      "step: 100/200 ...  - loss: 0.4513 - val_loss: 0.5409\n",
      " - main_loss: 0.2446 - main_acc: 0.8991 - main_recall: 0.7951 - val_main_loss: 0.3251 - val_main_acc: 0.8620 - val_main_recall: 0.7717\n",
      " - aux_loss: 0.4917 - aux_acc: 0.7226 - aux_recall: 0.7944 - val_aux_loss: 0.5366 - val_aux_acc: 0.6928 - val_aux_recall: 0.7688\n",
      "step: 125/200 ...  - loss: 0.4419 - val_loss: 0.5383\n",
      " - main_loss: 0.2405 - main_acc: 0.9011 - main_recall: 0.7976 - val_main_loss: 0.3275 - val_main_acc: 0.8624 - val_main_recall: 0.7579\n",
      " - aux_loss: 0.4897 - aux_acc: 0.7233 - aux_recall: 0.7969 - val_aux_loss: 0.5401 - val_aux_acc: 0.6947 - val_aux_recall: 0.7547\n",
      "step: 150/200 ...  - loss: 0.4396 - val_loss: 0.5408\n",
      " - main_loss: 0.2376 - main_acc: 0.9028 - main_recall: 0.8031 - val_main_loss: 0.3295 - val_main_acc: 0.8622 - val_main_recall: 0.7761\n",
      " - aux_loss: 0.4867 - aux_acc: 0.7260 - aux_recall: 0.8024 - val_aux_loss: 0.5385 - val_aux_acc: 0.6909 - val_aux_recall: 0.7734\n",
      "step: 175/200 ...  - loss: 0.4357 - val_loss: 0.5426\n",
      " - main_loss: 0.2347 - main_acc: 0.9036 - main_recall: 0.8031 - val_main_loss: 0.3312 - val_main_acc: 0.8613 - val_main_recall: 0.7646\n",
      " - aux_loss: 0.4869 - aux_acc: 0.7258 - aux_recall: 0.8023 - val_aux_loss: 0.5407 - val_aux_acc: 0.6908 - val_aux_recall: 0.7615\n",
      "step: 200/200 ...  - loss: 0.4308 - val_loss: 0.5430\n",
      " - main_loss: 0.2323 - main_acc: 0.9049 - main_recall: 0.8051 - val_main_loss: 0.3335 - val_main_acc: 0.8610 - val_main_recall: 0.7539\n",
      " - aux_loss: 0.4851 - aux_acc: 0.7273 - aux_recall: 0.8044 - val_aux_loss: 0.5415 - val_aux_acc: 0.6947 - val_aux_recall: 0.7506\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 25/200 ...  - loss: 0.3575 - val_loss: 0.3633\n",
      " - main_loss: 0.1871 - main_acc: 0.9273 - main_recall: 0.9184 - val_main_loss: 0.1957 - val_main_acc: 0.9222 - val_main_recall: 0.9116\n",
      " - aux_loss: 0.3470 - aux_acc: 0.8117 - aux_recall: 0.9183 - val_aux_loss: 0.3627 - val_aux_acc: 0.8020 - val_aux_recall: 0.9116\n",
      "step: 50/200 ...  - loss: 0.3056 - val_loss: 0.3218\n",
      " - main_loss: 0.1609 - main_acc: 0.9347 - main_recall: 0.9233 - val_main_loss: 0.1756 - val_main_acc: 0.9288 - val_main_recall: 0.9138\n",
      " - aux_loss: 0.3327 - aux_acc: 0.8192 - aux_recall: 0.9232 - val_aux_loss: 0.3471 - val_aux_acc: 0.8135 - val_aux_recall: 0.9137\n",
      "step: 75/200 ...  - loss: 0.2906 - val_loss: 0.3217\n",
      " - main_loss: 0.1531 - main_acc: 0.9380 - main_recall: 0.9261 - val_main_loss: 0.1808 - val_main_acc: 0.9275 - val_main_recall: 0.9183\n",
      " - aux_loss: 0.3272 - aux_acc: 0.8205 - aux_recall: 0.9260 - val_aux_loss: 0.3496 - val_aux_acc: 0.8068 - val_aux_recall: 0.9183\n",
      "step: 100/200 ...  - loss: 0.2914 - val_loss: 0.3270\n",
      " - main_loss: 0.1498 - main_acc: 0.9395 - main_recall: 0.9290 - val_main_loss: 0.1816 - val_main_acc: 0.9255 - val_main_recall: 0.9148\n",
      " - aux_loss: 0.3251 - aux_acc: 0.8229 - aux_recall: 0.9289 - val_aux_loss: 0.3512 - val_aux_acc: 0.8037 - val_aux_recall: 0.9147\n",
      "step: 125/200 ...  - loss: 0.2859 - val_loss: 0.3286\n",
      " - main_loss: 0.1453 - main_acc: 0.9414 - main_recall: 0.9292 - val_main_loss: 0.1833 - val_main_acc: 0.9237 - val_main_recall: 0.9118\n",
      " - aux_loss: 0.3220 - aux_acc: 0.8250 - aux_recall: 0.9291 - val_aux_loss: 0.3504 - val_aux_acc: 0.8056 - val_aux_recall: 0.9117\n",
      "step: 150/200 ...  - loss: 0.2821 - val_loss: 0.3315\n",
      " - main_loss: 0.1413 - main_acc: 0.9430 - main_recall: 0.9296 - val_main_loss: 0.1861 - val_main_acc: 0.9249 - val_main_recall: 0.9133\n",
      " - aux_loss: 0.3191 - aux_acc: 0.8264 - aux_recall: 0.9295 - val_aux_loss: 0.3528 - val_aux_acc: 0.8016 - val_aux_recall: 0.9131\n",
      "step: 175/200 ...  - loss: 0.2734 - val_loss: 0.3339\n",
      " - main_loss: 0.1350 - main_acc: 0.9454 - main_recall: 0.9342 - val_main_loss: 0.1886 - val_main_acc: 0.9229 - val_main_recall: 0.9155\n",
      " - aux_loss: 0.3154 - aux_acc: 0.8288 - aux_recall: 0.9341 - val_aux_loss: 0.3560 - val_aux_acc: 0.8049 - val_aux_recall: 0.9155\n",
      "step: 200/200 ...  - loss: 0.2743 - val_loss: 0.3356\n",
      " - main_loss: 0.1343 - main_acc: 0.9465 - main_recall: 0.9328 - val_main_loss: 0.1890 - val_main_acc: 0.9233 - val_main_recall: 0.9179\n",
      " - aux_loss: 0.3138 - aux_acc: 0.8299 - aux_recall: 0.9326 - val_aux_loss: 0.3526 - val_aux_acc: 0.8054 - val_aux_recall: 0.9178\n",
      "Entrenando sin especie: Specie_Human\n",
      "step: 25/200 ...  - loss: 0.3851 - val_loss: 0.3990\n",
      " - main_loss: 0.2177 - main_acc: 0.9083 - main_recall: 0.8083 - val_main_loss: 0.2326 - val_main_acc: 0.8963 - val_main_recall: 0.7945\n",
      " - aux_loss: 0.4014 - aux_acc: 0.7713 - aux_recall: 0.8081 - val_aux_loss: 0.4137 - val_aux_acc: 0.7638 - val_aux_recall: 0.7903\n",
      "step: 50/200 ...  - loss: 0.3538 - val_loss: 0.3822\n",
      " - main_loss: 0.1959 - main_acc: 0.9180 - main_recall: 0.8202 - val_main_loss: 0.2233 - val_main_acc: 0.9019 - val_main_recall: 0.8107\n",
      " - aux_loss: 0.3899 - aux_acc: 0.7802 - aux_recall: 0.8200 - val_aux_loss: 0.4010 - val_aux_acc: 0.7708 - val_aux_recall: 0.8066\n",
      "step: 75/200 ...  - loss: 0.3395 - val_loss: 0.3756\n",
      " - main_loss: 0.1856 - main_acc: 0.9231 - main_recall: 0.8258 - val_main_loss: 0.2203 - val_main_acc: 0.9047 - val_main_recall: 0.8103\n",
      " - aux_loss: 0.3835 - aux_acc: 0.7836 - aux_recall: 0.8255 - val_aux_loss: 0.3984 - val_aux_acc: 0.7705 - val_aux_recall: 0.8061\n",
      "step: 100/200 ...  - loss: 0.3353 - val_loss: 0.3784\n",
      " - main_loss: 0.1803 - main_acc: 0.9251 - main_recall: 0.8306 - val_main_loss: 0.2213 - val_main_acc: 0.9028 - val_main_recall: 0.8115\n",
      " - aux_loss: 0.3813 - aux_acc: 0.7850 - aux_recall: 0.8304 - val_aux_loss: 0.3983 - val_aux_acc: 0.7730 - val_aux_recall: 0.8073\n",
      "step: 125/200 ...  - loss: 0.3270 - val_loss: 0.3774\n",
      " - main_loss: 0.1756 - main_acc: 0.9276 - main_recall: 0.8305 - val_main_loss: 0.2238 - val_main_acc: 0.9035 - val_main_recall: 0.8118\n",
      " - aux_loss: 0.3798 - aux_acc: 0.7867 - aux_recall: 0.8303 - val_aux_loss: 0.3998 - val_aux_acc: 0.7717 - val_aux_recall: 0.8077\n",
      "step: 150/200 ...  - loss: 0.3244 - val_loss: 0.3850\n",
      " - main_loss: 0.1714 - main_acc: 0.9296 - main_recall: 0.8345 - val_main_loss: 0.2277 - val_main_acc: 0.9026 - val_main_recall: 0.8227\n",
      " - aux_loss: 0.3769 - aux_acc: 0.7884 - aux_recall: 0.8342 - val_aux_loss: 0.4021 - val_aux_acc: 0.7702 - val_aux_recall: 0.8187\n",
      "step: 175/200 ...  - loss: 0.3184 - val_loss: 0.3820\n",
      " - main_loss: 0.1671 - main_acc: 0.9317 - main_recall: 0.8386 - val_main_loss: 0.2269 - val_main_acc: 0.9041 - val_main_recall: 0.8244\n",
      " - aux_loss: 0.3742 - aux_acc: 0.7897 - aux_recall: 0.8383 - val_aux_loss: 0.4008 - val_aux_acc: 0.7705 - val_aux_recall: 0.8204\n",
      "step: 200/200 ...  - loss: 0.3176 - val_loss: 0.3879\n",
      " - main_loss: 0.1648 - main_acc: 0.9322 - main_recall: 0.8399 - val_main_loss: 0.2306 - val_main_acc: 0.9025 - val_main_recall: 0.8179\n",
      " - aux_loss: 0.3736 - aux_acc: 0.7910 - aux_recall: 0.8397 - val_aux_loss: 0.4019 - val_aux_acc: 0.7738 - val_aux_recall: 0.8140\n",
      "Evaluando especie sin balancear: Specie_Human\n",
      "loss     = 5.6533\n",
      "main_loss     = 4.6745\n",
      "aux_loss     = 4.4955\n",
      "main_acc     = 0.6663\n",
      "main_recall     = 0.0006\n",
      "aux_acc     = 0.6667\n",
      "aux_recall     = 0.0006\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Human\n",
      "loss     = 8.4385\n",
      "main_loss     = 7.0101\n",
      "aux_loss     = 6.7432\n",
      "main_acc     = 0.4998\n",
      "main_recall     = 0.0006\n",
      "aux_acc     = 0.5000\n",
      "aux_recall     = 0.0006\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 25/200 ...  - loss: 4.5670 - val_loss: 4.3447\n",
      " - main_loss: 0.5289 - main_acc: 0.7270 - main_recall: 0.5593 - val_main_loss: 0.4823 - val_main_acc: 0.7648 - val_main_recall: 0.6172\n",
      " - aux_loss: 0.5953 - aux_acc: 0.6632 - aux_recall: 0.5590 - val_aux_loss: 0.5745 - val_aux_acc: 0.6785 - val_aux_recall: 0.6155\n",
      "step: 50/200 ...  - loss: 1.0184 - val_loss: 1.0008\n",
      " - main_loss: 0.4303 - main_acc: 0.8052 - main_recall: 0.6351 - val_main_loss: 0.4265 - val_main_acc: 0.8092 - val_main_recall: 0.6545\n",
      " - aux_loss: 0.5676 - aux_acc: 0.6744 - aux_recall: 0.6347 - val_aux_loss: 0.5804 - val_aux_acc: 0.6706 - val_aux_recall: 0.6515\n",
      "step: 75/200 ...  - loss: 0.7394 - val_loss: 0.7373\n",
      " - main_loss: 0.4084 - main_acc: 0.8186 - main_recall: 0.6406 - val_main_loss: 0.4063 - val_main_acc: 0.8215 - val_main_recall: 0.6257\n",
      " - aux_loss: 0.5666 - aux_acc: 0.6714 - aux_recall: 0.6401 - val_aux_loss: 0.5842 - val_aux_acc: 0.6697 - val_aux_recall: 0.6215\n",
      "step: 100/200 ...  - loss: 0.6710 - val_loss: 0.6735\n",
      " - main_loss: 0.3903 - main_acc: 0.8275 - main_recall: 0.6441 - val_main_loss: 0.3924 - val_main_acc: 0.8262 - val_main_recall: 0.6256\n",
      " - aux_loss: 0.5615 - aux_acc: 0.6738 - aux_recall: 0.6436 - val_aux_loss: 0.5816 - val_aux_acc: 0.6710 - val_aux_recall: 0.6217\n",
      "step: 125/200 ...  - loss: 0.6393 - val_loss: 0.6414\n",
      " - main_loss: 0.3759 - main_acc: 0.8339 - main_recall: 0.6587 - val_main_loss: 0.3786 - val_main_acc: 0.8341 - val_main_recall: 0.6614\n",
      " - aux_loss: 0.5570 - aux_acc: 0.6786 - aux_recall: 0.6582 - val_aux_loss: 0.5686 - val_aux_acc: 0.6752 - val_aux_recall: 0.6584\n",
      "step: 150/200 ...  - loss: 0.6211 - val_loss: 0.6225\n",
      " - main_loss: 0.3650 - main_acc: 0.8397 - main_recall: 0.6644 - val_main_loss: 0.3663 - val_main_acc: 0.8401 - val_main_recall: 0.6576\n",
      " - aux_loss: 0.5558 - aux_acc: 0.6805 - aux_recall: 0.6640 - val_aux_loss: 0.5663 - val_aux_acc: 0.6802 - val_aux_recall: 0.6543\n",
      "step: 175/200 ...  - loss: 0.5968 - val_loss: 0.6035\n",
      " - main_loss: 0.3550 - main_acc: 0.8446 - main_recall: 0.6741 - val_main_loss: 0.3600 - val_main_acc: 0.8427 - val_main_recall: 0.6829\n",
      " - aux_loss: 0.5526 - aux_acc: 0.6840 - aux_recall: 0.6736 - val_aux_loss: 0.5653 - val_aux_acc: 0.6758 - val_aux_recall: 0.6800\n",
      "step: 200/200 ...  - loss: 0.5802 - val_loss: 0.5887\n",
      " - main_loss: 0.3451 - main_acc: 0.8495 - main_recall: 0.6752 - val_main_loss: 0.3537 - val_main_acc: 0.8469 - val_main_recall: 0.6746\n",
      " - aux_loss: 0.5478 - aux_acc: 0.6868 - aux_recall: 0.6748 - val_aux_loss: 0.5629 - val_aux_acc: 0.6805 - val_aux_recall: 0.6712\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 25/200 ...  - loss: 0.6543 - val_loss: 0.6603\n",
      " - main_loss: 0.3874 - main_acc: 0.8341 - main_recall: 0.5460 - val_main_loss: 0.3982 - val_main_acc: 0.8253 - val_main_recall: 0.5219\n",
      " - aux_loss: 0.6203 - aux_acc: 0.6447 - aux_recall: 0.5445 - val_aux_loss: 0.6250 - val_aux_acc: 0.6448 - val_aux_recall: 0.5164\n",
      "step: 50/200 ...  - loss: 0.6199 - val_loss: 0.6417\n",
      " - main_loss: 0.3688 - main_acc: 0.8415 - main_recall: 0.5596 - val_main_loss: 0.3873 - val_main_acc: 0.8308 - val_main_recall: 0.5382\n",
      " - aux_loss: 0.6127 - aux_acc: 0.6489 - aux_recall: 0.5582 - val_aux_loss: 0.6237 - val_aux_acc: 0.6453 - val_aux_recall: 0.5328\n",
      "step: 75/200 ...  - loss: 0.6102 - val_loss: 0.6383\n",
      " - main_loss: 0.3594 - main_acc: 0.8457 - main_recall: 0.5695 - val_main_loss: 0.3852 - val_main_acc: 0.8302 - val_main_recall: 0.5337\n",
      " - aux_loss: 0.6096 - aux_acc: 0.6523 - aux_recall: 0.5682 - val_aux_loss: 0.6223 - val_aux_acc: 0.6474 - val_aux_recall: 0.5281\n",
      "step: 100/200 ...  - loss: 0.5958 - val_loss: 0.6296\n",
      " - main_loss: 0.3529 - main_acc: 0.8488 - main_recall: 0.5759 - val_main_loss: 0.3837 - val_main_acc: 0.8302 - val_main_recall: 0.5392\n",
      " - aux_loss: 0.6063 - aux_acc: 0.6538 - aux_recall: 0.5746 - val_aux_loss: 0.6228 - val_aux_acc: 0.6484 - val_aux_recall: 0.5342\n",
      "step: 125/200 ...  - loss: 0.5896 - val_loss: 0.6290\n",
      " - main_loss: 0.3469 - main_acc: 0.8521 - main_recall: 0.5804 - val_main_loss: 0.3824 - val_main_acc: 0.8320 - val_main_recall: 0.5422\n",
      " - aux_loss: 0.6050 - aux_acc: 0.6540 - aux_recall: 0.5790 - val_aux_loss: 0.6210 - val_aux_acc: 0.6497 - val_aux_recall: 0.5366\n",
      "step: 150/200 ...  - loss: 0.5822 - val_loss: 0.6243\n",
      " - main_loss: 0.3419 - main_acc: 0.8535 - main_recall: 0.5846 - val_main_loss: 0.3804 - val_main_acc: 0.8332 - val_main_recall: 0.5485\n",
      " - aux_loss: 0.6041 - aux_acc: 0.6553 - aux_recall: 0.5832 - val_aux_loss: 0.6220 - val_aux_acc: 0.6476 - val_aux_recall: 0.5431\n",
      "step: 175/200 ...  - loss: 0.5750 - val_loss: 0.6245\n",
      " - main_loss: 0.3372 - main_acc: 0.8564 - main_recall: 0.5882 - val_main_loss: 0.3840 - val_main_acc: 0.8328 - val_main_recall: 0.5381\n",
      " - aux_loss: 0.6025 - aux_acc: 0.6561 - aux_recall: 0.5868 - val_aux_loss: 0.6226 - val_aux_acc: 0.6491 - val_aux_recall: 0.5329\n",
      "step: 200/200 ...  - loss: 0.5719 - val_loss: 0.6239\n",
      " - main_loss: 0.3343 - main_acc: 0.8577 - main_recall: 0.5900 - val_main_loss: 0.3828 - val_main_acc: 0.8335 - val_main_recall: 0.5414\n",
      " - aux_loss: 0.6018 - aux_acc: 0.6576 - aux_recall: 0.5885 - val_aux_loss: 0.6216 - val_aux_acc: 0.6504 - val_aux_recall: 0.5360\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 25/200 ...  - loss: 0.5188 - val_loss: 0.5135\n",
      " - main_loss: 0.3004 - main_acc: 0.8745 - main_recall: 0.7485 - val_main_loss: 0.2991 - val_main_acc: 0.8711 - val_main_recall: 0.7302\n",
      " - aux_loss: 0.5385 - aux_acc: 0.6917 - aux_recall: 0.7478 - val_aux_loss: 0.5421 - val_aux_acc: 0.6977 - val_aux_recall: 0.7256\n",
      "step: 50/200 ...  - loss: 0.4829 - val_loss: 0.4964\n",
      " - main_loss: 0.2815 - main_acc: 0.8817 - main_recall: 0.7578 - val_main_loss: 0.2924 - val_main_acc: 0.8743 - val_main_recall: 0.7492\n",
      " - aux_loss: 0.5229 - aux_acc: 0.7018 - aux_recall: 0.7571 - val_aux_loss: 0.5307 - val_aux_acc: 0.6992 - val_aux_recall: 0.7452\n",
      "step: 75/200 ...  - loss: 0.4768 - val_loss: 0.4994\n",
      " - main_loss: 0.2732 - main_acc: 0.8849 - main_recall: 0.7641 - val_main_loss: 0.2942 - val_main_acc: 0.8736 - val_main_recall: 0.7359\n",
      " - aux_loss: 0.5196 - aux_acc: 0.7037 - aux_recall: 0.7634 - val_aux_loss: 0.5299 - val_aux_acc: 0.6987 - val_aux_recall: 0.7316\n",
      "step: 100/200 ...  - loss: 0.4688 - val_loss: 0.4988\n",
      " - main_loss: 0.2667 - main_acc: 0.8874 - main_recall: 0.7658 - val_main_loss: 0.2954 - val_main_acc: 0.8731 - val_main_recall: 0.7437\n",
      " - aux_loss: 0.5165 - aux_acc: 0.7057 - aux_recall: 0.7651 - val_aux_loss: 0.5293 - val_aux_acc: 0.6999 - val_aux_recall: 0.7395\n",
      "step: 125/200 ...  - loss: 0.4628 - val_loss: 0.4984\n",
      " - main_loss: 0.2619 - main_acc: 0.8903 - main_recall: 0.7688 - val_main_loss: 0.2946 - val_main_acc: 0.8748 - val_main_recall: 0.7487\n",
      " - aux_loss: 0.5134 - aux_acc: 0.7092 - aux_recall: 0.7682 - val_aux_loss: 0.5279 - val_aux_acc: 0.6998 - val_aux_recall: 0.7447\n",
      "step: 150/200 ...  - loss: 0.4567 - val_loss: 0.4989\n",
      " - main_loss: 0.2568 - main_acc: 0.8933 - main_recall: 0.7763 - val_main_loss: 0.2965 - val_main_acc: 0.8743 - val_main_recall: 0.7516\n",
      " - aux_loss: 0.5095 - aux_acc: 0.7121 - aux_recall: 0.7756 - val_aux_loss: 0.5261 - val_aux_acc: 0.7007 - val_aux_recall: 0.7478\n",
      "step: 175/200 ...  - loss: 0.4482 - val_loss: 0.5003\n",
      " - main_loss: 0.2510 - main_acc: 0.8964 - main_recall: 0.7799 - val_main_loss: 0.2992 - val_main_acc: 0.8724 - val_main_recall: 0.7594\n",
      " - aux_loss: 0.5079 - aux_acc: 0.7137 - aux_recall: 0.7791 - val_aux_loss: 0.5301 - val_aux_acc: 0.6981 - val_aux_recall: 0.7560\n",
      "step: 200/200 ...  - loss: 0.4443 - val_loss: 0.5027\n",
      " - main_loss: 0.2462 - main_acc: 0.8980 - main_recall: 0.7839 - val_main_loss: 0.3002 - val_main_acc: 0.8728 - val_main_recall: 0.7561\n",
      " - aux_loss: 0.5054 - aux_acc: 0.7156 - aux_recall: 0.7832 - val_aux_loss: 0.5301 - val_aux_acc: 0.6996 - val_aux_recall: 0.7525\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 25/200 ...  - loss: 0.5011 - val_loss: 0.4908\n",
      " - main_loss: 0.3042 - main_acc: 0.8688 - main_recall: 0.7225 - val_main_loss: 0.2947 - val_main_acc: 0.8764 - val_main_recall: 0.7437\n",
      " - aux_loss: 0.5193 - aux_acc: 0.7114 - aux_recall: 0.7211 - val_aux_loss: 0.5283 - val_aux_acc: 0.7084 - val_aux_recall: 0.7420\n",
      "step: 50/200 ...  - loss: 0.4778 - val_loss: 0.4793\n",
      " - main_loss: 0.2874 - main_acc: 0.8773 - main_recall: 0.7330 - val_main_loss: 0.2876 - val_main_acc: 0.8805 - val_main_recall: 0.7481\n",
      " - aux_loss: 0.5116 - aux_acc: 0.7162 - aux_recall: 0.7316 - val_aux_loss: 0.5194 - val_aux_acc: 0.7133 - val_aux_recall: 0.7465\n",
      "step: 75/200 ...  - loss: 0.4695 - val_loss: 0.4784\n",
      " - main_loss: 0.2807 - main_acc: 0.8803 - main_recall: 0.7363 - val_main_loss: 0.2877 - val_main_acc: 0.8787 - val_main_recall: 0.7464\n",
      " - aux_loss: 0.5092 - aux_acc: 0.7175 - aux_recall: 0.7350 - val_aux_loss: 0.5191 - val_aux_acc: 0.7149 - val_aux_recall: 0.7446\n",
      "step: 100/200 ...  - loss: 0.4614 - val_loss: 0.4761\n",
      " - main_loss: 0.2754 - main_acc: 0.8826 - main_recall: 0.7426 - val_main_loss: 0.2877 - val_main_acc: 0.8789 - val_main_recall: 0.7456\n",
      " - aux_loss: 0.5065 - aux_acc: 0.7189 - aux_recall: 0.7412 - val_aux_loss: 0.5177 - val_aux_acc: 0.7134 - val_aux_recall: 0.7440\n",
      "step: 125/200 ...  - loss: 0.4562 - val_loss: 0.4804\n",
      " - main_loss: 0.2692 - main_acc: 0.8856 - main_recall: 0.7503 - val_main_loss: 0.2904 - val_main_acc: 0.8770 - val_main_recall: 0.7451\n",
      " - aux_loss: 0.5030 - aux_acc: 0.7207 - aux_recall: 0.7488 - val_aux_loss: 0.5185 - val_aux_acc: 0.7135 - val_aux_recall: 0.7432\n",
      "step: 150/200 ...  - loss: 0.4511 - val_loss: 0.4817\n",
      " - main_loss: 0.2666 - main_acc: 0.8870 - main_recall: 0.7528 - val_main_loss: 0.2934 - val_main_acc: 0.8765 - val_main_recall: 0.7642\n",
      " - aux_loss: 0.5006 - aux_acc: 0.7224 - aux_recall: 0.7514 - val_aux_loss: 0.5199 - val_aux_acc: 0.7152 - val_aux_recall: 0.7627\n",
      "step: 175/200 ...  - loss: 0.4457 - val_loss: 0.4797\n",
      " - main_loss: 0.2607 - main_acc: 0.8893 - main_recall: 0.7543 - val_main_loss: 0.2910 - val_main_acc: 0.8773 - val_main_recall: 0.7576\n",
      " - aux_loss: 0.4997 - aux_acc: 0.7229 - aux_recall: 0.7529 - val_aux_loss: 0.5190 - val_aux_acc: 0.7155 - val_aux_recall: 0.7560\n",
      "step: 200/200 ...  - loss: 0.4453 - val_loss: 0.4845\n",
      " - main_loss: 0.2596 - main_acc: 0.8896 - main_recall: 0.7545 - val_main_loss: 0.2938 - val_main_acc: 0.8763 - val_main_recall: 0.7546\n",
      " - aux_loss: 0.4986 - aux_acc: 0.7227 - aux_recall: 0.7531 - val_aux_loss: 0.5225 - val_aux_acc: 0.7125 - val_aux_recall: 0.7530\n",
      "Entrenando sin especie: Specie_Mouse\n",
      "step: 25/200 ...  - loss: 0.4893 - val_loss: 0.4874\n",
      " - main_loss: 0.2973 - main_acc: 0.8721 - main_recall: 0.6340 - val_main_loss: 0.2967 - val_main_acc: 0.8734 - val_main_recall: 0.6349\n",
      " - aux_loss: 0.5341 - aux_acc: 0.7009 - aux_recall: 0.6321 - val_aux_loss: 0.5365 - val_aux_acc: 0.7044 - val_aux_recall: 0.6301\n",
      "step: 50/200 ...  - loss: 0.4719 - val_loss: 0.4848\n",
      " - main_loss: 0.2847 - main_acc: 0.8777 - main_recall: 0.6412 - val_main_loss: 0.2966 - val_main_acc: 0.8719 - val_main_recall: 0.6490\n",
      " - aux_loss: 0.5292 - aux_acc: 0.7051 - aux_recall: 0.6394 - val_aux_loss: 0.5340 - val_aux_acc: 0.7069 - val_aux_recall: 0.6440\n",
      "step: 75/200 ...  - loss: 0.4631 - val_loss: 0.4819\n",
      " - main_loss: 0.2759 - main_acc: 0.8817 - main_recall: 0.6475 - val_main_loss: 0.2935 - val_main_acc: 0.8733 - val_main_recall: 0.6386\n",
      " - aux_loss: 0.5256 - aux_acc: 0.7057 - aux_recall: 0.6456 - val_aux_loss: 0.5307 - val_aux_acc: 0.7078 - val_aux_recall: 0.6335\n",
      "step: 100/200 ...  - loss: 0.4573 - val_loss: 0.4824\n",
      " - main_loss: 0.2710 - main_acc: 0.8843 - main_recall: 0.6557 - val_main_loss: 0.2946 - val_main_acc: 0.8714 - val_main_recall: 0.6478\n",
      " - aux_loss: 0.5222 - aux_acc: 0.7089 - aux_recall: 0.6538 - val_aux_loss: 0.5321 - val_aux_acc: 0.7073 - val_aux_recall: 0.6429\n",
      "step: 125/200 ...  - loss: 0.4534 - val_loss: 0.4844\n",
      " - main_loss: 0.2664 - main_acc: 0.8868 - main_recall: 0.6586 - val_main_loss: 0.2960 - val_main_acc: 0.8718 - val_main_recall: 0.6412\n",
      " - aux_loss: 0.5214 - aux_acc: 0.7101 - aux_recall: 0.6566 - val_aux_loss: 0.5304 - val_aux_acc: 0.7070 - val_aux_recall: 0.6360\n",
      "step: 150/200 ...  - loss: 0.4493 - val_loss: 0.4869\n",
      " - main_loss: 0.2622 - main_acc: 0.8883 - main_recall: 0.6610 - val_main_loss: 0.2972 - val_main_acc: 0.8715 - val_main_recall: 0.6537\n",
      " - aux_loss: 0.5205 - aux_acc: 0.7101 - aux_recall: 0.6591 - val_aux_loss: 0.5328 - val_aux_acc: 0.7069 - val_aux_recall: 0.6487\n",
      "step: 175/200 ...  - loss: 0.4488 - val_loss: 0.4903\n",
      " - main_loss: 0.2619 - main_acc: 0.8887 - main_recall: 0.6628 - val_main_loss: 0.2999 - val_main_acc: 0.8689 - val_main_recall: 0.6406\n",
      " - aux_loss: 0.5209 - aux_acc: 0.7108 - aux_recall: 0.6609 - val_aux_loss: 0.5365 - val_aux_acc: 0.7071 - val_aux_recall: 0.6353\n",
      "step: 200/200 ...  - loss: 0.4462 - val_loss: 0.4892\n",
      " - main_loss: 0.2592 - main_acc: 0.8897 - main_recall: 0.6651 - val_main_loss: 0.2993 - val_main_acc: 0.8711 - val_main_recall: 0.6480\n",
      " - aux_loss: 0.5197 - aux_acc: 0.7122 - aux_recall: 0.6633 - val_aux_loss: 0.5352 - val_aux_acc: 0.7050 - val_aux_recall: 0.6430\n",
      "Evaluando especie sin balancear: Specie_Mouse\n",
      "loss     = 1.4065\n",
      "main_loss     = 1.2291\n",
      "aux_loss     = 0.4793\n",
      "main_acc     = 0.5085\n",
      "main_recall     = 0.6562\n",
      "aux_acc     = 0.8084\n",
      "aux_recall     = 0.6624\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Mouse\n",
      "loss     = 1.4065\n",
      "main_loss     = 1.2291\n",
      "aux_loss     = 0.4793\n",
      "main_acc     = 0.5085\n",
      "main_recall     = 0.6562\n",
      "aux_acc     = 0.8084\n",
      "aux_recall     = 0.6624\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 25/200 ...  - loss: 6.6222 - val_loss: 6.4577\n",
      " - main_loss: 0.4654 - main_acc: 0.7561 - main_recall: 0.7279 - val_main_loss: 0.4087 - val_main_acc: 0.7874 - val_main_recall: 0.7617\n",
      " - aux_loss: 0.4804 - aux_acc: 0.7302 - aux_recall: 0.7279 - val_aux_loss: 0.4576 - val_aux_acc: 0.7405 - val_aux_recall: 0.7618\n",
      "step: 50/200 ...  - loss: 3.9157 - val_loss: 3.8415\n",
      " - main_loss: 0.3745 - main_acc: 0.8242 - main_recall: 0.7753 - val_main_loss: 0.3484 - val_main_acc: 0.8355 - val_main_recall: 0.7975\n",
      " - aux_loss: 0.4432 - aux_acc: 0.7515 - aux_recall: 0.7753 - val_aux_loss: 0.4432 - val_aux_acc: 0.7503 - val_aux_recall: 0.7972\n",
      "step: 75/200 ...  - loss: 2.4678 - val_loss: 2.4276\n",
      " - main_loss: 0.3489 - main_acc: 0.8407 - main_recall: 0.7925 - val_main_loss: 0.3367 - val_main_acc: 0.8449 - val_main_recall: 0.8158\n",
      " - aux_loss: 0.4331 - aux_acc: 0.7583 - aux_recall: 0.7925 - val_aux_loss: 0.4387 - val_aux_acc: 0.7584 - val_aux_recall: 0.8150\n",
      "step: 100/200 ...  - loss: 1.6510 - val_loss: 1.6303\n",
      " - main_loss: 0.3305 - main_acc: 0.8509 - main_recall: 0.8055 - val_main_loss: 0.3299 - val_main_acc: 0.8512 - val_main_recall: 0.8251\n",
      " - aux_loss: 0.4252 - aux_acc: 0.7640 - aux_recall: 0.8055 - val_aux_loss: 0.4368 - val_aux_acc: 0.7595 - val_aux_recall: 0.8239\n",
      "step: 125/200 ...  - loss: 1.1509 - val_loss: 1.1403\n",
      " - main_loss: 0.3200 - main_acc: 0.8571 - main_recall: 0.8105 - val_main_loss: 0.3246 - val_main_acc: 0.8544 - val_main_recall: 0.8024\n",
      " - aux_loss: 0.4246 - aux_acc: 0.7660 - aux_recall: 0.8105 - val_aux_loss: 0.4415 - val_aux_acc: 0.7548 - val_aux_recall: 0.8010\n",
      "step: 150/200 ...  - loss: 0.8984 - val_loss: 0.9020\n",
      " - main_loss: 0.3087 - main_acc: 0.8637 - main_recall: 0.8177 - val_main_loss: 0.3201 - val_main_acc: 0.8576 - val_main_recall: 0.8129\n",
      " - aux_loss: 0.4190 - aux_acc: 0.7695 - aux_recall: 0.8177 - val_aux_loss: 0.4423 - val_aux_acc: 0.7581 - val_aux_recall: 0.8116\n",
      "step: 175/200 ...  - loss: 0.7951 - val_loss: 0.8018\n",
      " - main_loss: 0.3010 - main_acc: 0.8684 - main_recall: 0.8202 - val_main_loss: 0.3134 - val_main_acc: 0.8625 - val_main_recall: 0.8126\n",
      " - aux_loss: 0.4174 - aux_acc: 0.7719 - aux_recall: 0.8202 - val_aux_loss: 0.4414 - val_aux_acc: 0.7582 - val_aux_recall: 0.8111\n",
      "step: 200/200 ...  - loss: 0.7367 - val_loss: 0.7491\n",
      " - main_loss: 0.2939 - main_acc: 0.8725 - main_recall: 0.8222 - val_main_loss: 0.3102 - val_main_acc: 0.8630 - val_main_recall: 0.8157\n",
      " - aux_loss: 0.4160 - aux_acc: 0.7741 - aux_recall: 0.8222 - val_aux_loss: 0.4432 - val_aux_acc: 0.7581 - val_aux_recall: 0.8142\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 25/200 ...  - loss: 0.7559 - val_loss: 0.7344\n",
      " - main_loss: 0.3715 - main_acc: 0.8371 - main_recall: 0.7121 - val_main_loss: 0.3593 - val_main_acc: 0.8459 - val_main_recall: 0.6959\n",
      " - aux_loss: 0.5256 - aux_acc: 0.7034 - aux_recall: 0.7116 - val_aux_loss: 0.5477 - val_aux_acc: 0.6970 - val_aux_recall: 0.6947\n",
      "step: 50/200 ...  - loss: 0.6489 - val_loss: 0.6457\n",
      " - main_loss: 0.3529 - main_acc: 0.8458 - main_recall: 0.7202 - val_main_loss: 0.3463 - val_main_acc: 0.8529 - val_main_recall: 0.6937\n",
      " - aux_loss: 0.5213 - aux_acc: 0.7060 - aux_recall: 0.7196 - val_aux_loss: 0.5480 - val_aux_acc: 0.6944 - val_aux_recall: 0.6921\n",
      "step: 75/200 ...  - loss: 0.6148 - val_loss: 0.6211\n",
      " - main_loss: 0.3413 - main_acc: 0.8525 - main_recall: 0.7284 - val_main_loss: 0.3451 - val_main_acc: 0.8532 - val_main_recall: 0.7197\n",
      " - aux_loss: 0.5170 - aux_acc: 0.7077 - aux_recall: 0.7278 - val_aux_loss: 0.5461 - val_aux_acc: 0.6937 - val_aux_recall: 0.7183\n",
      "step: 100/200 ...  - loss: 0.5926 - val_loss: 0.6009\n",
      " - main_loss: 0.3319 - main_acc: 0.8568 - main_recall: 0.7342 - val_main_loss: 0.3383 - val_main_acc: 0.8572 - val_main_recall: 0.7033\n",
      " - aux_loss: 0.5120 - aux_acc: 0.7092 - aux_recall: 0.7337 - val_aux_loss: 0.5407 - val_aux_acc: 0.6967 - val_aux_recall: 0.7013\n",
      "step: 125/200 ...  - loss: 0.5726 - val_loss: 0.5849\n",
      " - main_loss: 0.3232 - main_acc: 0.8611 - main_recall: 0.7383 - val_main_loss: 0.3319 - val_main_acc: 0.8612 - val_main_recall: 0.7340\n",
      " - aux_loss: 0.5078 - aux_acc: 0.7120 - aux_recall: 0.7378 - val_aux_loss: 0.5382 - val_aux_acc: 0.6996 - val_aux_recall: 0.7324\n",
      "step: 150/200 ...  - loss: 0.5523 - val_loss: 0.5677\n",
      " - main_loss: 0.3161 - main_acc: 0.8656 - main_recall: 0.7436 - val_main_loss: 0.3293 - val_main_acc: 0.8627 - val_main_recall: 0.7364\n",
      " - aux_loss: 0.5049 - aux_acc: 0.7151 - aux_recall: 0.7431 - val_aux_loss: 0.5311 - val_aux_acc: 0.7026 - val_aux_recall: 0.7349\n",
      "step: 175/200 ...  - loss: 0.5386 - val_loss: 0.5572\n",
      " - main_loss: 0.3086 - main_acc: 0.8682 - main_recall: 0.7491 - val_main_loss: 0.3241 - val_main_acc: 0.8643 - val_main_recall: 0.7577\n",
      " - aux_loss: 0.5012 - aux_acc: 0.7164 - aux_recall: 0.7487 - val_aux_loss: 0.5271 - val_aux_acc: 0.7030 - val_aux_recall: 0.7566\n",
      "step: 200/200 ...  - loss: 0.5325 - val_loss: 0.5617\n",
      " - main_loss: 0.3036 - main_acc: 0.8715 - main_recall: 0.7525 - val_main_loss: 0.3273 - val_main_acc: 0.8634 - val_main_recall: 0.7550\n",
      " - aux_loss: 0.4996 - aux_acc: 0.7186 - aux_recall: 0.7521 - val_aux_loss: 0.5301 - val_aux_acc: 0.7042 - val_aux_recall: 0.7538\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 25/200 ...  - loss: 0.4329 - val_loss: 0.4377\n",
      " - main_loss: 0.2235 - main_acc: 0.9127 - main_recall: 0.9005 - val_main_loss: 0.2359 - val_main_acc: 0.9074 - val_main_recall: 0.9020\n",
      " - aux_loss: 0.3566 - aux_acc: 0.7997 - aux_recall: 0.9004 - val_aux_loss: 0.3743 - val_aux_acc: 0.8019 - val_aux_recall: 0.9019\n",
      "step: 50/200 ...  - loss: 0.3494 - val_loss: 0.3648\n",
      " - main_loss: 0.1952 - main_acc: 0.9202 - main_recall: 0.9122 - val_main_loss: 0.2084 - val_main_acc: 0.9140 - val_main_recall: 0.9044\n",
      " - aux_loss: 0.3382 - aux_acc: 0.8099 - aux_recall: 0.9122 - val_aux_loss: 0.3578 - val_aux_acc: 0.8061 - val_aux_recall: 0.9043\n",
      "step: 75/200 ...  - loss: 0.3611 - val_loss: 0.3809\n",
      " - main_loss: 0.1890 - main_acc: 0.9220 - main_recall: 0.9147 - val_main_loss: 0.2084 - val_main_acc: 0.9133 - val_main_recall: 0.9099\n",
      " - aux_loss: 0.3373 - aux_acc: 0.8101 - aux_recall: 0.9146 - val_aux_loss: 0.3600 - val_aux_acc: 0.8011 - val_aux_recall: 0.9097\n",
      "step: 100/200 ...  - loss: 0.3342 - val_loss: 0.3659\n",
      " - main_loss: 0.1804 - main_acc: 0.9260 - main_recall: 0.9201 - val_main_loss: 0.2091 - val_main_acc: 0.9135 - val_main_recall: 0.9096\n",
      " - aux_loss: 0.3323 - aux_acc: 0.8149 - aux_recall: 0.9200 - val_aux_loss: 0.3606 - val_aux_acc: 0.8028 - val_aux_recall: 0.9095\n",
      "step: 125/200 ...  - loss: 0.3302 - val_loss: 0.3669\n",
      " - main_loss: 0.1749 - main_acc: 0.9284 - main_recall: 0.9209 - val_main_loss: 0.2088 - val_main_acc: 0.9154 - val_main_recall: 0.9053\n",
      " - aux_loss: 0.3301 - aux_acc: 0.8161 - aux_recall: 0.9208 - val_aux_loss: 0.3607 - val_aux_acc: 0.8031 - val_aux_recall: 0.9051\n",
      "step: 150/200 ...  - loss: 0.3354 - val_loss: 0.3794\n",
      " - main_loss: 0.1713 - main_acc: 0.9296 - main_recall: 0.9209 - val_main_loss: 0.2113 - val_main_acc: 0.9136 - val_main_recall: 0.9124\n",
      " - aux_loss: 0.3304 - aux_acc: 0.8158 - aux_recall: 0.9208 - val_aux_loss: 0.3635 - val_aux_acc: 0.8011 - val_aux_recall: 0.9122\n",
      "step: 175/200 ...  - loss: 0.3165 - val_loss: 0.3651\n",
      " - main_loss: 0.1665 - main_acc: 0.9315 - main_recall: 0.9247 - val_main_loss: 0.2104 - val_main_acc: 0.9158 - val_main_recall: 0.9181\n",
      " - aux_loss: 0.3267 - aux_acc: 0.8187 - aux_recall: 0.9246 - val_aux_loss: 0.3572 - val_aux_acc: 0.8042 - val_aux_recall: 0.9179\n",
      "step: 200/200 ...  - loss: 0.3173 - val_loss: 0.3760\n",
      " - main_loss: 0.1629 - main_acc: 0.9336 - main_recall: 0.9236 - val_main_loss: 0.2175 - val_main_acc: 0.9136 - val_main_recall: 0.9047\n",
      " - aux_loss: 0.3268 - aux_acc: 0.8184 - aux_recall: 0.9235 - val_aux_loss: 0.3626 - val_aux_acc: 0.8004 - val_aux_recall: 0.9046\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 25/200 ...  - loss: 0.5685 - val_loss: 0.5595\n",
      " - main_loss: 0.3375 - main_acc: 0.8571 - main_recall: 0.7230 - val_main_loss: 0.3281 - val_main_acc: 0.8613 - val_main_recall: 0.7409\n",
      " - aux_loss: 0.5272 - aux_acc: 0.7052 - aux_recall: 0.7216 - val_aux_loss: 0.5511 - val_aux_acc: 0.6992 - val_aux_recall: 0.7394\n",
      "step: 50/200 ...  - loss: 0.5260 - val_loss: 0.5324\n",
      " - main_loss: 0.3076 - main_acc: 0.8687 - main_recall: 0.7366 - val_main_loss: 0.3103 - val_main_acc: 0.8685 - val_main_recall: 0.7529\n",
      " - aux_loss: 0.5145 - aux_acc: 0.7128 - aux_recall: 0.7354 - val_aux_loss: 0.5315 - val_aux_acc: 0.7028 - val_aux_recall: 0.7514\n",
      "step: 75/200 ...  - loss: 0.5116 - val_loss: 0.5251\n",
      " - main_loss: 0.2985 - main_acc: 0.8722 - main_recall: 0.7443 - val_main_loss: 0.3090 - val_main_acc: 0.8702 - val_main_recall: 0.7640\n",
      " - aux_loss: 0.5103 - aux_acc: 0.7146 - aux_recall: 0.7431 - val_aux_loss: 0.5299 - val_aux_acc: 0.7076 - val_aux_recall: 0.7625\n",
      "step: 100/200 ...  - loss: 0.5015 - val_loss: 0.5216\n",
      " - main_loss: 0.2893 - main_acc: 0.8772 - main_recall: 0.7498 - val_main_loss: 0.3064 - val_main_acc: 0.8705 - val_main_recall: 0.7639\n",
      " - aux_loss: 0.5072 - aux_acc: 0.7172 - aux_recall: 0.7485 - val_aux_loss: 0.5234 - val_aux_acc: 0.7128 - val_aux_recall: 0.7624\n",
      "step: 125/200 ...  - loss: 0.4945 - val_loss: 0.5264\n",
      " - main_loss: 0.2846 - main_acc: 0.8788 - main_recall: 0.7519 - val_main_loss: 0.3121 - val_main_acc: 0.8685 - val_main_recall: 0.7543\n",
      " - aux_loss: 0.5057 - aux_acc: 0.7178 - aux_recall: 0.7507 - val_aux_loss: 0.5273 - val_aux_acc: 0.7098 - val_aux_recall: 0.7526\n",
      "step: 150/200 ...  - loss: 0.4839 - val_loss: 0.5176\n",
      " - main_loss: 0.2783 - main_acc: 0.8821 - main_recall: 0.7567 - val_main_loss: 0.3083 - val_main_acc: 0.8697 - val_main_recall: 0.7673\n",
      " - aux_loss: 0.5027 - aux_acc: 0.7203 - aux_recall: 0.7555 - val_aux_loss: 0.5245 - val_aux_acc: 0.7121 - val_aux_recall: 0.7657\n",
      "step: 175/200 ...  - loss: 0.4814 - val_loss: 0.5170\n",
      " - main_loss: 0.2746 - main_acc: 0.8841 - main_recall: 0.7578 - val_main_loss: 0.3056 - val_main_acc: 0.8711 - val_main_recall: 0.7656\n",
      " - aux_loss: 0.5017 - aux_acc: 0.7201 - aux_recall: 0.7565 - val_aux_loss: 0.5219 - val_aux_acc: 0.7142 - val_aux_recall: 0.7639\n",
      "step: 200/200 ...  - loss: 0.4785 - val_loss: 0.5196\n",
      " - main_loss: 0.2709 - main_acc: 0.8854 - main_recall: 0.7578 - val_main_loss: 0.3076 - val_main_acc: 0.8708 - val_main_recall: 0.7592\n",
      " - aux_loss: 0.5006 - aux_acc: 0.7208 - aux_recall: 0.7566 - val_aux_loss: 0.5243 - val_aux_acc: 0.7128 - val_aux_recall: 0.7576\n",
      "Entrenando sin especie: Specie_Pig\n",
      "step: 25/200 ...  - loss: 0.4006 - val_loss: 0.4100\n",
      " - main_loss: 0.2178 - main_acc: 0.9088 - main_recall: 0.8069 - val_main_loss: 0.2274 - val_main_acc: 0.9022 - val_main_recall: 0.8031\n",
      " - aux_loss: 0.3994 - aux_acc: 0.7827 - aux_recall: 0.8061 - val_aux_loss: 0.4153 - val_aux_acc: 0.7761 - val_aux_recall: 0.8015\n",
      "step: 50/200 ...  - loss: 0.3754 - val_loss: 0.3958\n",
      " - main_loss: 0.2064 - main_acc: 0.9135 - main_recall: 0.8063 - val_main_loss: 0.2241 - val_main_acc: 0.9020 - val_main_recall: 0.7998\n",
      " - aux_loss: 0.3932 - aux_acc: 0.7822 - aux_recall: 0.8055 - val_aux_loss: 0.4072 - val_aux_acc: 0.7769 - val_aux_recall: 0.7982\n",
      "step: 75/200 ...  - loss: 0.3683 - val_loss: 0.3945\n",
      " - main_loss: 0.2019 - main_acc: 0.9152 - main_recall: 0.8069 - val_main_loss: 0.2253 - val_main_acc: 0.9018 - val_main_recall: 0.7982\n",
      " - aux_loss: 0.3907 - aux_acc: 0.7841 - aux_recall: 0.8062 - val_aux_loss: 0.4057 - val_aux_acc: 0.7783 - val_aux_recall: 0.7965\n",
      "step: 100/200 ...  - loss: 0.3657 - val_loss: 0.3968\n",
      " - main_loss: 0.1984 - main_acc: 0.9166 - main_recall: 0.8080 - val_main_loss: 0.2266 - val_main_acc: 0.9025 - val_main_recall: 0.7962\n",
      " - aux_loss: 0.3901 - aux_acc: 0.7834 - aux_recall: 0.8073 - val_aux_loss: 0.4057 - val_aux_acc: 0.7790 - val_aux_recall: 0.7946\n",
      "step: 125/200 ...  - loss: 0.3609 - val_loss: 0.3946\n",
      " - main_loss: 0.1954 - main_acc: 0.9181 - main_recall: 0.8100 - val_main_loss: 0.2272 - val_main_acc: 0.9011 - val_main_recall: 0.7997\n",
      " - aux_loss: 0.3888 - aux_acc: 0.7839 - aux_recall: 0.8092 - val_aux_loss: 0.4040 - val_aux_acc: 0.7792 - val_aux_recall: 0.7980\n",
      "step: 150/200 ...  - loss: 0.3571 - val_loss: 0.3958\n",
      " - main_loss: 0.1922 - main_acc: 0.9193 - main_recall: 0.8103 - val_main_loss: 0.2284 - val_main_acc: 0.9010 - val_main_recall: 0.7945\n",
      " - aux_loss: 0.3874 - aux_acc: 0.7849 - aux_recall: 0.8093 - val_aux_loss: 0.4027 - val_aux_acc: 0.7793 - val_aux_recall: 0.7928\n",
      "step: 175/200 ...  - loss: 0.3520 - val_loss: 0.3957\n",
      " - main_loss: 0.1895 - main_acc: 0.9207 - main_recall: 0.8128 - val_main_loss: 0.2300 - val_main_acc: 0.8996 - val_main_recall: 0.7941\n",
      " - aux_loss: 0.3865 - aux_acc: 0.7850 - aux_recall: 0.8120 - val_aux_loss: 0.4039 - val_aux_acc: 0.7775 - val_aux_recall: 0.7924\n",
      "step: 200/200 ...  - loss: 0.3519 - val_loss: 0.3996\n",
      " - main_loss: 0.1885 - main_acc: 0.9208 - main_recall: 0.8130 - val_main_loss: 0.2326 - val_main_acc: 0.9002 - val_main_recall: 0.7996\n",
      " - aux_loss: 0.3860 - aux_acc: 0.7856 - aux_recall: 0.8122 - val_aux_loss: 0.4058 - val_aux_acc: 0.7779 - val_aux_recall: 0.7980\n",
      "Evaluando especie sin balancear: Specie_Pig\n",
      "loss     = 0.9619\n",
      "main_loss     = 0.6679\n",
      "aux_loss     = 1.0605\n",
      "main_acc     = 0.7246\n",
      "main_recall     = 0.6690\n",
      "aux_acc     = 0.4206\n",
      "aux_recall     = 0.6690\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Pig\n",
      "loss     = 1.0275\n",
      "main_loss     = 0.7543\n",
      "aux_loss     = 0.9567\n",
      "main_acc     = 0.6861\n",
      "main_recall     = 0.6690\n",
      "aux_acc     = 0.4920\n",
      "aux_recall     = 0.6690\n",
      "\n",
      "\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 25/200 ...  - loss: 7.8819 - val_loss: 7.7505\n",
      " - main_loss: 0.5179 - main_acc: 0.7216 - main_recall: 0.6081 - val_main_loss: 0.4586 - val_main_acc: 0.7504 - val_main_recall: 0.5406\n",
      " - aux_loss: 0.5358 - aux_acc: 0.6967 - aux_recall: 0.6081 - val_aux_loss: 0.4906 - val_aux_acc: 0.7400 - val_aux_recall: 0.5408\n",
      "step: 50/200 ...  - loss: 6.0067 - val_loss: 5.9269\n",
      " - main_loss: 0.4210 - main_acc: 0.7952 - main_recall: 0.6546 - val_main_loss: 0.3819 - val_main_acc: 0.8120 - val_main_recall: 0.6282\n",
      " - aux_loss: 0.4915 - aux_acc: 0.7279 - aux_recall: 0.6546 - val_aux_loss: 0.4684 - val_aux_acc: 0.7482 - val_aux_recall: 0.6255\n",
      "step: 75/200 ...  - loss: 5.0299 - val_loss: 4.9787\n",
      " - main_loss: 0.3906 - main_acc: 0.8164 - main_recall: 0.6824 - val_main_loss: 0.3572 - val_main_acc: 0.8379 - val_main_recall: 0.6852\n",
      " - aux_loss: 0.4823 - aux_acc: 0.7340 - aux_recall: 0.6825 - val_aux_loss: 0.4624 - val_aux_acc: 0.7507 - val_aux_recall: 0.6804\n",
      "step: 100/200 ...  - loss: 4.4407 - val_loss: 4.3914\n",
      " - main_loss: 0.3798 - main_acc: 0.8233 - main_recall: 0.6930 - val_main_loss: 0.3520 - val_main_acc: 0.8398 - val_main_recall: 0.7025\n",
      " - aux_loss: 0.4798 - aux_acc: 0.7362 - aux_recall: 0.6930 - val_aux_loss: 0.4627 - val_aux_acc: 0.7491 - val_aux_recall: 0.6979\n",
      "step: 125/200 ...  - loss: 3.5520 - val_loss: 3.4987\n",
      " - main_loss: 0.3701 - main_acc: 0.8307 - main_recall: 0.7012 - val_main_loss: 0.3475 - val_main_acc: 0.8429 - val_main_recall: 0.7100\n",
      " - aux_loss: 0.4743 - aux_acc: 0.7378 - aux_recall: 0.7012 - val_aux_loss: 0.4589 - val_aux_acc: 0.7514 - val_aux_recall: 0.7050\n",
      "step: 150/200 ...  - loss: 2.7563 - val_loss: 2.7124\n",
      " - main_loss: 0.3623 - main_acc: 0.8349 - main_recall: 0.7020 - val_main_loss: 0.3428 - val_main_acc: 0.8451 - val_main_recall: 0.7061\n",
      " - aux_loss: 0.4710 - aux_acc: 0.7390 - aux_recall: 0.7020 - val_aux_loss: 0.4573 - val_aux_acc: 0.7486 - val_aux_recall: 0.7006\n",
      "step: 175/200 ...  - loss: 2.2389 - val_loss: 2.2064\n",
      " - main_loss: 0.3540 - main_acc: 0.8407 - main_recall: 0.7159 - val_main_loss: 0.3386 - val_main_acc: 0.8475 - val_main_recall: 0.7143\n",
      " - aux_loss: 0.4678 - aux_acc: 0.7401 - aux_recall: 0.7160 - val_aux_loss: 0.4569 - val_aux_acc: 0.7498 - val_aux_recall: 0.7092\n",
      "step: 200/200 ...  - loss: 1.9691 - val_loss: 1.9448\n",
      " - main_loss: 0.3483 - main_acc: 0.8430 - main_recall: 0.7246 - val_main_loss: 0.3359 - val_main_acc: 0.8476 - val_main_recall: 0.7229\n",
      " - aux_loss: 0.4645 - aux_acc: 0.7415 - aux_recall: 0.7247 - val_aux_loss: 0.4580 - val_aux_acc: 0.7485 - val_aux_recall: 0.7176\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 25/200 ...  - loss: 0.9719 - val_loss: 0.9410\n",
      " - main_loss: 0.3962 - main_acc: 0.8232 - main_recall: 0.5986 - val_main_loss: 0.3921 - val_main_acc: 0.8281 - val_main_recall: 0.5647\n",
      " - aux_loss: 0.5491 - aux_acc: 0.6937 - aux_recall: 0.5980 - val_aux_loss: 0.5701 - val_aux_acc: 0.7002 - val_aux_recall: 0.5569\n",
      "step: 50/200 ...  - loss: 0.6725 - val_loss: 0.6710\n",
      " - main_loss: 0.3747 - main_acc: 0.8353 - main_recall: 0.5914 - val_main_loss: 0.3741 - val_main_acc: 0.8366 - val_main_recall: 0.5873\n",
      " - aux_loss: 0.5452 - aux_acc: 0.6960 - aux_recall: 0.5907 - val_aux_loss: 0.5579 - val_aux_acc: 0.6967 - val_aux_recall: 0.5799\n",
      "step: 75/200 ...  - loss: 0.6254 - val_loss: 0.6289\n",
      " - main_loss: 0.3608 - main_acc: 0.8423 - main_recall: 0.5946 - val_main_loss: 0.3636 - val_main_acc: 0.8399 - val_main_recall: 0.5872\n",
      " - aux_loss: 0.5425 - aux_acc: 0.6967 - aux_recall: 0.5939 - val_aux_loss: 0.5556 - val_aux_acc: 0.6988 - val_aux_recall: 0.5796\n",
      "step: 100/200 ...  - loss: 0.6028 - val_loss: 0.6044\n",
      " - main_loss: 0.3485 - main_acc: 0.8481 - main_recall: 0.5985 - val_main_loss: 0.3507 - val_main_acc: 0.8473 - val_main_recall: 0.6094\n",
      " - aux_loss: 0.5398 - aux_acc: 0.6975 - aux_recall: 0.5978 - val_aux_loss: 0.5491 - val_aux_acc: 0.6976 - val_aux_recall: 0.6019\n",
      "step: 125/200 ...  - loss: 0.5826 - val_loss: 0.5840\n",
      " - main_loss: 0.3379 - main_acc: 0.8531 - main_recall: 0.6009 - val_main_loss: 0.3407 - val_main_acc: 0.8514 - val_main_recall: 0.5917\n",
      " - aux_loss: 0.5377 - aux_acc: 0.6978 - aux_recall: 0.6002 - val_aux_loss: 0.5464 - val_aux_acc: 0.7024 - val_aux_recall: 0.5831\n",
      "step: 150/200 ...  - loss: 0.5688 - val_loss: 0.5768\n",
      " - main_loss: 0.3288 - main_acc: 0.8574 - main_recall: 0.6037 - val_main_loss: 0.3364 - val_main_acc: 0.8528 - val_main_recall: 0.6162\n",
      " - aux_loss: 0.5366 - aux_acc: 0.6988 - aux_recall: 0.6030 - val_aux_loss: 0.5481 - val_aux_acc: 0.6985 - val_aux_recall: 0.6086\n",
      "step: 175/200 ...  - loss: 0.5533 - val_loss: 0.5625\n",
      " - main_loss: 0.3227 - main_acc: 0.8606 - main_recall: 0.6076 - val_main_loss: 0.3334 - val_main_acc: 0.8550 - val_main_recall: 0.6051\n",
      " - aux_loss: 0.5350 - aux_acc: 0.6999 - aux_recall: 0.6069 - val_aux_loss: 0.5399 - val_aux_acc: 0.7045 - val_aux_recall: 0.5972\n",
      "step: 200/200 ...  - loss: 0.5394 - val_loss: 0.5536\n",
      " - main_loss: 0.3169 - main_acc: 0.8628 - main_recall: 0.6088 - val_main_loss: 0.3303 - val_main_acc: 0.8557 - val_main_recall: 0.6032\n",
      " - aux_loss: 0.5333 - aux_acc: 0.7006 - aux_recall: 0.6080 - val_aux_loss: 0.5425 - val_aux_acc: 0.7049 - val_aux_recall: 0.5949\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 25/200 ...  - loss: 0.4557 - val_loss: 0.4518\n",
      " - main_loss: 0.2470 - main_acc: 0.8970 - main_recall: 0.7790 - val_main_loss: 0.2475 - val_main_acc: 0.8925 - val_main_recall: 0.7672\n",
      " - aux_loss: 0.4225 - aux_acc: 0.7623 - aux_recall: 0.7788 - val_aux_loss: 0.4576 - val_aux_acc: 0.7496 - val_aux_recall: 0.7622\n",
      "step: 50/200 ...  - loss: 0.4067 - val_loss: 0.4142\n",
      " - main_loss: 0.2301 - main_acc: 0.9022 - main_recall: 0.7824 - val_main_loss: 0.2384 - val_main_acc: 0.8958 - val_main_recall: 0.7683\n",
      " - aux_loss: 0.4114 - aux_acc: 0.7657 - aux_recall: 0.7821 - val_aux_loss: 0.4267 - val_aux_acc: 0.7591 - val_aux_recall: 0.7635\n",
      "step: 75/200 ...  - loss: 0.4055 - val_loss: 0.4137\n",
      " - main_loss: 0.2243 - main_acc: 0.9056 - main_recall: 0.7866 - val_main_loss: 0.2351 - val_main_acc: 0.8964 - val_main_recall: 0.7720\n",
      " - aux_loss: 0.4076 - aux_acc: 0.7666 - aux_recall: 0.7863 - val_aux_loss: 0.4177 - val_aux_acc: 0.7590 - val_aux_recall: 0.7673\n",
      "step: 100/200 ...  - loss: 0.3897 - val_loss: 0.4074\n",
      " - main_loss: 0.2186 - main_acc: 0.9077 - main_recall: 0.7870 - val_main_loss: 0.2377 - val_main_acc: 0.8958 - val_main_recall: 0.7715\n",
      " - aux_loss: 0.4041 - aux_acc: 0.7682 - aux_recall: 0.7867 - val_aux_loss: 0.4174 - val_aux_acc: 0.7589 - val_aux_recall: 0.7672\n",
      "step: 125/200 ...  - loss: 0.3981 - val_loss: 0.4159\n",
      " - main_loss: 0.2159 - main_acc: 0.9085 - main_recall: 0.7876 - val_main_loss: 0.2344 - val_main_acc: 0.8965 - val_main_recall: 0.7703\n",
      " - aux_loss: 0.4037 - aux_acc: 0.7681 - aux_recall: 0.7874 - val_aux_loss: 0.4185 - val_aux_acc: 0.7590 - val_aux_recall: 0.7656\n",
      "step: 150/200 ...  - loss: 0.4004 - val_loss: 0.4214\n",
      " - main_loss: 0.2127 - main_acc: 0.9101 - main_recall: 0.7898 - val_main_loss: 0.2353 - val_main_acc: 0.8966 - val_main_recall: 0.7792\n",
      " - aux_loss: 0.4019 - aux_acc: 0.7689 - aux_recall: 0.7896 - val_aux_loss: 0.4182 - val_aux_acc: 0.7574 - val_aux_recall: 0.7748\n",
      "step: 175/200 ...  - loss: 0.3837 - val_loss: 0.4149\n",
      " - main_loss: 0.2059 - main_acc: 0.9126 - main_recall: 0.7932 - val_main_loss: 0.2381 - val_main_acc: 0.8958 - val_main_recall: 0.7732\n",
      " - aux_loss: 0.4002 - aux_acc: 0.7709 - aux_recall: 0.7929 - val_aux_loss: 0.4158 - val_aux_acc: 0.7590 - val_aux_recall: 0.7688\n",
      "step: 200/200 ...  - loss: 0.3924 - val_loss: 0.4281\n",
      " - main_loss: 0.2047 - main_acc: 0.9135 - main_recall: 0.7964 - val_main_loss: 0.2398 - val_main_acc: 0.8959 - val_main_recall: 0.7718\n",
      " - aux_loss: 0.3991 - aux_acc: 0.7709 - aux_recall: 0.7962 - val_aux_loss: 0.4197 - val_aux_acc: 0.7599 - val_aux_recall: 0.7673\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 25/200 ...  - loss: 0.5607 - val_loss: 0.5592\n",
      " - main_loss: 0.3284 - main_acc: 0.8586 - main_recall: 0.6103 - val_main_loss: 0.3305 - val_main_acc: 0.8567 - val_main_recall: 0.5987\n",
      " - aux_loss: 0.5435 - aux_acc: 0.6938 - aux_recall: 0.6085 - val_aux_loss: 0.5501 - val_aux_acc: 0.6974 - val_aux_recall: 0.5935\n",
      "step: 50/200 ...  - loss: 0.5295 - val_loss: 0.5447\n",
      " - main_loss: 0.3103 - main_acc: 0.8662 - main_recall: 0.6140 - val_main_loss: 0.3245 - val_main_acc: 0.8590 - val_main_recall: 0.6254\n",
      " - aux_loss: 0.5365 - aux_acc: 0.6985 - aux_recall: 0.6122 - val_aux_loss: 0.5443 - val_aux_acc: 0.6988 - val_aux_recall: 0.6201\n",
      "step: 75/200 ...  - loss: 0.5197 - val_loss: 0.5444\n",
      " - main_loss: 0.3038 - main_acc: 0.8695 - main_recall: 0.6171 - val_main_loss: 0.3258 - val_main_acc: 0.8581 - val_main_recall: 0.6045\n",
      " - aux_loss: 0.5353 - aux_acc: 0.6994 - aux_recall: 0.6151 - val_aux_loss: 0.5463 - val_aux_acc: 0.6979 - val_aux_recall: 0.5989\n",
      "step: 100/200 ...  - loss: 0.5143 - val_loss: 0.5435\n",
      " - main_loss: 0.2972 - main_acc: 0.8729 - main_recall: 0.6242 - val_main_loss: 0.3238 - val_main_acc: 0.8585 - val_main_recall: 0.6100\n",
      " - aux_loss: 0.5325 - aux_acc: 0.7020 - aux_recall: 0.6222 - val_aux_loss: 0.5426 - val_aux_acc: 0.7035 - val_aux_recall: 0.6046\n",
      "step: 125/200 ...  - loss: 0.5076 - val_loss: 0.5394\n",
      " - main_loss: 0.2934 - main_acc: 0.8748 - main_recall: 0.6273 - val_main_loss: 0.3230 - val_main_acc: 0.8578 - val_main_recall: 0.6143\n",
      " - aux_loss: 0.5317 - aux_acc: 0.7027 - aux_recall: 0.6252 - val_aux_loss: 0.5448 - val_aux_acc: 0.6994 - val_aux_recall: 0.6090\n",
      "step: 150/200 ...  - loss: 0.5023 - val_loss: 0.5397\n",
      " - main_loss: 0.2888 - main_acc: 0.8771 - main_recall: 0.6300 - val_main_loss: 0.3254 - val_main_acc: 0.8590 - val_main_recall: 0.6024\n",
      " - aux_loss: 0.5303 - aux_acc: 0.7043 - aux_recall: 0.6281 - val_aux_loss: 0.5421 - val_aux_acc: 0.7029 - val_aux_recall: 0.5967\n",
      "step: 175/200 ...  - loss: 0.4930 - val_loss: 0.5352\n",
      " - main_loss: 0.2845 - main_acc: 0.8793 - main_recall: 0.6320 - val_main_loss: 0.3248 - val_main_acc: 0.8578 - val_main_recall: 0.6197\n",
      " - aux_loss: 0.5293 - aux_acc: 0.7044 - aux_recall: 0.6300 - val_aux_loss: 0.5422 - val_aux_acc: 0.7013 - val_aux_recall: 0.6145\n",
      "step: 200/200 ...  - loss: 0.4909 - val_loss: 0.5351\n",
      " - main_loss: 0.2818 - main_acc: 0.8805 - main_recall: 0.6376 - val_main_loss: 0.3244 - val_main_acc: 0.8580 - val_main_recall: 0.6171\n",
      " - aux_loss: 0.5277 - aux_acc: 0.7058 - aux_recall: 0.6356 - val_aux_loss: 0.5401 - val_aux_acc: 0.7048 - val_aux_recall: 0.6121\n",
      "Entrenando sin especie: Specie_Rat\n",
      "step: 25/200 ...  - loss: 0.4011 - val_loss: 0.4129\n",
      " - main_loss: 0.2224 - main_acc: 0.9074 - main_recall: 0.7963 - val_main_loss: 0.2339 - val_main_acc: 0.8994 - val_main_recall: 0.7860\n",
      " - aux_loss: 0.4051 - aux_acc: 0.7789 - aux_recall: 0.7955 - val_aux_loss: 0.4225 - val_aux_acc: 0.7729 - val_aux_recall: 0.7842\n",
      "step: 50/200 ...  - loss: 0.3758 - val_loss: 0.4023\n",
      " - main_loss: 0.2085 - main_acc: 0.9124 - main_recall: 0.8014 - val_main_loss: 0.2318 - val_main_acc: 0.8993 - val_main_recall: 0.7879\n",
      " - aux_loss: 0.3978 - aux_acc: 0.7810 - aux_recall: 0.8005 - val_aux_loss: 0.4146 - val_aux_acc: 0.7768 - val_aux_recall: 0.7862\n",
      "step: 75/200 ...  - loss: 0.3706 - val_loss: 0.4053\n",
      " - main_loss: 0.2049 - main_acc: 0.9140 - main_recall: 0.8036 - val_main_loss: 0.2370 - val_main_acc: 0.8971 - val_main_recall: 0.7907\n",
      " - aux_loss: 0.3950 - aux_acc: 0.7817 - aux_recall: 0.8027 - val_aux_loss: 0.4142 - val_aux_acc: 0.7757 - val_aux_recall: 0.7891\n",
      "step: 100/200 ...  - loss: 0.3630 - val_loss: 0.4040\n",
      " - main_loss: 0.1998 - main_acc: 0.9159 - main_recall: 0.8043 - val_main_loss: 0.2367 - val_main_acc: 0.8968 - val_main_recall: 0.7829\n",
      " - aux_loss: 0.3930 - aux_acc: 0.7823 - aux_recall: 0.8036 - val_aux_loss: 0.4106 - val_aux_acc: 0.7767 - val_aux_recall: 0.7812\n",
      "step: 125/200 ...  - loss: 0.3604 - val_loss: 0.4082\n",
      " - main_loss: 0.1966 - main_acc: 0.9179 - main_recall: 0.8049 - val_main_loss: 0.2402 - val_main_acc: 0.8960 - val_main_recall: 0.7879\n",
      " - aux_loss: 0.3925 - aux_acc: 0.7815 - aux_recall: 0.8040 - val_aux_loss: 0.4123 - val_aux_acc: 0.7744 - val_aux_recall: 0.7863\n",
      "step: 150/200 ...  - loss: 0.3559 - val_loss: 0.4096\n",
      " - main_loss: 0.1926 - main_acc: 0.9194 - main_recall: 0.8060 - val_main_loss: 0.2414 - val_main_acc: 0.8953 - val_main_recall: 0.7875\n",
      " - aux_loss: 0.3916 - aux_acc: 0.7812 - aux_recall: 0.8052 - val_aux_loss: 0.4132 - val_aux_acc: 0.7743 - val_aux_recall: 0.7860\n",
      "step: 175/200 ...  - loss: 0.3555 - val_loss: 0.4103\n",
      " - main_loss: 0.1915 - main_acc: 0.9201 - main_recall: 0.8098 - val_main_loss: 0.2423 - val_main_acc: 0.8966 - val_main_recall: 0.7914\n",
      " - aux_loss: 0.3909 - aux_acc: 0.7822 - aux_recall: 0.8090 - val_aux_loss: 0.4126 - val_aux_acc: 0.7744 - val_aux_recall: 0.7898\n",
      "step: 200/200 ...  - loss: 0.3480 - val_loss: 0.4083\n",
      " - main_loss: 0.1873 - main_acc: 0.9221 - main_recall: 0.8115 - val_main_loss: 0.2429 - val_main_acc: 0.8964 - val_main_recall: 0.7922\n",
      " - aux_loss: 0.3892 - aux_acc: 0.7816 - aux_recall: 0.8106 - val_aux_loss: 0.4118 - val_aux_acc: 0.7736 - val_aux_recall: 0.7906\n",
      "Evaluando especie sin balancear: Specie_Rat\n",
      "loss     = 0.9105\n",
      "main_loss     = 0.6353\n",
      "aux_loss     = 0.9700\n",
      "main_acc     = 0.7309\n",
      "main_recall     = 0.4917\n",
      "aux_acc     = 0.4836\n",
      "aux_recall     = 0.4917\n",
      "\n",
      "\n",
      "Evaluando especie balanceada: Specie_Rat\n",
      "loss     = 0.9051\n",
      "main_loss     = 0.6360\n",
      "aux_loss     = 0.9394\n",
      "main_acc     = 0.7307\n",
      "main_recall     = 0.5059\n",
      "aux_acc     = 0.5037\n",
      "aux_recall     = 0.4855\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "species_siames_cross_dict = {}\n",
    "for specie in species_metadata:\n",
    "    dataset_complete_no_species = dataset_complete[dataset_complete[specie] == 0]    \n",
    "    dataset_complete_species = dataset_complete[dataset_complete[specie] == 1]    \n",
    "        \n",
    "    df_no_species = dataset_complete_no_species[dataset_complete_no_species[specie] == 0]\n",
    "    \n",
    "    df_train, df_val = train_test_split(df_no_species, test_size=0.2,random_state=9,stratify=df_no_species[\"Is_Ohnolog\"])\n",
    "    \n",
    "    df_train_x = df_train.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_train_x = df_train_x.drop(embedding_1_cols,axis=1)\n",
    "    df_train_x = df_train_x.drop(embedding_2_cols,axis=1)\n",
    "    \n",
    "    df_train_emb_x_1 = df_train[embedding_1_cols]\n",
    "    df_train_emb_x_2 = df_train[embedding_2_cols]\n",
    "\n",
    "    model = level_siames_merge_layer(df_train_x,df_train_emb_x_1,df_train_emb_x_2,\"Siames \" + specie,128)        \n",
    "    specie_metadata_copy = species_metadata[:]\n",
    "    specie_metadata_copy.remove(specie)\n",
    "\n",
    "    for specie_cross in specie_metadata_copy:\n",
    "        df_no_species = dataset_complete_no_species[dataset_complete_no_species[specie_cross] == 0]\n",
    "        df_train, df_val = train_test_split(df_no_species, test_size=0.2,random_state=9,stratify=df_no_species[\"Is_Ohnolog\"])\n",
    "\n",
    "        df_train_x = df_train.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "        df_train_x = df_train_x.drop(embedding_1_cols,axis=1)\n",
    "        df_train_x = df_train_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "        df_train_emb_x_1 = df_train[embedding_1_cols]\n",
    "        df_train_emb_x_2 = df_train[embedding_2_cols]\n",
    "        df_train_y = df_train[\"Is_Ohnolog\"]\n",
    "\n",
    "        df_val_x = df_val.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "        df_val_x = df_val_x.drop(embedding_1_cols,axis=1)\n",
    "        df_val_x = df_val_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "        df_val_emb_x_1 = df_val[embedding_1_cols]\n",
    "        df_val_emb_x_2 = df_val[embedding_2_cols]\n",
    "        df_val_y = df_val[\"Is_Ohnolog\"]\n",
    "\n",
    "        print(\"Entrenando sin especie: \" + specie)\n",
    "        log = fit_model_siames(df_train_x.values,df_train_emb_x_1.values,df_train_emb_x_2.values,df_train_y.values,df_val_x.values,df_val_emb_x_1.values,df_val_emb_x_2.values,df_val_y.values,model,200,Adamax(),256,[1,0.2],0)\n",
    "        \n",
    "    \n",
    "    df_test_species_x = dataset_complete_species.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_species_emb_x_1 =  dataset_complete_species[embedding_1_cols]\n",
    "    df_test_species_emb_x_2 =  dataset_complete_species[embedding_2_cols]\n",
    "    df_test_species_y = dataset_complete_species[\"Is_Ohnolog\"]\n",
    "    \n",
    "    species_siames_cross_dict[specie] = {}\n",
    "    \n",
    "    print(\"Evaluando especie sin balancear: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_species_emb_x_1.values,df_test_species_emb_x_2.values,df_test_species_x.values],[df_test_species_y.values,df_test_species_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_siames_cross_dict[specie][\"Sin Balanceo\"] = metrics[5]\n",
    "    \n",
    "    df_species_ohnologs = dataset_complete_species[dataset_complete_species[\"Is_Ohnolog\"] == 1]\n",
    "    df_species_no_ohnologs = dataset_complete_species[dataset_complete_species[\"Is_Ohnolog\"] == 0]\n",
    "    \n",
    "    if(len(df_species_ohnologs)>len(df_species_no_ohnologs)):\n",
    "        df_species_new = df_species_no_ohnologs.append(df_species_ohnologs.sample(len(df_species_no_ohnologs)))        \n",
    "    else:\n",
    "        df_species_new = df_species_ohnologs.append(df_species_no_ohnologs.sample(len(df_species_ohnologs)))\n",
    "\n",
    "    if(len(df_species_new) == 0):\n",
    "        df_species_new = df_species_ohnologs        \n",
    "        \n",
    "    df_test_species_x = df_species_new.drop([\"Is_Ohnolog\",\"Is_Paralog\",\"Dup_Class\"],axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_1_cols,axis=1)\n",
    "    df_test_species_x = df_test_species_x.drop(embedding_2_cols,axis=1)\n",
    "\n",
    "    df_test_species_emb_x_1 = df_species_new[embedding_1_cols]\n",
    "    df_test_species_emb_x_2 = df_species_new[embedding_2_cols]\n",
    "    df_test_species_y = df_species_new[\"Is_Ohnolog\"]                    \n",
    "    \n",
    "    print(\"Evaluando especie balanceada: \" + specie)\n",
    "    metrics_names,metrics = (model.metrics_names,model.evaluate([df_test_species_emb_x_1.values,df_test_species_emb_x_2.values,df_test_species_x.values],[df_test_species_y.values,df_test_species_y.values], batch_size=256,verbose=False))\n",
    "    count = 0\n",
    "    for i in range(0,len(metrics)):\n",
    "        print(f'{metrics_names[i]}     = {metrics[i]:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    species_cross_dict[specie][\"Balanceadas\"] = metrics[5]   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis3",
   "language": "python",
   "name": "thesis3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
